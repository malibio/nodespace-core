//! SurrealStore - Direct SurrealDB Backend Implementation
//!
//! This module provides the primary and only database backend for NodeSpace,
//! using SurrealDB embedded database with RocksDB storage engine.
//!
//! # Architecture
//!
//! SurrealStore uses a **hybrid dual-table architecture**:
//! 1. **Universal `nodes` table** - Common metadata, embeddings, hierarchy
//! 2. **Type-specific tables** - Type-safe schemas per entity (`task`, `text`, etc.)
//!
//! # Design Principles
//!
//! 1. **Embedded RocksDB**: Desktop-only backend using `kv-rocksdb` engine
//! 2. **SCHEMALESS Mode**: Core tables use SCHEMALESS for dynamic properties
//! 3. **Record IDs**: Native SurrealDB format `table:uuid` (type embedded in ID)
//! 4. **Direct Access**: No abstraction layers, SurrealStore used directly by services
//!
//! # Performance Targets (from PoC)
//!
//! - Startup time: <100ms (PoC: 52ms)
//! - 100K nodes query: <200ms (PoC: 104ms)
//! - Deep pagination: <50ms (PoC: 8.3ms)
//! - Complex queries avg: <300ms (PoC: 211ms)
//!
//! # Examples
//!
//! ```rust,no_run
//! use nodespace_core::db::SurrealStore;
//! use std::path::PathBuf;
//!
//! #[tokio::main]
//! async fn main() -> anyhow::Result<()> {
//!     // Create embedded SurrealDB store
//!     let db_path = PathBuf::from("./data/surreal.db");
//!     let store = SurrealStore::new(db_path).await?;
//!
//!     // Direct database access
//!     let node = store.get_node("task:550e8400-e29b-41d4-a716-446655440000").await?;
//!
//!     Ok(())
//! }
//! ```

use crate::models::{DeleteResult, Node, NodeQuery, NodeUpdate};
use anyhow::{Context, Result};
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use serde_json::Value;
use std::path::PathBuf;
use std::sync::Arc;
use surrealdb::engine::local::{Db, RocksDb};
use surrealdb::engine::remote::http::{Client, Http};
use surrealdb::opt::auth::Root;
use surrealdb::sql::{Id, Thing};
use surrealdb::Surreal;

/// Internal struct matching SurrealDB's schema with 'uuid' field
///
/// # Schema Evolution
///
/// - **v1.0** (Issue #470): Initial SurrealDB schema migration
///   - Core node fields (uuid, node_type, content, parent_id, etc.)
///   - Embedding vector storage
///   - Version-based optimistic concurrency control
///
/// - **v1.1** (Issue #481): Advanced SurrealDB features
///   - Added `embedding_stale` field for tracking embedding staleness
///   - Default: `false` (backward compatible via `#[serde(default)]`)
///   - Existing nodes without this field are treated as not stale
///   - Automatically set to `true` when content changes, cleared when embedding regenerated
///
/// - **v1.2** (Issue #511 Phase 1): Graph-native architecture preparation
///   - Added `data` field: Optional record link to type-specific table (replaces properties field)
///   - Added `variants` field: Type history for lossless type switching
///   - Added `_schema_version` field: Universal versioning (moved from type tables)
///   - Table renamed from `nodes` to `node` (singular, consistent naming)
///
/// # Embedding Storage Architecture (Issue #495)
///
/// Embeddings use a **hybrid storage architecture** with different representations
/// at different boundaries:
///
/// - **External API** (`Node` struct): `Vec<u8>` binary blobs
///   - Generated by `EmbeddingService::to_blob()` (little-endian f32 encoding)
///   - Storage-efficient format for transfer and external persistence
///
/// - **Database Storage** (`SurrealNode` struct): `Vec<f32>` float arrays
///   - Required by SurrealDB's `vector::similarity::cosine()` function
///   - Enables native vector operations without conversion overhead
///
/// ## Conversion Points
///
/// **Write Path** (Vec<u8> â†’ Vec<f32>):
/// - `create_node()`: Lines 568-569 via `blob_to_f32_array()`
/// - `update_node()`: Lines 676-681 via `blob_to_f32_array()`
/// - `update_embedding()`: Lines 1335-1336 via `blob_to_f32_array()`
///
/// **Read Path** (Vec<f32> â†’ Vec<u8>):
/// - `From<SurrealNode> for Node`: Lines 98-103 via `f32::to_le_bytes()`
///
/// This dual representation optimizes for both external compatibility (binary blobs)
/// and internal query performance (native f32 arrays).
///
/// All new fields use `#[serde(default)]` to maintain backward compatibility with
/// existing database records that don't have these fields.
#[derive(Debug, Clone, Serialize, Deserialize)]
struct SurrealNode {
    uuid: String,
    node_type: String,
    content: String,
    parent_id: Option<String>,
    container_node_id: Option<String>,
    before_sibling_id: Option<String>,
    version: i64,
    created_at: String,
    modified_at: String,
    properties: Value,
    #[serde(default)]
    embedding_vector: Option<Vec<f32>>,
    #[serde(default)]
    embedding_stale: bool,
    #[serde(default)]
    mentions: Vec<String>,
    #[serde(default)]
    mentioned_by: Vec<String>,
    // Phase 1 fields (Issue #511) - all use #[serde(default)] for backward compatibility
    #[serde(default)]
    data: Option<String>, // Record link to type-specific table (e.g., "task:uuid")
    #[serde(default)]
    variants: Value, // Type history map {task: "task:uuid", text: null}
    #[serde(default)]
    _schema_version: i64, // Universal schema version (default: 1)
}

impl From<SurrealNode> for Node {
    fn from(sn: SurrealNode) -> Self {
        // Convert f32 vector back to binary blob (Vec<u8>) for Node struct
        let embedding_vector = sn.embedding_vector.map(|floats| {
            floats
                .iter()
                .flat_map(|f| f.to_le_bytes())
                .collect::<Vec<u8>>()
        });

        Node {
            id: sn.uuid,
            node_type: sn.node_type,
            content: sn.content,
            parent_id: sn.parent_id,
            container_node_id: sn.container_node_id,
            before_sibling_id: sn.before_sibling_id,
            version: sn.version,
            created_at: DateTime::parse_from_rfc3339(&sn.created_at)
                .map(|dt| dt.with_timezone(&Utc))
                .unwrap_or_else(|_| Utc::now()),
            modified_at: DateTime::parse_from_rfc3339(&sn.modified_at)
                .map(|dt| dt.with_timezone(&Utc))
                .unwrap_or_else(|_| Utc::now()),
            properties: sn.properties,
            embedding_vector,
            mentions: sn.mentions,
            mentioned_by: sn.mentioned_by,
        }
    }
}

/// SurrealStore implements NodeStore trait for SurrealDB backend
///
/// Supports two connection modes:
/// - **Embedded RocksDB**: Desktop production mode (Surreal<Db>)
/// - **HTTP Client**: Dev-proxy mode (Surreal<Client>)
///
/// Uses hybrid dual-table architecture for optimal query performance.
pub struct SurrealStore<C = Db>
where
    C: surrealdb::Connection,
{
    /// SurrealDB connection
    db: Arc<Surreal<C>>,
}

/// Type alias for embedded RocksDB store
pub type EmbeddedStore = SurrealStore<Db>;

/// Type alias for HTTP client store
pub type HttpStore = SurrealStore<Client>;

impl SurrealStore<Db> {
    /// Create a new SurrealStore with embedded RocksDB backend
    ///
    /// # Arguments
    ///
    /// * `db_path` - Path to RocksDB database directory
    ///
    /// # Returns
    ///
    /// Initialized SurrealStore with schema setup complete
    ///
    /// # Errors
    ///
    /// Returns error if:
    /// - Database path is invalid
    /// - RocksDB initialization fails
    /// - Schema initialization fails
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// # use nodespace_core::db::SurrealStore;
    /// # use std::path::PathBuf;
    /// # #[tokio::main]
    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// let store = SurrealStore::new(PathBuf::from("./data/surreal.db")).await?;
    /// # Ok(())
    /// # }
    /// ```
    pub async fn new(db_path: PathBuf) -> Result<Self> {
        // Initialize embedded RocksDb
        let db = Surreal::new::<RocksDb>(db_path)
            .await
            .context("Failed to initialize SurrealDB with RocksDB backend")?;

        // Use namespace and database
        db.use_ns("nodespace")
            .use_db("nodes")
            .await
            .context("Failed to set namespace/database")?;

        let db = Arc::new(db);

        // Initialize schema (create tables)
        Self::initialize_schema(&db).await?;

        // Seed core schemas (create schema nodes)
        Self::seed_core_schemas(&db).await?;

        Ok(Self { db })
    }
}

impl SurrealStore<Client> {
    /// Create HTTP client store for dev-proxy mode
    ///
    /// This connects to a remote SurrealDB server via HTTP API.
    /// Used by dev-proxy to enable Surrealist inspection while preserving business logic.
    ///
    /// # Arguments
    ///
    /// * `endpoint` - SurrealDB server address (e.g., "127.0.0.1:8000")
    /// * `namespace` - Database namespace (e.g., "nodespace")
    /// * `database` - Database name (e.g., "nodes")
    /// * `username` - Auth username (e.g., "root")
    /// * `password` - Auth password (e.g., "root")
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// use nodespace_core::db::SurrealStore;
    ///
    /// #[tokio::main]
    /// async fn main() -> anyhow::Result<()> {
    ///     let store = SurrealStore::new_http(
    ///         "127.0.0.1:8000",
    ///         "nodespace",
    ///         "nodes",
    ///         "root",
    ///         "root"
    ///     ).await?;
    ///
    ///     // Use store normally - same API as embedded mode
    ///     let node = store.get_node("some-id").await?;
    ///
    ///     Ok(())
    /// }
    /// ```
    pub async fn new_http(
        endpoint: &str,
        namespace: &str,
        database: &str,
        username: &str,
        password: &str,
    ) -> Result<Self> {
        tracing::info!("Connecting to SurrealDB HTTP server at {}", endpoint);

        // Create HTTP client connection to remote SurrealDB server
        let db = Surreal::new::<Http>(endpoint)
            .await
            .context("Failed to connect to SurrealDB HTTP server")?;

        // Authenticate with root credentials
        db.signin(Root { username, password })
            .await
            .context("Failed to authenticate with SurrealDB")?;

        // Set namespace and database
        db.use_ns(namespace)
            .use_db(database)
            .await
            .context("Failed to set namespace/database")?;

        let db = Arc::new(db);

        // IMPORTANT: Do NOT call initialize_schema() or seed_core_schemas()
        // In HTTP mode, the server should already be initialized.
        // Calling these would try to recreate tables/schemas.
        tracing::info!("âœ… Connected to SurrealDB HTTP server");

        Ok(Self { db })
    }
}

impl<C> SurrealStore<C>
where
    C: surrealdb::Connection,
{
    /// Initialize database schema (universal node table + core type tables)
    ///
    /// Creates SCHEMALESS tables for flexible property handling while maintaining
    /// core field structure.
    ///
    /// # Phase 1 (Issue #511)
    /// - Table name: `node` (singular, consistent naming)
    /// - New fields: data, variants, _schema_version (initialized on creation)
    async fn initialize_schema(db: &Arc<Surreal<Db>>) -> Result<()> {
        // Universal node table (singular) - SCHEMALESS for maximum flexibility
        db.query(
            "
            DEFINE TABLE IF NOT EXISTS node SCHEMALESS;
            ",
        )
        .await
        .context("Failed to create universal node table")?;

        // Core type tables - SCHEMALESS for user extensibility
        let core_types = [
            "task",
            "text",
            "date",
            "header",
            "code_block",
            "quote_block",
            "ordered_list",
        ];

        for node_type in core_types {
            db.query(format!(
                "DEFINE TABLE IF NOT EXISTS {} SCHEMALESS;",
                node_type
            ))
            .await
            .with_context(|| format!("Failed to create {} table", node_type))?;
        }

        // Mentions table for reference graph
        db.query(
            "
            DEFINE TABLE IF NOT EXISTS mentions SCHEMALESS TYPE RELATION;
            ",
        )
        .await
        .context("Failed to create mentions table")?;

        // Phase 3 (Issue #511): has_child graph edges for hierarchy
        // RELATE table for parent->child relationships
        // Replaces parent_id field-based queries with graph traversal
        db.query(
            "
            DEFINE TABLE IF NOT EXISTS has_child SCHEMALESS TYPE RELATION;
            ",
        )
        .await
        .context("Failed to create has_child relation table")?;

        // Phase 3 (Issue #511): Critical indexes for graph traversal performance
        // Without these, traversal is O(nÂ²) - WITH them it's O(1) for parent/child lookups
        db.query(
            "
            DEFINE INDEX IF NOT EXISTS idx_has_child_in ON has_child FIELDS in;
            DEFINE INDEX IF NOT EXISTS idx_has_child_out ON has_child FIELDS out;
            ",
        )
        .await
        .context("Failed to create has_child indexes")?;

        Ok(())
    }

    /// Seed core schema definitions as nodes
    ///
    /// Creates schema nodes (node_type = "schema") with schema definitions
    /// stored in properties. Checks for existing schemas to be idempotent.
    async fn seed_core_schemas(db: &Arc<Surreal<Db>>) -> Result<()> {
        use serde_json::json;

        // Check if schemas already exist by trying to get one
        // If any schema exists, assume all are seeded (they're created atomically)
        // Phase 4 (Issue #511): Use record ID for schema lookup
        let task_exists = db
            .query("SELECT * FROM type::thing('node', 'task') LIMIT 1")
            .await
            .context("Failed to check for existing schemas")?
            .take::<Option<SurrealNode>>(0)
            .ok()
            .flatten()
            .is_some();

        if task_exists {
            tracing::info!("âœ… Core schemas already seeded");
            return Ok(());
        }

        tracing::info!("ðŸŒ± Seeding core schemas...");

        // Create temporary SurrealStore to use create_node method
        let store = SurrealStore::<Db> { db: Arc::clone(db) };

        let now = Utc::now();

        // Task schema
        let task_node = Node {
            id: "task".to_string(),
            node_type: "schema".to_string(),
            content: "Task".to_string(),
            parent_id: None,
            container_node_id: None,
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Task tracking schema",
                "fields": [
                    {
                        "name": "status",
                        "type": "enum",
                        "protection": "core",
                        "core_values": ["OPEN", "IN_PROGRESS", "DONE"],
                        "user_values": [],
                        "indexed": true,
                        "required": true,
                        "extensible": true,
                        "default": "OPEN",
                        "description": "Task status"
                    },
                    {
                        "name": "priority",
                        "type": "enum",
                        "protection": "user",
                        "core_values": ["LOW", "MEDIUM", "HIGH"],
                        "user_values": [],
                        "indexed": true,
                        "required": false,
                        "extensible": true,
                        "description": "Task priority"
                    },
                    {
                        "name": "due_date",
                        "type": "date",
                        "protection": "user",
                        "indexed": true,
                        "required": false,
                        "description": "Due date"
                    },
                    {
                        "name": "started_at",
                        "type": "date",
                        "protection": "user",
                        "indexed": false,
                        "required": false,
                        "description": "Started at"
                    },
                    {
                        "name": "completed_at",
                        "type": "date",
                        "protection": "user",
                        "indexed": false,
                        "required": false,
                        "description": "Completed at"
                    },
                    {
                        "name": "assignee",
                        "type": "text",
                        "protection": "user",
                        "indexed": true,
                        "required": false,
                        "description": "Assignee"
                    }
                ]
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(task_node).await?;

        // Date schema
        let date_node = Node {
            id: "date".to_string(),
            node_type: "schema".to_string(),
            content: "Date".to_string(),
            parent_id: None,
            container_node_id: None,
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Date node schema",
                "fields": []
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(date_node).await?;

        // Text schema
        let text_node = Node {
            id: "text".to_string(),
            node_type: "schema".to_string(),
            content: "Text".to_string(),
            parent_id: None,
            container_node_id: None,
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Plain text content",
                "fields": []
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(text_node).await?;

        // Header schema
        let header_node = Node {
            id: "header".to_string(),
            node_type: "schema".to_string(),
            content: "Header".to_string(),
            parent_id: None,
            container_node_id: None,
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Markdown header (h1-h6)",
                "fields": []
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(header_node).await?;

        // Code block schema
        let code_block_node = Node {
            id: "code-block".to_string(),
            node_type: "schema".to_string(),
            content: "Code Block".to_string(),
            parent_id: None,
            container_node_id: None,
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Code block with syntax highlighting",
                "fields": []
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(code_block_node).await?;

        // Quote block schema
        let quote_block_node = Node {
            id: "quote-block".to_string(),
            node_type: "schema".to_string(),
            content: "Quote Block".to_string(),
            parent_id: None,
            container_node_id: None,
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Blockquote for citations",
                "fields": []
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(quote_block_node).await?;

        // Ordered list schema
        let ordered_list_node = Node {
            id: "ordered-list".to_string(),
            node_type: "schema".to_string(),
            content: "Ordered List".to_string(),
            parent_id: None,
            container_node_id: None,
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Numbered list item",
                "fields": []
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(ordered_list_node).await?;

        tracing::info!("âœ… Core schemas seeded successfully");

        Ok(())
    }

    /// Convert Turso-style ID to SurrealDB Record ID format
    ///
    /// Turso IDs are plain UUIDs. SurrealDB uses `table:uuid` format.
    /// This method extracts the type from the node and constructs the Record ID.
    ///
    /// # Arguments
    ///
    /// * `node_type` - The node type (becomes table name)
    /// * `id` - The UUID portion
    ///
    /// # Returns
    ///
    /// SurrealDB Record ID string: `table:uuid`
    fn to_record_id(node_type: &str, id: &str) -> String {
        format!("{}:{}", node_type, id)
    }

    /// Parse SurrealDB Record ID into (table, uuid) components
    ///
    /// # Arguments
    ///
    /// * `record_id` - SurrealDB Record ID (e.g., "task:uuid")
    ///
    /// # Returns
    ///
    /// Tuple of (table_name, uuid_portion)
    #[allow(dead_code)]
    fn parse_record_id(record_id: &str) -> Result<(String, String)> {
        let parts: Vec<&str> = record_id.splitn(2, ':').collect();
        if parts.len() != 2 {
            return Err(anyhow::anyhow!(
                "Invalid Record ID format: {}. Expected 'table:uuid'",
                record_id
            ));
        }
        Ok((parts[0].to_string(), parts[1].to_string()))
    }
}

impl<C> SurrealStore<C>
where
    C: surrealdb::Connection,
{
    /// Convert binary blob embedding to f32 array for SurrealDB vector functions
    ///
    /// Embeddings are stored as Vec<u8> (bytes), but SurrealDB vector functions
    /// require Vec<f32>. This performs the conversion.
    ///
    /// # Arguments
    /// * `blob` - Binary embedding data (384 dimensions * 4 bytes = 1536 bytes)
    ///
    /// # Returns
    /// Vec<f32> with 384 elements
    ///
    /// # Errors
    /// Returns error if blob length is not divisible by 4 (invalid f32 encoding)
    fn blob_to_f32_array(blob: &[u8]) -> Result<Vec<f32>> {
        if !blob.len().is_multiple_of(4) {
            return Err(anyhow::anyhow!(
                "Invalid embedding blob: length {} not divisible by 4",
                blob.len()
            ));
        }

        let float_count = blob.len() / 4;
        let mut floats = Vec::with_capacity(float_count);

        for chunk in blob.chunks_exact(4) {
            let bytes: [u8; 4] = chunk.try_into().unwrap();
            floats.push(f32::from_le_bytes(bytes));
        }

        Ok(floats)
    }

    /// Phase 3 (Issue #511): Validate that adding a child doesn't create a cycle
    ///
    /// Checks if `parent_id` is a descendant of `child_id` by traversing
    /// the has_child graph edges recursively.
    ///
    /// # Arguments
    /// * `parent_id` - ID of the node that will become the parent
    /// * `child_id` - ID of the node that will become the child
    ///
    /// # Returns
    /// * `Ok(())` if no cycle would be created
    /// * `Err` if adding this relationship would create a cycle
    ///
    /// # Example Cycle
    /// ```text
    /// A -> B -> C (existing edges)
    /// Trying to add: C -> A  (would create cycle A->B->C->A)
    /// ```
    async fn validate_no_cycle(&self, parent_id: &str, child_id: &str) -> Result<()> {
        // Query: Check if parent is a descendant of child (would create cycle)
        // Uses recursive graph traversal via ->has_child-> edges
        let query = r#"
            SELECT id FROM node:âŸ¨$parent_idâŸ©
            WHERE id IN (
                SELECT ->has_child->node.*.id FROM node:âŸ¨$child_idâŸ©
            )
            LIMIT 1;
        "#;

        let mut response = self
            .db
            .query(query)
            .bind(("parent_id", parent_id.to_string()))
            .bind(("child_id", child_id.to_string()))
            .await?;

        let result: Vec<Value> = response.take(0)?;

        if !result.is_empty() {
            return Err(anyhow::anyhow!(
                "Cannot add child {} to parent {} - would create cycle",
                child_id,
                parent_id
            ));
        }

        Ok(())
    }

    pub async fn create_node(&self, node: Node) -> Result<Node> {
        // Generate SurrealDB Record ID
        let record_id = Self::to_record_id(&node.node_type, &node.id);

        // Convert embedding blob to f32 array if present
        let embedding_f32 = node
            .embedding_vector
            .as_ref()
            .map(|blob| Self::blob_to_f32_array(blob))
            .transpose()?;

        // Insert into universal node table
        let query = "
            CREATE type::thing($table, $id) CONTENT {
                uuid: $uuid,
                node_type: $node_type,
                content: $content,
                parent_id: $parent_id,
                container_node_id: $container_node_id,
                before_sibling_id: $before_sibling_id,
                version: $version,
                created_at: $created_at,
                modified_at: $modified_at,
                properties: $properties,
                embedding_vector: $embedding_vector,
                data: $data,
                variants: $variants,
                _schema_version: $_schema_version
            };
        ";

        // Phase 1 (Issue #511): Initialize new fields
        // - data: Will be set when creating type-specific record (if properties exist)
        // - variants: Empty object {} for new nodes
        // - _schema_version: Default to 1
        let variants_value = serde_json::json!({});

        self.db
            .query(query)
            .bind(("table", "node"))
            .bind(("id", record_id.clone()))
            .bind(("uuid", node.id.clone()))
            .bind(("node_type", node.node_type.clone()))
            .bind(("content", node.content.clone()))
            .bind(("parent_id", node.parent_id.clone()))
            .bind(("container_node_id", node.container_node_id.clone()))
            .bind(("before_sibling_id", node.before_sibling_id.clone()))
            .bind(("version", node.version))
            .bind(("created_at", node.created_at.to_rfc3339()))
            .bind(("modified_at", node.modified_at.to_rfc3339()))
            .bind(("properties", node.properties.clone()))
            .bind(("embedding_vector", embedding_f32))
            .bind(("data", None::<String>)) // Will be set below if type has properties
            .bind(("variants", variants_value))
            .bind(("_schema_version", 1i64))
            .await
            .context("Failed to create node in universal table")?;

        // Insert into type-specific table (if properties exist)
        if !node
            .properties
            .as_object()
            .unwrap_or(&serde_json::Map::new())
            .is_empty()
        {
            // Phase 2 (Issue #511): Store properties directly (flattened)
            // Do NOT add uuid or _schema_version - those belong in node table only
            let props = node.properties.clone();

            self.db
                .query("CREATE type::thing($table, $id) CONTENT $properties;")
                .bind(("table", node.node_type.clone()))
                .bind(("id", node.id.clone()))
                .bind(("properties", props))
                .await
                .context("Failed to create node in type-specific table")?;

            // Phase 1 (Issue #511): Set data field to link to type-specific record
            // Use record ID directly instead of WHERE clause for better performance
            self.db
                .query("UPDATE type::thing('node', $id) SET data = type::thing($type_table, $id);")
                .bind(("id", node.id.clone()))
                .bind(("type_table", node.node_type.clone()))
                .await
                .context("Failed to set data link")?;
        }

        // Phase 3 (Issue #511): Create has_child graph edge if parent_id is set
        // This creates a bidirectional edge: parent->has_child->child
        // Dual-mode: Both parent_id field AND graph edge exist for gradual migration
        if let Some(parent_id) = &node.parent_id {
            // Validate no cycle before creating edge
            self.validate_no_cycle(parent_id, &node.id).await?;

            self.db
                .query("RELATE type::thing('node', $parent_id)->has_child->type::thing('node', $child_id);")
                .bind(("parent_id", parent_id.clone()))
                .bind(("child_id", node.id.clone()))
                .await
                .context("Failed to create has_child graph edge")?;
        }

        // Return the created node directly (avoids triggering backfill/migration during creation)
        // The node was successfully created with the values provided, so we can return it as-is
        Ok(node)
    }

    /// Phase 3 (Issue #511): Create has_child edges for all existing parent-child relationships
    ///
    /// Migration helper to backfill graph edges for nodes created before Phase 3.
    /// Reads all nodes with parent_id and creates corresponding has_child edges.
    ///
    /// **IMPORTANT**: This is dual-mode migration - both parent_id field AND graph edges exist.
    /// The parent_id field will be removed in Phase 5 after all queries are updated.
    ///
    /// # Returns
    /// Number of edges created
    ///
    /// # Example Usage
    /// ```rust,no_run
    /// # use nodespace_core::db::SurrealStore;
    /// # use std::path::PathBuf;
    /// # #[tokio::main]
    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// let store = SurrealStore::new(PathBuf::from("./data/surreal.db")).await?;
    /// let count = store.create_has_child_edges_for_existing_nodes().await?;
    /// println!("Created {} has_child edges", count);
    /// # Ok(())
    /// # }
    /// ```
    pub async fn create_has_child_edges_for_existing_nodes(&self) -> Result<usize> {
        // Get all nodes with parents (where parent_id is not null)
        let query = "SELECT uuid, parent_id FROM node WHERE parent_id IS NOT NONE;";
        let mut response = self.db.query(query).await?;
        let nodes: Vec<SurrealNode> = response.take(0)?;

        tracing::info!(
            "Creating has_child edges for {} existing parent-child relationships",
            nodes.len()
        );

        let mut edges_created = 0;

        for node in nodes {
            if let Some(parent_id) = node.parent_id {
                // Create has_child edge (parent->has_child->child)
                // Note: We skip cycle validation here because existing relationships
                // are assumed to be valid (cycles shouldn't exist in parent_id field structure)
                self.db
                    .query("RELATE type::thing('node', $parent_id)->has_child->type::thing('node', $child_id);")
                    .bind(("parent_id", parent_id))
                    .bind(("child_id", node.uuid))
                    .await
                    .context("Failed to create has_child edge during migration")?;

                edges_created += 1;

                if edges_created % 100 == 0 {
                    tracing::info!("Created {} has_child edges...", edges_created);
                }
            }
        }

        tracing::info!("âœ… Created {} has_child edges successfully", edges_created);
        Ok(edges_created)
    }

    pub async fn get_node(&self, id: &str) -> Result<Option<Node>> {
        // Phase 4 (Issue #511): Direct record ID lookup (O(1) primary key access)
        // Uses SurrealDB record ID: node:âŸ¨uuidâŸ©
        // FETCH data: Hydrates the record link in the 'data' field
        let query = "SELECT * FROM type::thing('node', $id) FETCH data;";
        let mut response = self
            .db
            .query(query)
            .bind(("id", id.to_string()))
            .await
            .context("Failed to query node by record ID")?;

        let surreal_nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract query results")?;

        Ok(surreal_nodes.into_iter().map(Into::into).next())
    }

    pub async fn update_node(&self, id: &str, update: NodeUpdate) -> Result<Node> {
        // Fetch current node
        let current = self
            .get_node(id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Node not found: {}", id))?;

        // Phase 4 (Issue #511): Update using record ID (O(1) primary key access)
        let query = "
            UPDATE type::thing('node', $id) SET
                content = $content,
                node_type = $node_type,
                parent_id = $parent_id,
                container_node_id = $container_node_id,
                before_sibling_id = $before_sibling_id,
                modified_at = time::now(),
                version = version + 1,
                properties = $properties,
                embedding_vector = $embedding_vector;
        ";

        let updated_content = update.content.unwrap_or(current.content);
        let updated_node_type = update.node_type.unwrap_or(current.node_type.clone());
        let updated_properties = update.properties.unwrap_or(current.properties.clone());

        // Convert embedding blob to f32 if provided
        let embedding_f32 = update
            .embedding_vector
            .flatten()
            .as_ref()
            .map(|blob| Self::blob_to_f32_array(blob))
            .transpose()?;

        self.db
            .query(query)
            .bind(("id", id.to_string()))
            .bind(("content", updated_content))
            .bind(("node_type", updated_node_type))
            .bind(("parent_id", update.parent_id.flatten()))
            .bind(("container_node_id", update.container_node_id.flatten()))
            .bind(("before_sibling_id", update.before_sibling_id.flatten()))
            .bind(("properties", updated_properties))
            .bind(("embedding_vector", embedding_f32))
            .await
            .context("Failed to update node")?;

        // Fetch and return updated node
        self.get_node(id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Node not found after update"))
    }

    /// Update a node with version check (optimistic locking)
    ///
    /// Only updates the node if its version matches the expected version.
    /// This provides atomic version-checked updates to prevent lost updates
    /// in concurrent scenarios.
    ///
    /// # Arguments
    ///
    /// * `id` - Node UUID to update
    /// * `expected_version` - Expected current version (for optimistic locking)
    /// * `update` - Fields to update
    ///
    /// # Returns
    ///
    /// * `Ok(Some(Node))` - Update succeeded, returns updated node
    /// * `Ok(None)` - Version mismatch, no update performed
    /// * `Err(_)` - Database error or node not found
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// # use nodespace_core::db::SurrealStore;
    /// # use nodespace_core::models::NodeUpdate;
    /// # use std::path::PathBuf;
    /// # #[tokio::main]
    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// # let store = SurrealStore::new(PathBuf::from("./data/surreal.db")).await?;
    /// let update = NodeUpdate {
    ///     content: Some("Updated content".to_string()),
    ///     ..Default::default()
    /// };
    ///
    /// match store.update_node_with_version_check("node-id", 5, update).await? {
    ///     Some(node) => println!("Updated to version {}", node.version),
    ///     None => println!("Version mismatch - node was modified by another process"),
    /// }
    /// # Ok(())
    /// # }
    /// ```
    pub async fn update_node_with_version_check(
        &self,
        id: &str,
        expected_version: i64,
        update: NodeUpdate,
    ) -> Result<Option<Node>> {
        // Fetch current node to build update values
        let current = self
            .get_node(id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Node not found: {}", id))?;

        // Phase 4 (Issue #511): Atomic update with version check using record ID
        // SurrealDB's UPDATE returns the updated records
        let query = "
            UPDATE type::thing('node', $id) SET
                content = $content,
                node_type = $node_type,
                parent_id = $parent_id,
                container_node_id = $container_node_id,
                before_sibling_id = $before_sibling_id,
                modified_at = time::now(),
                version = version + 1,
                properties = $properties,
                embedding_vector = $embedding_vector
            WHERE version = $expected_version
            RETURN AFTER;
        ";

        let updated_content = update.content.unwrap_or(current.content);
        let updated_node_type = update.node_type.unwrap_or(current.node_type.clone());
        let updated_properties = update.properties.unwrap_or(current.properties.clone());

        // Convert embedding blob to f32 if provided
        let embedding_f32 = update
            .embedding_vector
            .flatten()
            .as_ref()
            .map(|blob| Self::blob_to_f32_array(blob))
            .transpose()?;

        let mut response = self
            .db
            .query(query)
            .bind(("id", id.to_string()))
            .bind(("expected_version", expected_version))
            .bind(("content", updated_content))
            .bind(("node_type", updated_node_type))
            .bind(("parent_id", update.parent_id.flatten()))
            .bind(("container_node_id", update.container_node_id.flatten()))
            .bind(("before_sibling_id", update.before_sibling_id.flatten()))
            .bind(("properties", updated_properties))
            .bind(("embedding_vector", embedding_f32))
            .await
            .context("Failed to update node with version check")?;

        // Extract updated nodes from response
        let updated_nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract update results")?;

        // If no nodes were updated, version mismatch occurred
        if updated_nodes.is_empty() {
            return Ok(None);
        }

        // Convert and return the updated node
        Ok(Some(updated_nodes.into_iter().next().unwrap().into()))
    }

    pub async fn delete_node(&self, id: &str) -> Result<DeleteResult> {
        // Get node to determine type for Record ID
        let node = match self.get_node(id).await? {
            Some(n) => n,
            None => return Ok(DeleteResult { existed: false }),
        };

        // Phase 4 (Issue #511): Delete using record IDs and graph edges
        // Use transaction for atomicity (all or nothing)
        let transaction_query = "
            BEGIN TRANSACTION;
            DELETE type::thing($table, $id);
            DELETE type::thing('node', $id);
            DELETE mentions WHERE in = type::thing('node', $id) OR out = type::thing('node', $id);
            DELETE has_child WHERE in = type::thing('node', $id) OR out = type::thing('node', $id);
            COMMIT TRANSACTION;
        ";

        self.db
            .query(transaction_query)
            .bind(("table", node.node_type.clone()))
            .bind(("id", node.id.clone()))
            .await
            .context("Failed to delete node and relations")?;

        Ok(DeleteResult { existed: true })
    }

    /// Delete a node with version check (optimistic locking)
    ///
    /// Only deletes the node if its version matches the expected version.
    /// Returns the number of rows affected (0 if version mismatch, 1 if deleted).
    pub async fn delete_with_version_check(
        &self,
        id: &str,
        expected_version: i64,
    ) -> Result<usize> {
        // First get the node to check version
        let node = match self.get_node(id).await? {
            Some(n) => n,
            None => return Ok(0), // Node doesn't exist
        };

        // Check version match
        if node.version != expected_version {
            return Ok(0); // Version mismatch, no deletion
        }

        // Version matches, proceed with deletion
        let result = self.delete_node(id).await?;
        Ok(if result.existed { 1 } else { 0 })
    }

    pub async fn query_nodes(&self, query: NodeQuery) -> Result<Vec<Node>> {
        // Handle mentioned_by query using graph traversal
        if let Some(ref mentioned_node_id) = query.mentioned_by {
            // Get the mentioned node to construct proper Record ID
            let mentioned_node = self
                .get_node(mentioned_node_id)
                .await?
                .ok_or_else(|| anyhow::anyhow!("Target node not found: {}", mentioned_node_id))?;

            let record_id = Self::to_record_id(&mentioned_node.node_type, &mentioned_node.id);
            let thing = Thing::from(("nodes", Id::String(record_id)));

            // Query nodes that have mentions pointing to this node
            let sql = if query.limit.is_some() {
                "SELECT VALUE in FROM mentions WHERE out = $target_thing LIMIT $limit;"
            } else {
                "SELECT VALUE in FROM mentions WHERE out = $target_thing;"
            };

            let mut query_builder = self.db.query(sql).bind(("target_thing", thing));

            if let Some(limit) = query.limit {
                query_builder = query_builder.bind(("limit", limit));
            }

            let mut response = query_builder
                .await
                .context("Failed to query mentioned_by nodes")?;

            let source_things: Vec<Thing> = response
                .take(0)
                .context("Failed to extract source nodes from mentions")?;

            // Fetch full node records for each source
            let mut nodes = Vec::new();
            for thing in source_things {
                if let Id::String(id_str) = &thing.id {
                    // Extract UUID from "node_type:uuid" format
                    if let Some(uuid) = id_str.split(':').nth(1) {
                        if let Some(node) = self.get_node(uuid).await? {
                            nodes.push(node);
                        }
                    }
                }
            }

            // Apply include_containers_and_tasks filter if specified
            // Phase 4 (Issue #511): Check parent_id instead of container_node_id
            // (parent_id still exists during dual-mode migration, will be removed in Phase 5)
            if let Some(true) = query.include_containers_and_tasks {
                nodes.retain(|n| n.node_type == "task" || n.parent_id.is_none());
            }

            return Ok(nodes);
        }

        // Handle content_contains query
        if let Some(ref search_query) = query.content_contains {
            let mut nodes = self
                .search_nodes_by_content(search_query, query.limit.map(|l| l as i64))
                .await?;

            // Apply include_containers_and_tasks filter if specified
            // Phase 4 (Issue #511): Check parent_id instead of container_node_id
            // (parent_id still exists during dual-mode migration, will be removed in Phase 5)
            if let Some(true) = query.include_containers_and_tasks {
                nodes.retain(|n| n.node_type == "task" || n.parent_id.is_none());
            }

            return Ok(nodes);
        }

        // Build WHERE clause conditions
        let mut conditions = Vec::new();

        if query.node_type.is_some() {
            conditions.push("node_type = $node_type".to_string());
        }

        if let Some(true) = query.include_containers_and_tasks {
            // Phase 4 (Issue #511): Include tasks OR root nodes (no incoming has_child edges)
            conditions.push("(node_type = 'task' OR !EXISTS(<-has_child<-node))".to_string());
        }

        // Build SQL query
        let where_clause = if !conditions.is_empty() {
            Some(conditions.join(" AND "))
        } else {
            None
        };

        let sql = match (&where_clause, query.limit) {
            (None, None) => "SELECT * FROM node;".to_string(),
            (None, Some(_)) => "SELECT * FROM node LIMIT $limit;".to_string(),
            (Some(clause), None) => format!("SELECT * FROM node WHERE {};", clause),
            (Some(clause), Some(_)) => {
                format!("SELECT * FROM node WHERE {} LIMIT $limit;", clause)
            }
        };

        let mut query_builder = self.db.query(sql);

        if let Some(node_type) = &query.node_type {
            query_builder = query_builder.bind(("node_type", node_type.clone()));
        }

        if let Some(limit) = query.limit {
            query_builder = query_builder.bind(("limit", limit));
        }

        let mut response = query_builder.await.context("Failed to query nodes")?;
        let surreal_nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract nodes from query response")?;
        Ok(surreal_nodes.into_iter().map(Into::into).collect())
    }

    pub async fn get_children(&self, parent_id: Option<&str>) -> Result<Vec<Node>> {
        // Phase 4 (Issue #511): Use graph edges for hierarchy traversal
        let (query, has_parent) = if parent_id.is_some() {
            // Query children using has_child graph edge
            // FETCH data: Hydrates the record link in the 'data' field
            ("SELECT ->has_child->node.* FROM type::thing('node', $parent_id) FETCH data ORDER BY before_sibling_id;", true)
        } else {
            // Root nodes: nodes that have NO incoming has_child edges
            ("SELECT * FROM node WHERE !EXISTS(<-has_child<-node) FETCH data ORDER BY before_sibling_id;", false)
        };

        let mut query_builder = self.db.query(query);

        if has_parent {
            query_builder = query_builder.bind(("parent_id", parent_id.unwrap().to_string()));
        }

        let mut response = query_builder.await.context("Failed to get children")?;
        let surreal_nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract children from response")?;
        Ok(surreal_nodes.into_iter().map(Into::into).collect())
    }

    pub async fn get_nodes_by_container(&self, container_id: &str) -> Result<Vec<Node>> {
        let query = "SELECT * FROM node WHERE container_node_id = $container_id;";
        let mut response = self
            .db
            .query(query)
            .bind(("container_id", container_id.to_string()))
            .await
            .context("Failed to get nodes by container")?;

        let surreal_nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract nodes by container from response")?;
        Ok(surreal_nodes.into_iter().map(Into::into).collect())
    }

    pub async fn search_nodes_by_content(
        &self,
        search_query: &str,
        limit: Option<i64>,
    ) -> Result<Vec<Node>> {
        let sql = if limit.is_some() {
            "SELECT * FROM node WHERE content CONTAINS $search_query LIMIT $limit;"
        } else {
            "SELECT * FROM node WHERE content CONTAINS $search_query;"
        };

        let mut query_builder = self
            .db
            .query(sql)
            .bind(("search_query", search_query.to_string()));

        if let Some(lim) = limit {
            query_builder = query_builder.bind(("limit", lim));
        }

        let mut response = query_builder.await.context("Failed to search nodes")?;
        let surreal_nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract search results from response")?;
        Ok(surreal_nodes.into_iter().map(Into::into).collect())
    }

    pub async fn move_node(&self, id: &str, new_parent_id: Option<&str>) -> Result<()> {
        // Phase 4 (Issue #511): Update using record ID
        self.db
            .query("UPDATE type::thing('node', $id) SET parent_id = $parent_id;")
            .bind(("id", id.to_string()))
            .bind(("parent_id", new_parent_id.map(|s| s.to_string())))
            .await
            .context("Failed to move node")?;

        Ok(())
    }

    pub async fn reorder_node(&self, id: &str, new_before_sibling_id: Option<&str>) -> Result<()> {
        // Phase 4 (Issue #511): Update using record ID
        self.db
            .query("UPDATE type::thing('node', $id) SET before_sibling_id = $before_sibling_id;")
            .bind(("id", id.to_string()))
            .bind((
                "before_sibling_id",
                new_before_sibling_id.map(|s| s.to_string()),
            ))
            .await
            .context("Failed to reorder node")?;

        Ok(())
    }

    pub async fn create_mention(
        &self,
        source_id: &str,
        target_id: &str,
        container_id: &str,
    ) -> Result<()> {
        // Get node types to construct proper Record IDs
        let source_node = self
            .get_node(source_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Source node not found: {}", source_id))?;
        let target_node = self
            .get_node(target_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Target node not found: {}", target_id))?;

        // Construct Thing objects for proper Record ID binding
        let source_record_id = Self::to_record_id(&source_node.node_type, &source_node.id);
        let target_record_id = Self::to_record_id(&target_node.node_type, &target_node.id);

        let source_thing = Thing::from(("nodes", Id::String(source_record_id)));
        let target_thing = Thing::from(("nodes", Id::String(target_record_id)));

        // Check if mention already exists (for idempotency)
        let check_query = "SELECT VALUE id FROM mentions WHERE in = $source AND out = $target;";
        let mut check_response = self
            .db
            .query(check_query)
            .bind(("source", source_thing.clone()))
            .bind(("target", target_thing.clone()))
            .await
            .context("Failed to check for existing mention")?;

        let existing_mention_ids: Vec<Thing> = check_response
            .take(0)
            .context("Failed to extract mention check results")?;

        // Only create mention if it doesn't exist
        if existing_mention_ids.is_empty() {
            // RELATE statement using Thing objects
            let query =
                "RELATE $source->mentions->$target CONTENT { container_id: $container_id };";

            self.db
                .query(query)
                .bind(("source", source_thing))
                .bind(("target", target_thing))
                .bind(("container_id", container_id.to_string()))
                .await
                .context("Failed to create mention")?;
        }

        Ok(())
    }

    pub async fn delete_mention(&self, source_id: &str, target_id: &str) -> Result<()> {
        // Get node types to construct proper Record IDs
        let source_node = self
            .get_node(source_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Source node not found: {}", source_id))?;
        let target_node = self
            .get_node(target_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Target node not found: {}", target_id))?;

        // Construct Thing objects for proper Record ID binding
        let source_record_id = Self::to_record_id(&source_node.node_type, &source_node.id);
        let target_record_id = Self::to_record_id(&target_node.node_type, &target_node.id);

        let source_thing = Thing::from(("nodes", Id::String(source_record_id)));
        let target_thing = Thing::from(("nodes", Id::String(target_record_id)));

        self.db
            .query("DELETE FROM mentions WHERE in = $source AND out = $target;")
            .bind(("source", source_thing))
            .bind(("target", target_thing))
            .await
            .context("Failed to delete mention")?;

        Ok(())
    }

    pub async fn get_outgoing_mentions(&self, node_id: &str) -> Result<Vec<String>> {
        // Get node type to construct proper Record ID
        let node = self
            .get_node(node_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Node not found: {}", node_id))?;

        // Construct Thing for proper Record ID binding
        let record_id = Self::to_record_id(&node.node_type, &node.id);
        let thing = Thing::from(("nodes", Id::String(record_id)));

        let query = "SELECT out FROM mentions WHERE in = $node_thing;";
        let mut response = self
            .db
            .query(query)
            .bind(("node_thing", thing))
            .await
            .context("Failed to get outgoing mentions")?;

        #[derive(Debug, Deserialize)]
        struct MentionOut {
            out: Thing,
        }

        let results: Vec<MentionOut> = response
            .take(0)
            .context("Failed to extract outgoing mentions from response")?;

        // Extract UUIDs from Thing Record IDs
        // Thing.id is Id::String("node_type:uuid"), so we need to extract just the UUID part
        Ok(results
            .into_iter()
            .filter_map(|m| {
                if let Id::String(id_str) = &m.out.id {
                    // id_str format: "node_type:uuid", extract UUID (after last colon)
                    id_str.split(':').nth(1).map(String::from)
                } else {
                    None
                }
            })
            .collect())
    }

    pub async fn get_incoming_mentions(&self, node_id: &str) -> Result<Vec<String>> {
        // Get node type to construct proper Record ID
        let node = self
            .get_node(node_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Node not found: {}", node_id))?;

        // Construct Thing for proper Record ID binding
        let record_id = Self::to_record_id(&node.node_type, &node.id);
        let thing = Thing::from(("nodes", Id::String(record_id)));

        let query = "SELECT in FROM mentions WHERE out = $node_thing;";
        let mut response = self
            .db
            .query(query)
            .bind(("node_thing", thing))
            .await
            .context("Failed to get incoming mentions")?;

        #[derive(Debug, Deserialize)]
        struct MentionIn {
            #[serde(rename = "in")]
            in_field: Thing,
        }

        let results: Vec<MentionIn> = response
            .take(0)
            .context("Failed to extract incoming mentions from response")?;

        // Extract UUIDs from Thing Record IDs
        Ok(results
            .into_iter()
            .filter_map(|m| {
                if let Id::String(id_str) = &m.in_field.id {
                    // id_str format: "node_type:uuid", extract UUID (after first colon)
                    id_str.split(':').nth(1).map(String::from)
                } else {
                    None
                }
            })
            .collect())
    }

    pub async fn get_mentioning_containers(&self, node_id: &str) -> Result<Vec<Node>> {
        // Get node type to construct proper Record ID
        // If node doesn't exist, return empty array (not an error)
        let node = match self.get_node(node_id).await? {
            Some(n) => n,
            None => return Ok(Vec::new()),
        };

        // Construct Thing for proper Record ID binding
        let record_id = Self::to_record_id(&node.node_type, &node.id);
        let thing = Thing::from(("nodes", Id::String(record_id)));

        let query = "SELECT container_id FROM mentions WHERE out = $node_thing;";
        let mut response = self
            .db
            .query(query)
            .bind(("node_thing", thing))
            .await
            .context("Failed to get mentioning containers")?;

        #[derive(Debug, Deserialize)]
        struct MentionRecord {
            container_id: String,
        }

        let mention_records: Vec<MentionRecord> = response
            .take(0)
            .context("Failed to extract container IDs from response")?;

        // Deduplicate container IDs
        let mut container_ids: Vec<String> = mention_records
            .into_iter()
            .map(|m| m.container_id)
            .collect();
        container_ids.sort();
        container_ids.dedup();

        // Fetch full node records
        let mut nodes = Vec::new();
        for container_id in container_ids {
            if let Some(node) = self.get_node(&container_id).await? {
                nodes.push(node);
            }
        }

        Ok(nodes)
    }

    pub async fn get_schema(&self, node_type: &str) -> Result<Option<Value>> {
        let schema_id = format!("schema:{}", node_type);
        let node = self.get_node(&schema_id).await?;
        Ok(node.map(|n| n.properties))
    }

    pub async fn update_schema(&self, node_type: &str, schema: &Value) -> Result<()> {
        let schema_id = format!("schema:{}", node_type);

        // Check if schema node exists
        if self.get_node(&schema_id).await?.is_some() {
            // Update existing schema
            let update = NodeUpdate {
                properties: Some(schema.clone()),
                ..Default::default()
            };
            self.update_node(&schema_id, update).await?;
        } else {
            // Create new schema node with deterministic ID
            let node = Node::new_with_id(
                schema_id,
                "schema".to_string(),
                node_type.to_string(),
                None,
                schema.clone(),
            );
            self.create_node(node).await?;
        }

        Ok(())
    }

    pub async fn get_nodes_without_embeddings(&self, limit: Option<i64>) -> Result<Vec<Node>> {
        let sql = if limit.is_some() {
            "SELECT * FROM node WHERE embedding_vector IS NONE LIMIT $limit;"
        } else {
            "SELECT * FROM node WHERE embedding_vector IS NONE;"
        };

        let mut query_builder = self.db.query(sql);

        if let Some(lim) = limit {
            query_builder = query_builder.bind(("limit", lim));
        }

        let mut response = query_builder
            .await
            .context("Failed to get nodes without embeddings")?;
        let surreal_nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract nodes without embeddings from response")?;
        Ok(surreal_nodes.into_iter().map(Into::into).collect())
    }

    pub async fn update_embedding(&self, node_id: &str, embedding: &[u8]) -> Result<()> {
        // Convert binary blob to f32 array for SurrealDB vector functions
        let embedding_f32 = Self::blob_to_f32_array(embedding)?;

        // Phase 4 (Issue #511): Update using record ID
        self.db
            .query("UPDATE type::thing('node', $id) SET embedding_vector = $embedding, embedding_stale = false;")
            .bind(("id", node_id.to_string()))
            .bind(("embedding", embedding_f32))
            .await
            .context("Failed to update embedding")?;

        Ok(())
    }

    /// Mark a node's embedding as stale (needing regeneration)
    ///
    /// Called when node content changes, signaling that the embedding vector
    /// needs to be regenerated. The embedding processor can then query for
    /// stale nodes and regenerate embeddings in batches.
    ///
    /// # Arguments
    ///
    /// * `node_id` - UUID of the node to mark as stale
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// # use nodespace_core::db::SurrealStore;
    /// # use std::path::PathBuf;
    /// # #[tokio::main]
    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// # let store = SurrealStore::new(PathBuf::from("./data/surreal.db")).await?;
    /// // Mark embedding as stale after content change
    /// store.mark_embedding_stale("node-id").await?;
    /// # Ok(())
    /// # }
    /// ```
    pub async fn mark_embedding_stale(&self, node_id: &str) -> Result<()> {
        // Phase 4 (Issue #511): Update using record ID
        self.db
            .query("UPDATE type::thing('node', $id) SET embedding_stale = true;")
            .bind(("id", node_id.to_string()))
            .await
            .context("Failed to mark embedding as stale")?;

        Ok(())
    }

    /// Get nodes with stale embeddings
    ///
    /// Returns nodes where content has changed since the embedding was generated,
    /// allowing the embedding processor to regenerate embeddings in batches.
    ///
    /// # Arguments
    ///
    /// * `limit` - Optional limit on number of nodes to return
    ///
    /// # Returns
    ///
    /// Vector of nodes with stale embeddings (embedding_stale = true)
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// # use nodespace_core::db::SurrealStore;
    /// # use std::path::PathBuf;
    /// # #[tokio::main]
    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// # let store = SurrealStore::new(PathBuf::from("./data/surreal.db")).await?;
    /// // Get up to 100 nodes needing embedding regeneration
    /// let stale_nodes = store.get_nodes_with_stale_embeddings(Some(100)).await?;
    /// # Ok(())
    /// # }
    /// ```
    pub async fn get_nodes_with_stale_embeddings(&self, limit: Option<i64>) -> Result<Vec<Node>> {
        let sql = if limit.is_some() {
            "SELECT * FROM node WHERE embedding_stale = true LIMIT $limit;"
        } else {
            "SELECT * FROM node WHERE embedding_stale = true;"
        };

        let mut query_builder = self.db.query(sql);

        if let Some(lim) = limit {
            query_builder = query_builder.bind(("limit", lim));
        }

        let mut response = query_builder
            .await
            .context("Failed to get nodes with stale embeddings")?;
        let surreal_nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract nodes with stale embeddings from response")?;
        Ok(surreal_nodes.into_iter().map(Into::into).collect())
    }

    /// Search for nodes by embedding similarity using SurrealDB's native vector functions
    ///
    /// Converts the query embedding from binary blob to f32 array, then uses
    /// SurrealDB's `vector::similarity::cosine()` to find semantically similar nodes.
    ///
    /// # Arguments
    /// * `embedding` - Query embedding as binary blob (from EmbeddingService::to_blob)
    /// * `limit` - Maximum number of results to return
    /// * `threshold` - Optional minimum similarity score (0.0-1.0, default: 0.5)
    ///
    /// # Returns
    /// Vector of (Node, similarity_score) tuples, sorted by similarity descending
    pub async fn search_by_embedding(
        &self,
        embedding: &[u8],
        limit: i64,
        threshold: Option<f64>,
    ) -> Result<Vec<(Node, f64)>> {
        // Convert binary blob to f32 array for SurrealDB
        let query_vector = Self::blob_to_f32_array(embedding)?;

        // Default threshold: 0.5 (moderate similarity)
        let min_similarity = threshold.unwrap_or(0.5);

        // SurrealDB query using vector::similarity::cosine
        // We need to explicitly select fields to avoid deserialization issues with the computed similarity field
        // Use SurrealQL's OR operator to provide defaults for NONE values (SurrealDB's COALESCE equivalent)
        let query = r#"
            SELECT
                uuid,
                node_type,
                content,
                parent_id,
                container_node_id,
                before_sibling_id,
                version,
                created_at,
                modified_at,
                properties,
                embedding_vector,
                embedding_stale OR false AS embedding_stale,
                mentions OR [] AS mentions,
                mentioned_by OR [] AS mentioned_by,
                vector::similarity::cosine(embedding_vector, $query_vector) AS similarity
            FROM node
            WHERE embedding_vector != NONE
              AND vector::similarity::cosine(embedding_vector, $query_vector) > $threshold
            ORDER BY similarity DESC
            LIMIT $limit;
        "#;

        let mut response = self
            .db
            .query(query)
            .bind(("query_vector", query_vector))
            .bind(("threshold", min_similarity))
            .bind(("limit", limit))
            .await
            .context("Failed to execute vector similarity search")?;

        // Deserialize response with similarity scores
        #[derive(Debug, Deserialize)]
        struct NodeWithSimilarity {
            uuid: String,
            node_type: String,
            content: String,
            #[serde(default)]
            parent_id: Option<String>,
            #[serde(default)]
            container_node_id: Option<String>,
            #[serde(default)]
            before_sibling_id: Option<String>,
            version: i64,
            created_at: String,
            modified_at: String,
            properties: Value,
            #[serde(default)]
            embedding_vector: Option<Vec<f32>>,
            #[serde(default)]
            embedding_stale: bool,
            #[serde(default)]
            mentions: Vec<String>,
            #[serde(default)]
            mentioned_by: Vec<String>,
            similarity: f64,
        }

        let results: Vec<NodeWithSimilarity> = response
            .take(0)
            .context("Failed to extract similarity search results")?;

        // Convert to (Node, f64) tuples
        Ok(results
            .into_iter()
            .map(|nws| {
                let surreal_node = SurrealNode {
                    uuid: nws.uuid,
                    node_type: nws.node_type,
                    content: nws.content,
                    parent_id: nws.parent_id,
                    container_node_id: nws.container_node_id,
                    before_sibling_id: nws.before_sibling_id,
                    version: nws.version,
                    created_at: nws.created_at,
                    modified_at: nws.modified_at,
                    properties: nws.properties,
                    embedding_vector: nws.embedding_vector,
                    embedding_stale: nws.embedding_stale,
                    mentions: nws.mentions,
                    mentioned_by: nws.mentioned_by,
                    data: None, // Phase 1 (Issue #511): Not used in similarity search
                    variants: serde_json::json!({}), // Phase 1 (Issue #511): Not used in similarity search
                    _schema_version: 1,              // Phase 1 (Issue #511): Default version
                };
                (surreal_node.into(), nws.similarity)
            })
            .collect())
    }

    /// Atomic bulk update using SurrealDB transactions
    ///
    /// Updates multiple nodes in a single atomic transaction. Either all updates
    /// succeed or all fail (rollback), ensuring data consistency.
    ///
    /// # Performance Considerations
    ///
    /// - **Optimal Batch Size:** 10-100 nodes (transaction overhead minimal)
    /// - **Large Batches:** >1000 nodes may hit transaction timeout (consider chunking)
    /// - **Validation Cost:** Pre-fetches all nodes for existence check
    ///
    /// # Arguments
    ///
    /// * `updates` - Vector of (node_id, NodeUpdate) tuples to apply
    ///
    /// # Returns
    ///
    /// * `Ok(())` - All updates succeeded
    /// * `Err(_)` - Transaction failed and rolled back, or batch size exceeded limit
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// # use nodespace_core::db::SurrealStore;
    /// # use nodespace_core::models::NodeUpdate;
    /// # use std::path::PathBuf;
    /// # #[tokio::main]
    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// # let store = SurrealStore::new(PathBuf::from("./data/surreal.db")).await?;
    /// let updates = vec![
    ///     ("node-1".to_string(), NodeUpdate {
    ///         content: Some("New content 1".to_string()),
    ///         ..Default::default()
    ///     }),
    ///     ("node-2".to_string(), NodeUpdate {
    ///         content: Some("New content 2".to_string()),
    ///         ..Default::default()
    ///     }),
    /// ];
    ///
    /// store.bulk_update(updates).await?; // All-or-nothing
    /// # Ok(())
    /// # }
    /// ```
    pub async fn bulk_update(&self, updates: Vec<(String, NodeUpdate)>) -> Result<()> {
        if updates.is_empty() {
            return Ok(());
        }

        // Prevent excessive batch sizes that could cause transaction timeouts
        const MAX_BATCH_SIZE: usize = 1000;
        if updates.len() > MAX_BATCH_SIZE {
            return Err(anyhow::anyhow!(
                "Bulk update batch size ({}) exceeds maximum ({}). Consider chunking the updates into smaller batches.",
                updates.len(),
                MAX_BATCH_SIZE
            ));
        }

        // Build transaction query
        let mut transaction_parts = vec!["BEGIN TRANSACTION;".to_string()];

        for (idx, (id, _)) in updates.iter().enumerate() {
            // Validate node exists (will fetch again later for merging values)
            self.get_node(id)
                .await?
                .ok_or_else(|| anyhow::anyhow!("Node not found: {}", id))?;

            // Phase 4 (Issue #511): Generate UPDATE statement using record ID
            let update_stmt = format!(
                "UPDATE type::thing('node', $id_{idx}) SET
                    content = $content_{idx},
                    node_type = $node_type_{idx},
                    parent_id = $parent_id_{idx},
                    container_node_id = $container_node_id_{idx},
                    before_sibling_id = $before_sibling_id_{idx},
                    modified_at = time::now(),
                    version = version + 1,
                    properties = $properties_{idx},
                    embedding_vector = $embedding_vector_{idx};",
                idx = idx
            );
            transaction_parts.push(update_stmt);
        }

        transaction_parts.push("COMMIT TRANSACTION;".to_string());
        let transaction_query = transaction_parts.join("\n");

        // Build query with all bindings
        let mut query_builder = self.db.query(transaction_query);

        for (idx, (id, update)) in updates.iter().enumerate() {
            // Fetch current node again for building merged values
            let current = self
                .get_node(id)
                .await?
                .ok_or_else(|| anyhow::anyhow!("Node not found: {}", id))?;

            let updated_content = update.content.clone().unwrap_or(current.content);
            let updated_node_type = update.node_type.clone().unwrap_or(current.node_type);
            let updated_properties = update.properties.clone().unwrap_or(current.properties);

            // Convert embedding blob to f32 if provided
            let embedding_f32 = update
                .embedding_vector
                .clone()
                .flatten()
                .as_ref()
                .map(|blob| Self::blob_to_f32_array(blob))
                .transpose()?;

            query_builder = query_builder
                .bind((format!("id_{}", idx), id.clone()))
                .bind((format!("content_{}", idx), updated_content))
                .bind((format!("node_type_{}", idx), updated_node_type))
                .bind((
                    format!("parent_id_{}", idx),
                    update.parent_id.clone().flatten(),
                ))
                .bind((
                    format!("container_node_id_{}", idx),
                    update.container_node_id.clone().flatten(),
                ))
                .bind((
                    format!("before_sibling_id_{}", idx),
                    update.before_sibling_id.clone().flatten(),
                ))
                .bind((format!("properties_{}", idx), updated_properties))
                .bind((format!("embedding_vector_{}", idx), embedding_f32));
        }

        query_builder
            .await
            .context("Failed to execute bulk update transaction")?;

        Ok(())
    }

    pub async fn batch_create_nodes(&self, nodes: Vec<Node>) -> Result<Vec<Node>> {
        let mut created_nodes = Vec::new();

        for node in nodes {
            let created = self.create_node(node).await?;
            created_nodes.push(created);
        }

        Ok(created_nodes)
    }

    pub fn close(&self) -> Result<()> {
        // SurrealDB handles cleanup automatically on drop
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde_json::json;
    use tempfile::TempDir;

    async fn create_test_store() -> Result<(SurrealStore, TempDir)> {
        let temp_dir = TempDir::new()?;
        let db_path = temp_dir.path().join("test_surreal.db");
        let store = SurrealStore::new(db_path).await?;
        Ok((store, temp_dir))
    }

    #[tokio::test]
    async fn test_create_and_get_node() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        let node = Node::new(
            "text".to_string(),
            "Test content".to_string(),
            None,
            json!({}),
        );

        let created = store.create_node(node.clone()).await?;
        assert_eq!(created.id, node.id);
        assert_eq!(created.content, "Test content");

        let fetched = store.get_node(&node.id).await?;
        assert!(fetched.is_some());
        assert_eq!(fetched.unwrap().id, node.id);

        Ok(())
    }

    #[tokio::test]
    async fn test_update_node() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        let node = Node::new(
            "text".to_string(),
            "Original content".to_string(),
            None,
            json!({}),
        );

        let created = store.create_node(node.clone()).await?;

        let update = NodeUpdate {
            content: Some("Updated content".to_string()),
            ..Default::default()
        };

        let updated = store.update_node(&created.id, update).await?;
        assert_eq!(updated.content, "Updated content");

        Ok(())
    }

    #[tokio::test]
    async fn test_delete_node() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        let node = Node::new(
            "text".to_string(),
            "Test content".to_string(),
            None,
            json!({}),
        );

        let created = store.create_node(node.clone()).await?;

        let result = store.delete_node(&created.id).await?;
        assert!(result.existed);

        let fetched = store.get_node(&created.id).await?;
        assert!(fetched.is_none());

        Ok(())
    }

    #[tokio::test]
    async fn test_schema_operations() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        let schema = json!({
            "type": "object",
            "properties": {
                "status": {"type": "string"}
            }
        });

        store.update_schema("task", &schema).await?;

        let fetched = store.get_schema("task").await?;
        assert!(fetched.is_some());
        assert_eq!(fetched.unwrap(), schema);

        Ok(())
    }

    // Vector Similarity Search Tests

    #[test]
    fn test_blob_to_f32_conversion() {
        // Valid embedding: 3 floats (12 bytes)
        let floats = [1.0f32, 2.5f32, -0.5f32];
        let blob: Vec<u8> = floats.iter().flat_map(|f| f.to_le_bytes()).collect();

        let result = EmbeddedStore::blob_to_f32_array(&blob).unwrap();
        assert_eq!(result.len(), 3);
        assert_eq!(result[0], 1.0);
        assert_eq!(result[1], 2.5);
        assert_eq!(result[2], -0.5);
    }

    #[test]
    fn test_blob_to_f32_invalid_length() {
        // Invalid blob: 13 bytes (not divisible by 4)
        let invalid_blob = vec![0u8; 13];

        let result = EmbeddedStore::blob_to_f32_array(&invalid_blob);
        assert!(result.is_err());
        assert!(result
            .unwrap_err()
            .to_string()
            .contains("not divisible by 4"));
    }

    #[tokio::test]
    async fn test_search_empty_database() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create a dummy embedding (384 floats)
        let query_vector = vec![0.5f32; 384];
        let query_blob: Vec<u8> = query_vector.iter().flat_map(|f| f.to_le_bytes()).collect();

        // Search empty database
        let results = store.search_by_embedding(&query_blob, 10, None).await?;

        assert_eq!(results.len(), 0, "Empty database should return no results");

        Ok(())
    }

    #[tokio::test]
    async fn test_search_with_similar_nodes() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create nodes with different embeddings
        let base_vector = vec![1.0f32; 384];
        let similar_vector = vec![0.99f32; 384]; // Very similar
        let dissimilar_vector = vec![-1.0f32; 384]; // Opposite direction

        let base_blob: Vec<u8> = base_vector.iter().flat_map(|f| f.to_le_bytes()).collect();
        let similar_blob: Vec<u8> = similar_vector
            .iter()
            .flat_map(|f| f.to_le_bytes())
            .collect();
        let dissimilar_blob: Vec<u8> = dissimilar_vector
            .iter()
            .flat_map(|f| f.to_le_bytes())
            .collect();

        // Create nodes
        let node1 = Node::new(
            "text".to_string(),
            "Base content".to_string(),
            None,
            json!({}),
        );
        let mut created1 = store.create_node(node1).await?;
        store.update_embedding(&created1.id, &similar_blob).await?;
        created1.embedding_vector = Some(similar_blob.clone());

        let node2 = Node::new(
            "text".to_string(),
            "Dissimilar content".to_string(),
            None,
            json!({}),
        );
        let mut created2 = store.create_node(node2).await?;
        store
            .update_embedding(&created2.id, &dissimilar_blob)
            .await?;
        created2.embedding_vector = Some(dissimilar_blob);

        // Search with base embedding
        let results = store.search_by_embedding(&base_blob, 10, None).await?;

        // Should return nodes sorted by similarity (highest first)
        assert!(!results.is_empty(), "Should find at least one similar node");

        // First result should be more similar (higher score)
        if results.len() > 1 {
            assert!(
                results[0].1 > results[1].1,
                "Results should be sorted by similarity descending"
            );
        }

        Ok(())
    }

    #[tokio::test]
    async fn test_search_with_threshold_filter() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create query vector
        let query_vector = vec![1.0f32; 384];
        let query_blob: Vec<u8> = query_vector.iter().flat_map(|f| f.to_le_bytes()).collect();

        // Create node with similar embedding
        let similar_vector = vec![0.99f32; 384];
        let similar_blob: Vec<u8> = similar_vector
            .iter()
            .flat_map(|f| f.to_le_bytes())
            .collect();

        let node = Node::new(
            "text".to_string(),
            "Test content".to_string(),
            None,
            json!({}),
        );
        let created = store.create_node(node).await?;
        store.update_embedding(&created.id, &similar_blob).await?;

        // Search with high threshold (0.99) - should find the node
        let results_high_threshold = store
            .search_by_embedding(&query_blob, 10, Some(0.9))
            .await?;
        assert!(
            !results_high_threshold.is_empty(),
            "Should find node with similarity > 0.9"
        );

        // Search with very high threshold (0.999) - might not find it
        let results_very_high = store
            .search_by_embedding(&query_blob, 10, Some(0.999))
            .await?;
        // This test is lenient because exact similarity depends on normalization
        assert!(
            results_very_high.len() <= results_high_threshold.len(),
            "Higher threshold should return fewer or equal results"
        );

        Ok(())
    }

    #[tokio::test]
    async fn test_search_respects_limit() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create 5 nodes with embeddings
        let base_vector = vec![1.0f32; 384];
        let blob: Vec<u8> = base_vector.iter().flat_map(|f| f.to_le_bytes()).collect();

        for i in 0..5 {
            let node = Node::new(
                "text".to_string(),
                format!("Content {}", i),
                None,
                json!({}),
            );
            let created = store.create_node(node).await?;
            store.update_embedding(&created.id, &blob).await?;
        }

        // Search with limit of 3
        let results = store.search_by_embedding(&blob, 3, Some(0.5)).await?;

        assert!(
            results.len() <= 3,
            "Should respect limit parameter (expected <= 3, got {})",
            results.len()
        );

        Ok(())
    }

    // Performance Benchmark Tests
    //
    // These tests measure search query performance on databases of varying sizes.
    // Current implementation uses linear scan (O(n)) without vector indexes.
    // Performance targets are based on real-world measurements on RocksDB storage.

    #[tokio::test]
    async fn test_search_performance_1k_nodes() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create 1,000 nodes with embeddings
        let base_vector = vec![1.0f32; 384];
        let blob: Vec<u8> = base_vector.iter().flat_map(|f| f.to_le_bytes()).collect();

        tracing::info!("Creating 1,000 nodes for performance test...");
        for i in 0..1000 {
            let node = Node::new(
                "text".to_string(),
                format!("Performance test content {}", i),
                None,
                json!({}),
            );
            let created = store.create_node(node).await?;
            store.update_embedding(&created.id, &blob).await?;

            if i % 100 == 0 {
                tracing::info!("Created {} nodes", i);
            }
        }

        tracing::info!("Starting performance benchmark...");

        // Measure search time (after data is created)
        let start = std::time::Instant::now();
        let results = store.search_by_embedding(&blob, 20, Some(0.5)).await?;
        let elapsed = start.elapsed();

        tracing::info!(
            "Search completed in {:?} with {} results",
            elapsed,
            results.len()
        );

        // Performance target: < 1500ms for 1,000 nodes (linear scan on RocksDB)
        // Real-world measurement: ~950ms
        // Note: This is the search query time only, not data creation time
        assert!(
            elapsed.as_millis() < 1500,
            "Search should complete in < 1500ms (took {:?})",
            elapsed
        );

        Ok(())
    }

    #[tokio::test]
    async fn test_search_with_real_nlp_embeddings() -> Result<()> {
        use nodespace_nlp_engine::EmbeddingService;
        use std::sync::Arc;

        let (store, _temp_dir) = create_test_store().await?;

        // Initialize real NLP engine
        let mut nlp_service = EmbeddingService::new(Default::default())?;
        nlp_service.initialize()?;
        let nlp = Arc::new(nlp_service);

        // Create nodes with semantically similar and dissimilar content
        let similar_text_1 = "Machine learning algorithms for data analysis";
        let similar_text_2 = "Deep learning neural networks and AI models";
        let dissimilar_text = "The weather forecast predicts sunny skies tomorrow";

        // Generate real embeddings
        let emb1 = nlp.generate_embedding(similar_text_1)?;
        let emb2 = nlp.generate_embedding(similar_text_2)?;
        let emb3 = nlp.generate_embedding(dissimilar_text)?;

        let blob1 = EmbeddingService::to_blob(&emb1);
        let blob2 = EmbeddingService::to_blob(&emb2);
        let blob3 = EmbeddingService::to_blob(&emb3);

        // Create nodes
        let node1 = Node::new(
            "text".to_string(),
            similar_text_1.to_string(),
            None,
            json!({}),
        );
        let mut created1 = store.create_node(node1).await?;
        store.update_embedding(&created1.id, &blob1).await?;
        created1.embedding_vector = Some(blob1.clone());

        let node2 = Node::new(
            "text".to_string(),
            similar_text_2.to_string(),
            None,
            json!({}),
        );
        let mut created2 = store.create_node(node2).await?;
        store.update_embedding(&created2.id, &blob2).await?;
        created2.embedding_vector = Some(blob2.clone());

        let node3 = Node::new(
            "text".to_string(),
            dissimilar_text.to_string(),
            None,
            json!({}),
        );
        let mut created3 = store.create_node(node3).await?;
        store.update_embedding(&created3.id, &blob3).await?;
        created3.embedding_vector = Some(blob3);

        // Search with first embedding (machine learning topic)
        let results = store.search_by_embedding(&blob1, 10, Some(0.3)).await?;

        // Verify results
        assert!(!results.is_empty(), "Should find at least one similar node");

        // The most similar should be the ML/AI content (node2), not the weather content
        let (top_node, top_similarity) = &results[0];
        tracing::info!(
            "Top result: content='{}', similarity={:.3}",
            top_node.content,
            top_similarity
        );

        // Find similarity scores for each content type
        let ml_similarity = results
            .iter()
            .find(|(n, _)| n.id == created2.id)
            .map(|(_, s)| *s);
        let weather_similarity = results
            .iter()
            .find(|(n, _)| n.id == created3.id)
            .map(|(_, s)| *s);

        tracing::info!(
            "ML/AI similarity: {:?}, Weather similarity: {:?}",
            ml_similarity,
            weather_similarity
        );

        // ML/AI content should be more similar to the query than weather content
        if let (Some(ml_sim), Some(weather_sim)) = (ml_similarity, weather_similarity) {
            assert!(
                ml_sim > weather_sim,
                "ML/AI content (sim={:.3}) should rank higher than weather content (sim={:.3})",
                ml_sim,
                weather_sim
            );
        }

        // Top result should have high similarity (> 0.7 for semantically related content)
        assert!(
            top_similarity > &0.5,
            "Top result should have similarity > 0.5 (got {:.3})",
            top_similarity
        );

        Ok(())
    }

    #[tokio::test]
    async fn test_search_performance_10k_nodes() -> Result<()> {
        // Skip this test unless RUN_LONG_TESTS=1 is set
        // Reason: Test takes ~10 minutes total (10K node creation + search)
        // The search itself is fast (~9.5s), but setup is slow
        if std::env::var("RUN_LONG_TESTS").unwrap_or_default() != "1" {
            eprintln!("Skipping 10K performance test (set RUN_LONG_TESTS=1 to run)");
            return Ok(());
        }

        let (store, _temp_dir) = create_test_store().await?;

        // Create 10,000 nodes with embeddings
        let base_vector = vec![1.0f32; 384];
        let blob: Vec<u8> = base_vector.iter().flat_map(|f| f.to_le_bytes()).collect();

        tracing::info!("Creating 10,000 nodes for performance test...");
        for i in 0..10000 {
            let node = Node::new(
                "text".to_string(),
                format!("Performance test content {}", i),
                None,
                json!({}),
            );
            let created = store.create_node(node).await?;
            store.update_embedding(&created.id, &blob).await?;

            if i % 1000 == 0 {
                tracing::info!("Created {} nodes", i);
            }
        }

        tracing::info!("Starting performance benchmark...");

        // Measure search time
        let start = std::time::Instant::now();
        let results = store.search_by_embedding(&blob, 20, Some(0.5)).await?;
        let elapsed = start.elapsed();

        tracing::info!(
            "Search completed in {:?} with {} results",
            elapsed,
            results.len()
        );

        // Performance target: < 15000ms (15 seconds) for 10,000 nodes (linear scan)
        // Estimated: ~9.5 seconds based on 1K node measurements (linear scaling)
        // Note: This is acceptable for MVP without vector indexes
        assert!(
            elapsed.as_millis() < 15000,
            "Search should complete in < 15s (took {:?})",
            elapsed
        );

        Ok(())
    }
}
