//! SurrealStore - Direct SurrealDB Backend Implementation
//!
//! This module provides the primary and only database backend for NodeSpace,
//! using SurrealDB embedded database with RocksDB storage engine.
//!
//! # Architecture
//!
//! SurrealStore uses a **graph-native architecture** (Issue #511):
//! 1. **Universal `node` table** - All node data with record IDs, graph edges for hierarchy
//! 2. **Type-specific tables** - Optional tables for types with properties (currently: `task`)
//! 3. **Graph edges** - `has_child` edges for parent-child relationships
//!
//! # Design Principles
//!
//! 1. **Embedded RocksDB**: Desktop-only backend using `kv-rocksdb` engine
//! 2. **SCHEMALESS Mode**: Core tables use SCHEMALESS for dynamic properties
//! 3. **Record IDs**: Native SurrealDB format `node:uuid` (type embedded in ID)
//! 4. **Graph Edges**: Hierarchy via `has_child` edges (no parent_id/container_node_id fields)
//! 5. **Direct Access**: No abstraction layers, SurrealStore used directly by services
//!
//! # Performance Targets (from PoC)
//!
//! - Startup time: <100ms (PoC: 52ms)
//! - 100K nodes query: <200ms (PoC: 104ms)
//! - Deep pagination: <50ms (PoC: 8.3ms)
//! - Complex queries avg: <300ms (PoC: 211ms)
//!
//! # Examples
//!
//! ```rust,no_run
//! use nodespace_core::db::SurrealStore;
//! use std::path::PathBuf;
//!
//! #[tokio::main]
//! async fn main() -> anyhow::Result<()> {
//!     // Create embedded SurrealDB store
//!     let db_path = PathBuf::from("./data/surreal.db");
//!     let store = SurrealStore::new(db_path).await?;
//!
//!     // Direct database access
//!     let node = store.get_node("task:550e8400-e29b-41d4-a716-446655440000").await?;
//!
//!     Ok(())
//! }
//! ```

use crate::models::{DeleteResult, Node, NodeQuery, NodeUpdate};
use anyhow::{Context, Result};
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use serde_json::Value;
use std::path::PathBuf;
use std::sync::Arc;
use surrealdb::engine::local::{Db, RocksDb};
use surrealdb::engine::remote::http::{Client, Http};
use surrealdb::opt::auth::Root;
use surrealdb::sql::{Id, Thing};
use surrealdb::Surreal;

/// Types that require type-specific tables for storing properties
///
/// - `task`: Has properties (priority, status, due_date, assignee, etc.)
/// - `schema`: Has properties (is_core, fields, version, etc.)
///
/// Other types (text, date, header, code_block, quote_block, ordered_list) store
/// all data in the universal `node` table's `content` field.
const TYPES_WITH_PROPERTIES: &[&str] = &["task", "schema"];

/// All valid node types that can be used in SurrealDB queries
/// Used to validate node_type parameters and prevent SQL injection
const VALID_NODE_TYPES: &[&str] = &[
    "text",
    "date",
    "header",
    "code_block",
    "quote_block",
    "ordered_list",
    "task",
    "schema",
];

/// Validates a node type against the whitelist of valid types
///
/// This prevents SQL injection attacks where malicious node_type values could
/// alter query semantics. All node_type parameters used in dynamic queries
/// must be validated with this function before use.
///
/// # Arguments
/// * `node_type` - The node type string to validate
///
/// # Returns
/// * `Ok(())` if the node_type is in the valid types list
/// * `Err(...)` if the node_type is not recognized
fn validate_node_type(node_type: &str) -> Result<()> {
    if VALID_NODE_TYPES.contains(&node_type) {
        Ok(())
    } else {
        Err(anyhow::anyhow!(
            "Invalid node type: '{}'. Valid types are: {}",
            node_type,
            VALID_NODE_TYPES.join(", ")
        ))
    }
}

/// Internal struct matching SurrealDB's schema
///
/// # Schema Evolution
///
/// - **v1.0** (Issue #470): Initial SurrealDB schema migration
///   - Core node fields with embedding vector storage
///   - Version-based optimistic concurrency control
///
/// - **v1.1** (Issue #481): Advanced SurrealDB features
///   - Added `embedding_stale` field for tracking embedding staleness
///   - Automatically set when content changes, cleared when embedding regenerated
///
/// - **v1.2** (Issue #511): Graph-native architecture
///   - Removed `uuid`, `parent_id`, `container_node_id`, `properties` fields
///   - Added `data` field: Optional record link to type-specific table
///   - Added `variants` field: Type history for lossless type switching
///   - Added `_schema_version` field: Universal versioning
///   - Table renamed from `nodes` to `node` (singular)
///   - Hierarchy via `has_child` graph edges only
///   - Only `task` type table exists (other types are schema-only)
///
/// # Embedding Storage Architecture (Issue #495)
///
/// Embeddings use a **hybrid storage architecture** with different representations
/// at different boundaries:
///
/// - **External API** (`Node` struct): `Vec<u8>` binary blobs
///   - Generated by `EmbeddingService::to_blob()` (little-endian f32 encoding)
///   - Storage-efficient format for transfer and external persistence
///
/// - **Database Storage** (`SurrealNode` struct): `Vec<f32>` float arrays
///   - Required by SurrealDB's `vector::similarity::cosine()` function
///   - Enables native vector operations without conversion overhead
///
/// This dual representation optimizes for both external compatibility (binary blobs)
/// and internal query performance (native f32 arrays).
#[derive(Debug, Clone, Serialize, Deserialize)]
struct SurrealNode {
    // Record ID is stored in the 'id' field returned by SurrealDB (e.g., node:‚ü®uuid‚ü©)
    id: Thing, // SurrealDB record ID (table:id format)
    #[serde(rename = "type")]
    node_type: String,
    content: String,
    before_sibling_id: Option<String>,
    version: i64,
    created_at: String,
    modified_at: String,
    embedding_vector: Option<Vec<f32>>,
    embedding_stale: bool,
    mentions: Vec<String>,
    mentioned_by: Vec<String>,
    // Graph-native architecture fields (Issue #511)
    /// FETCH data Limitation (Issue #511):
    ///
    /// **Problem**: SurrealDB's Thing type cannot be deserialized to `serde_json::Value`.
    ///
    /// **Root Cause**: When using `SELECT * FROM node FETCH data`, the `data` field can be:
    /// - A String (record link): `"task:uuid"`  when not fetched
    /// - An Object (fetched record): `{id: Thing, priority: "HIGH", ...}` when FETCH succeeds
    ///
    /// The `id` field in the fetched object is a SurrealDB `Thing` type, which serde_json
    /// cannot deserialize to `Value`, causing:
    /// ```
    /// Error: invalid type: enum, expected any valid JSON value
    /// ```
    ///
    /// **Attempted Solutions**:
    /// 1. ‚ùå Option<Value> - Fails with Thing deserialization error
    /// 2. ‚ùå Custom deserializer - Complex, error-prone
    /// 3. ‚úÖ Skip + manual fetch with OMIT id - Current workaround
    ///
    /// **Workaround**: Use `#[serde(skip_deserializing)]` and manually fetch properties
    /// with `SELECT * OMIT id` to exclude the Thing-typed id field.
    ///
    /// **Performance Impact**: Creates N+1 query pattern (see get_children implementation).
    /// Batch fetching added to mitigate this issue.
    ///
    /// **Future**: Investigate SurrealDB support for FETCH with field exclusion:
    /// `SELECT * FROM node FETCH data.* OMIT data.id;`
    #[serde(skip_deserializing)]
    data: Option<Value>, // Placeholder - properties fetched separately
    #[serde(skip_deserializing, default)]
    variants: Value, // Type history map {task: "task:uuid", text: null}
    /// Properties field stores user-defined properties for types without dedicated tables
    /// For types with dedicated tables (task, schema), this contains _schema_version only
    /// and actual properties are fetched from the type-specific table
    #[serde(default)]
    properties: Value,
}

impl From<SurrealNode> for Node {
    fn from(sn: SurrealNode) -> Self {
        // Keep f32 vector as-is (no conversion to bytes)
        // SurrealDB stores array<float> natively, and JSON API expects f32 arrays
        let embedding_vector = sn.embedding_vector;

        // Extract UUID from Thing record ID (e.g., node:‚ü®uuid‚ü© -> uuid)
        let id = match &sn.id.id {
            Id::String(s) => {
                // Format is "node:uuid", extract the UUID part
                s.split(':').nth(1).unwrap_or(s).to_string()
            }
            _ => sn.id.id.to_string(),
        };

        // Extract properties:
        // 1. If data field is populated (types with dedicated tables like task/schema), use it
        // 2. Otherwise use properties field (types without dedicated tables like text/date)
        let properties = if let Some(Value::Object(ref obj)) = sn.data {
            tracing::debug!(
                "FETCH data populated for node {}: data has {} fields",
                id,
                obj.len()
            );
            // Remove the 'id' field and use remaining fields as properties
            let mut props = obj.clone();
            props.remove("id");
            Value::Object(props)
        } else if !sn.properties.is_null() {
            tracing::debug!(
                "Using properties field for node {} (type: {}): {} fields",
                id,
                sn.node_type,
                sn.properties.as_object().map(|o| o.len()).unwrap_or(0)
            );
            sn.properties
        } else {
            tracing::debug!(
                "No properties found for node {} (type: {})",
                id,
                sn.node_type
            );
            serde_json::json!({})
        };

        Node {
            id,
            node_type: sn.node_type,
            content: sn.content,
            before_sibling_id: sn.before_sibling_id,
            version: sn.version,
            created_at: DateTime::parse_from_rfc3339(&sn.created_at)
                .map(|dt| dt.with_timezone(&Utc))
                .unwrap_or_else(|_| Utc::now()),
            modified_at: DateTime::parse_from_rfc3339(&sn.modified_at)
                .map(|dt| dt.with_timezone(&Utc))
                .unwrap_or_else(|_| Utc::now()),
            properties,
            embedding_vector,
            mentions: sn.mentions,
            mentioned_by: sn.mentioned_by,
        }
    }
}

/// Batch fetch properties for multiple nodes of the same type
///
/// **Purpose**: Avoid N+1 query pattern when fetching properties for multiple nodes.
///
/// **Performance**:
/// - Old: 100 nodes = 100 individual queries
/// - New: 100 nodes = 1 batch query per type
///
/// # Arguments
///
/// * `db` - SurrealDB connection
/// * `node_type` - Type of nodes (e.g., "task", "schema")
/// * `node_ids` - Vector of node IDs to fetch properties for
///
/// # Returns
///
/// HashMap mapping node ID to its properties
async fn batch_fetch_properties<C: surrealdb::Connection>(
    db: &Surreal<C>,
    node_type: &str,
    node_ids: &[String],
) -> Result<std::collections::HashMap<String, Value>> {
    if node_ids.is_empty() {
        return Ok(std::collections::HashMap::new());
    }

    // Build array of Thing IDs for the WHERE IN clause
    let thing_ids: Vec<Thing> = node_ids
        .iter()
        .map(|id| Thing::from((node_type.to_string(), id.clone())))
        .collect();

    // Batch query strategy: Query properties with WHERE IN for efficiency
    // We select all fields but need to handle the id separately since it's a Thing type
    // Workaround: Query with id, convert to string, then build properties without id
    let query = format!("SELECT * FROM {} WHERE id IN $ids;", node_type);

    let mut response = db
        .query(&query)
        .bind(("ids", thing_ids))
        .await
        .with_context(|| format!("Failed to batch fetch properties for type '{}'", node_type))?;

    // Deserialize as generic Values to extract id as string
    let records: Vec<Value> = response.take(0).with_context(|| {
        format!(
            "Failed to parse batch property results for type '{}'",
            node_type
        )
    })?;

    // Convert to HashMap keyed by node ID (extracted from Thing)
    let mut result = std::collections::HashMap::new();
    for record in records {
        if let Some(obj) = record.as_object() {
            // Extract id as string (format: "task:uuid" -> "uuid")
            if let Some(id_value) = obj.get("id") {
                if let Some(id_str) = id_value.as_str() {
                    // Parse Thing ID: "task:uuid" -> "uuid"
                    let node_id = id_str.split(':').nth(1).unwrap_or(id_str).to_string();

                    // Create properties object without the 'id' field
                    let mut props = obj.clone();
                    props.remove("id");
                    result.insert(node_id, Value::Object(props));
                }
            }
        }
    }

    Ok(result)
}

/// SurrealStore implements NodeStore trait for SurrealDB backend
///
/// Supports two connection modes:
/// - **Embedded RocksDB**: Desktop production mode (Surreal<Db>)
/// - **HTTP Client**: Dev-proxy mode (Surreal<Client>)
///
/// Uses hybrid dual-table architecture for optimal query performance.
pub struct SurrealStore<C = Db>
where
    C: surrealdb::Connection,
{
    /// SurrealDB connection
    db: Arc<Surreal<C>>,
}

/// Type alias for embedded RocksDB store
pub type EmbeddedStore = SurrealStore<Db>;

/// Type alias for HTTP client store
pub type HttpStore = SurrealStore<Client>;

impl SurrealStore<Db> {
    /// Create a new SurrealStore with embedded RocksDB backend
    ///
    /// # Arguments
    ///
    /// * `db_path` - Path to RocksDB database directory
    ///
    /// # Returns
    ///
    /// Initialized SurrealStore with schema setup complete
    ///
    /// # Errors
    ///
    /// Returns error if:
    /// - Database path is invalid
    /// - RocksDB initialization fails
    /// - Schema initialization fails
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// # use nodespace_core::db::SurrealStore;
    /// # use std::path::PathBuf;
    /// # #[tokio::main]
    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// let store = SurrealStore::new(PathBuf::from("./data/surreal.db")).await?;
    /// # Ok(())
    /// # }
    /// ```
    pub async fn new(db_path: PathBuf) -> Result<Self> {
        // Initialize embedded RocksDb
        let db = Surreal::new::<RocksDb>(db_path)
            .await
            .context("Failed to initialize SurrealDB with RocksDB backend")?;

        // Use namespace and database
        db.use_ns("nodespace")
            .use_db("nodes")
            .await
            .context("Failed to set namespace/database")?;

        let db = Arc::new(db);

        // Initialize schema (create tables)
        Self::initialize_schema(&db).await?;

        // Seed core schemas (create schema nodes)
        Self::seed_core_schemas(&db).await?;

        Ok(Self { db })
    }
}

impl SurrealStore<Client> {
    /// Create HTTP client store for dev-proxy mode
    ///
    /// This connects to a remote SurrealDB server via HTTP API.
    /// Used by dev-proxy to enable Surrealist inspection while preserving business logic.
    ///
    /// # Arguments
    ///
    /// * `endpoint` - SurrealDB server address (e.g., "127.0.0.1:8000")
    /// * `namespace` - Database namespace (e.g., "nodespace")
    /// * `database` - Database name (e.g., "nodes")
    /// * `username` - Auth username (e.g., "root")
    /// * `password` - Auth password (e.g., "root")
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// use nodespace_core::db::SurrealStore;
    ///
    /// #[tokio::main]
    /// async fn main() -> anyhow::Result<()> {
    ///     let store = SurrealStore::new_http(
    ///         "127.0.0.1:8000",
    ///         "nodespace",
    ///         "nodes",
    ///         "root",
    ///         "root"
    ///     ).await?;
    ///
    ///     // Use store normally - same API as embedded mode
    ///     let node = store.get_node("some-id").await?;
    ///
    ///     Ok(())
    /// }
    /// ```
    pub async fn new_http(
        endpoint: &str,
        namespace: &str,
        database: &str,
        username: &str,
        password: &str,
    ) -> Result<Self> {
        tracing::info!("Connecting to SurrealDB HTTP server at {}", endpoint);

        // Create HTTP client connection to remote SurrealDB server
        let db = Surreal::new::<Http>(endpoint)
            .await
            .context("Failed to connect to SurrealDB HTTP server")?;

        // Authenticate with root credentials
        db.signin(Root { username, password })
            .await
            .context("Failed to authenticate with SurrealDB")?;

        // Set namespace and database
        db.use_ns(namespace)
            .use_db(database)
            .await
            .context("Failed to set namespace/database")?;

        let db = Arc::new(db);

        // IMPORTANT: Do NOT call initialize_schema() or seed_core_schemas()
        // In HTTP mode, the server should already be initialized.
        // Calling these would try to recreate tables/schemas.
        tracing::info!("‚úÖ Connected to SurrealDB HTTP server");

        Ok(Self { db })
    }
}

impl<C> SurrealStore<C>
where
    C: surrealdb::Connection,
{
    /// Get the underlying database connection
    ///
    /// This is used by services (like SchemaService) that need direct database access
    /// for operations like DEFINE TABLE or DEFINE FIELD.
    pub fn db(&self) -> &Arc<Surreal<C>> {
        &self.db
    }

    /// Initialize database schema (universal node table + core type tables)
    ///
    /// Creates SCHEMALESS tables for flexible property handling while maintaining
    /// core field structure.
    ///
    /// # Graph-Native Architecture (Issue #511)
    /// - Table name: `node` (singular, consistent naming)
    /// - New fields: data, variants, _schema_version (initialized on creation)
    async fn initialize_schema(db: &Arc<Surreal<Db>>) -> Result<()> {
        // Universal node table (singular) - SCHEMALESS for maximum flexibility
        db.query(
            "
            DEFINE TABLE IF NOT EXISTS node SCHEMALESS;
            ",
        )
        .await
        .context("Failed to create universal node table")?;

        // Phase 6 (Issue #511): Only create type tables for types with properties
        // Types without properties (text, date, header, code_block, quote_block, ordered_list)
        // don't need separate tables - all data is in the node table
        let core_types_with_properties = ["task", "schema"];

        for node_type in core_types_with_properties {
            db.query(format!(
                "DEFINE TABLE IF NOT EXISTS {} SCHEMALESS;",
                node_type
            ))
            .await
            .with_context(|| format!("Failed to create {} table", node_type))?;
        }

        // Mentions table for reference graph
        db.query(
            "
            DEFINE TABLE IF NOT EXISTS mentions SCHEMALESS TYPE RELATION;
            ",
        )
        .await
        .context("Failed to create mentions table")?;

        // has_child graph edges for hierarchy
        // RELATE table for parent->child relationships
        // Replaces parent_id field-based queries with graph traversal
        db.query(
            "
            DEFINE TABLE IF NOT EXISTS has_child SCHEMALESS TYPE RELATION;
            ",
        )
        .await
        .context("Failed to create has_child relation table")?;

        // Critical indexes for graph traversal performance
        // Without these, traversal is O(n¬≤) - WITH them it's O(1) for parent/child lookups
        db.query(
            "
            DEFINE INDEX IF NOT EXISTS idx_has_child_in ON has_child FIELDS in;
            DEFINE INDEX IF NOT EXISTS idx_has_child_out ON has_child FIELDS out;
            ",
        )
        .await
        .context("Failed to create has_child indexes")?;

        Ok(())
    }

    /// Seed core schema definitions as nodes
    ///
    /// Creates schema nodes (node_type = "schema") with schema definitions
    /// stored in properties. Checks for existing schemas to be idempotent.
    async fn seed_core_schemas(db: &Arc<Surreal<Db>>) -> Result<()> {
        use serde_json::json;

        // Check if schemas already exist by trying to get one
        // If any schema exists, assume all are seeded (they're created atomically)
        // Use record ID for schema lookup
        let task_exists = db
            .query("SELECT * FROM type::thing('node', 'task') LIMIT 1")
            .await
            .context("Failed to check for existing schemas")?
            .take::<Option<SurrealNode>>(0)
            .ok()
            .flatten()
            .is_some();

        if task_exists {
            tracing::info!("‚úÖ Core schemas already seeded");
            return Ok(());
        }

        tracing::info!("üå± Seeding core schemas...");

        // Create temporary SurrealStore to use create_node method
        let store = SurrealStore::<Db> { db: Arc::clone(db) };

        let now = Utc::now();

        // Task schema
        let task_node = Node {
            id: "task".to_string(),
            node_type: "schema".to_string(),
            content: "Task".to_string(),
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Task tracking schema",
                "fields": [
                    {
                        "name": "status",
                        "type": "enum",
                        "protection": "core",
                        "core_values": ["OPEN", "IN_PROGRESS", "DONE"],
                        "user_values": [],
                        "indexed": true,
                        "required": true,
                        "extensible": true,
                        "default": "OPEN",
                        "description": "Task status"
                    },
                    {
                        "name": "priority",
                        "type": "enum",
                        "protection": "user",
                        "core_values": ["LOW", "MEDIUM", "HIGH"],
                        "user_values": [],
                        "indexed": true,
                        "required": false,
                        "extensible": true,
                        "description": "Task priority"
                    },
                    {
                        "name": "due_date",
                        "type": "date",
                        "protection": "user",
                        "indexed": true,
                        "required": false,
                        "description": "Due date"
                    },
                    {
                        "name": "started_at",
                        "type": "date",
                        "protection": "user",
                        "indexed": false,
                        "required": false,
                        "description": "Started at"
                    },
                    {
                        "name": "completed_at",
                        "type": "date",
                        "protection": "user",
                        "indexed": false,
                        "required": false,
                        "description": "Completed at"
                    },
                    {
                        "name": "assignee",
                        "type": "text",
                        "protection": "user",
                        "indexed": true,
                        "required": false,
                        "description": "Assignee"
                    }
                ]
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(task_node).await?;

        // Date schema
        let date_node = Node {
            id: "date".to_string(),
            node_type: "schema".to_string(),
            content: "Date".to_string(),
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Date node schema",
                "fields": []
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(date_node).await?;

        // Text schema
        let text_node = Node {
            id: "text".to_string(),
            node_type: "schema".to_string(),
            content: "Text".to_string(),
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Plain text content",
                "fields": []
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(text_node).await?;

        // Header schema
        let header_node = Node {
            id: "header".to_string(),
            node_type: "schema".to_string(),
            content: "Header".to_string(),
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Markdown header (h1-h6)",
                "fields": []
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(header_node).await?;

        // Code block schema
        let code_block_node = Node {
            id: "code-block".to_string(),
            node_type: "schema".to_string(),
            content: "Code Block".to_string(),
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Code block with syntax highlighting",
                "fields": []
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(code_block_node).await?;

        // Quote block schema
        let quote_block_node = Node {
            id: "quote-block".to_string(),
            node_type: "schema".to_string(),
            content: "Quote Block".to_string(),
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Blockquote for citations",
                "fields": []
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(quote_block_node).await?;

        // Ordered list schema
        let ordered_list_node = Node {
            id: "ordered-list".to_string(),
            node_type: "schema".to_string(),
            content: "Ordered List".to_string(),
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Numbered list item",
                "fields": []
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(ordered_list_node).await?;

        tracing::info!("‚úÖ Core schemas seeded successfully");

        Ok(())
    }

    /// Convert Turso-style ID to SurrealDB Record ID format
    ///
    /// Turso IDs are plain UUIDs. SurrealDB uses `table:uuid` format.
    /// This method extracts the type from the node and constructs the Record ID.
    ///
    /// # Arguments
    ///
    /// * `node_type` - The node type (becomes table name)
    /// * `id` - The UUID portion
    ///
    /// # Returns
    ///
    /// SurrealDB Record ID string: `table:uuid`
    fn to_record_id(node_type: &str, id: &str) -> String {
        format!("{}:{}", node_type, id)
    }

    /// Parse SurrealDB Record ID into (table, uuid) components
    ///
    /// # Arguments
    ///
    /// * `record_id` - SurrealDB Record ID (e.g., "task:uuid")
    ///
    /// # Returns
    ///
    /// Tuple of (table_name, uuid_portion)
    #[allow(dead_code)]
    fn parse_record_id(record_id: &str) -> Result<(String, String)> {
        let parts: Vec<&str> = record_id.splitn(2, ':').collect();
        if parts.len() != 2 {
            return Err(anyhow::anyhow!(
                "Invalid Record ID format: {}. Expected 'table:uuid'",
                record_id
            ));
        }
        Ok((parts[0].to_string(), parts[1].to_string()))
    }
}

impl<C> SurrealStore<C>
where
    C: surrealdb::Connection,
{
    pub async fn create_node(&self, node: Node) -> Result<Node> {
        // Convert embedding blob to f32 array if present
        // embedding_vector is already Vec<f32>, no conversion needed
        let embedding_f32 = node.embedding_vector.clone();

        // Insert into universal node table (graph-native architecture)
        // Record ID format: node:uuid (constructed by type::thing)
        // For types without dedicated tables (text, date, etc.), properties are stored here
        // For types with dedicated tables (task, schema), properties go in the type-specific table
        //
        // NOTE: _schema_version is managed by NodeService, not SurrealStore.
        // NodeService adds _schema_version only for node types with schema fields (task, person, etc.).
        // Types with empty schemas (text, date, header, etc.) don't need versioning.
        // Don't add _schema_version here - it causes properties pollution.
        let props_with_schema = node.properties.as_object().cloned().unwrap_or_default();

        let query = "
            CREATE type::thing($table, $id) CONTENT {
                type: $node_type,
                content: $content,
                before_sibling_id: $before_sibling_id,
                version: $version,
                created_at: $created_at,
                modified_at: $modified_at,
                embedding_vector: $embedding_vector,
                embedding_stale: $embedding_stale,
                mentions: $mentions,
                mentioned_by: $mentioned_by,
                data: $data,
                variants: $variants,
                properties: $properties
            };
        ";

        // Initialize graph-native fields
        let variants_value = serde_json::json!({});

        self.db
            .query(query)
            .bind(("table", "node"))
            .bind(("id", node.id.clone())) // Just the UUID, type::thing will construct node:uuid
            .bind(("node_type", node.node_type.clone()))
            .bind(("content", node.content.clone()))
            .bind(("before_sibling_id", node.before_sibling_id.clone()))
            .bind(("version", node.version))
            .bind(("created_at", node.created_at.to_rfc3339()))
            .bind(("modified_at", node.modified_at.to_rfc3339()))
            .bind(("embedding_vector", embedding_f32))
            .bind(("embedding_stale", false))
            .bind(("mentions", Vec::<String>::new()))
            .bind(("mentioned_by", Vec::<String>::new()))
            .bind(("data", None::<String>)) // Will be set below if type has properties
            .bind(("variants", variants_value))
            .bind(("properties", serde_json::Value::Object(props_with_schema)))
            .await
            .context("Failed to create node in universal table")?;

        // Insert into type-specific table for types with properties (task, schema)
        if TYPES_WITH_PROPERTIES.contains(&node.node_type.as_str())
            && !node
                .properties
                .as_object()
                .unwrap_or(&serde_json::Map::new())
                .is_empty()
        {
            // Store properties directly in type-specific table (flattened)
            self.db
                .query("CREATE type::thing($table, $id) CONTENT $properties;")
                .bind(("table", node.node_type.clone()))
                .bind(("id", node.id.clone()))
                .bind(("properties", node.properties.clone()))
                .await
                .context("Failed to create node in type-specific table")?;

            // Set data field to link to type-specific record
            self.db
                .query("UPDATE type::thing('node', $id) SET data = type::thing($type_table, $id);")
                .bind(("id", node.id.clone()))
                .bind(("type_table", node.node_type.clone()))
                .await
                .context("Failed to set data link")?;
        }

        // Note: Parent-child relationships are now established separately via move_node()
        // This allows cleaner separation of node creation from hierarchy management

        // Return the created node directly
        Ok(node)
    }

    /// Create a child node atomically with parent edge in a single transaction
    ///
    /// This is the atomic version of create_node + move_node. It guarantees that either:
    /// - The node, type-specific record (if applicable), and parent edge are ALL created
    /// - OR nothing is created (transaction rolls back on failure)
    ///
    /// # Performance Target
    /// - <15ms for create operation (from Issue #532 acceptance criteria)
    ///
    /// # Arguments
    ///
    /// * `parent_id` - ID of the parent node
    /// * `node_type` - Type of the node to create
    /// * `content` - Content of the node
    /// * `properties` - Properties for the node
    /// * `before_sibling_id` - Optional sibling ordering
    ///
    /// # Returns
    ///
    /// The created node with all fields populated
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use nodespace_core::db::SurrealStore;
    /// # use serde_json::json;
    /// # async fn example(store: &SurrealStore) -> anyhow::Result<()> {
    /// let child = store.create_child_node_atomic(
    ///     "parent-uuid",
    ///     "text",
    ///     "Child content",
    ///     json!({}),
    ///     None,
    /// ).await?;
    /// # Ok(())
    /// # }
    /// ```
    pub async fn create_child_node_atomic(
        &self,
        parent_id: &str,
        node_type: &str,
        content: &str,
        properties: Value,
        before_sibling_id: Option<&str>,
    ) -> Result<Node> {
        use uuid::Uuid;

        // Validate node type to prevent SQL injection
        validate_node_type(node_type)?;

        // Generate node ID and convert parameters to owned strings for 'static lifetime
        let node_id = Uuid::new_v4().to_string();
        let parent_id = parent_id.to_string();
        let node_type = node_type.to_string();
        let content = content.to_string();
        let before_sibling_id = before_sibling_id.map(|s| s.to_string());

        let now = Utc::now();
        let created_at = now.to_rfc3339();
        let modified_at = now.to_rfc3339();

        // Validate parent exists (prevent orphan nodes)
        let parent_exists = self.get_node(&parent_id).await?;
        if parent_exists.is_none() {
            return Err(anyhow::anyhow!("Parent node not found: {}", parent_id));
        }

        // Validate no cycle (prevent child from being ancestor of parent)
        self.validate_no_cycle(&parent_id, &node_id).await?;

        // Prepare properties for type-specific tables
        let props_with_schema = properties.as_object().cloned().unwrap_or_default();
        let has_type_table = TYPES_WITH_PROPERTIES.contains(&node_type.as_str());

        // Build atomic transaction query using quoted Record IDs with parameter binding
        // This ensures ALL operations succeed or ALL fail
        // Record IDs with hyphens must be quoted in backticks: `node:uuid-with-hyphens`
        let transaction_query = if has_type_table && !props_with_schema.is_empty() {
            // For types with dedicated tables (task, schema)
            r#"
                BEGIN TRANSACTION;

                -- Create node in universal table
                CREATE $node_id CONTENT {
                    type: $node_type,
                    content: $content,
                    before_sibling_id: $before_sibling_id,
                    version: 1,
                    created_at: $created_at,
                    modified_at: $modified_at,
                    embedding_vector: NONE,
                    embedding_stale: false,
                    mentions: [],
                    mentioned_by: [],
                    data: NONE,
                    variants: {},
                    properties: $properties
                };

                -- Create type-specific record
                CREATE $type_id CONTENT $properties;

                -- Link node to type-specific record
                UPDATE $node_id SET data = $type_id;

                -- Create parent-child edge (parent->has_child->child)
                RELATE $parent_id->has_child->$node_id;

                COMMIT TRANSACTION;
            "#
            .to_string()
        } else {
            // For types without dedicated tables (text, date, etc.)
            r#"
                BEGIN TRANSACTION;

                -- Create node in universal table
                CREATE $node_id CONTENT {
                    type: $node_type,
                    content: $content,
                    before_sibling_id: $before_sibling_id,
                    version: 1,
                    created_at: $created_at,
                    modified_at: $modified_at,
                    embedding_vector: NONE,
                    embedding_stale: false,
                    mentions: [],
                    mentioned_by: [],
                    data: NONE,
                    variants: {},
                    properties: $properties
                };

                -- Create parent-child edge (parent->has_child->child)
                RELATE $parent_id->has_child->$node_id;

                COMMIT TRANSACTION;
            "#
            .to_string()
        };

        // Construct Thing objects for Record IDs
        // Thing format: table name paired with ID
        let node_thing = surrealdb::sql::Thing::from(("node".to_string(), node_id.clone()));
        let parent_thing = surrealdb::sql::Thing::from(("node".to_string(), parent_id.clone()));
        let type_thing = surrealdb::sql::Thing::from((node_type.clone(), node_id.clone()));

        // Execute transaction (we don't care about the return value, just the side effects)
        self.db
            .query(transaction_query)
            .bind(("node_id", node_thing))
            .bind(("parent_id", parent_thing))
            .bind(("type_id", type_thing))
            .bind(("node_type", node_type.clone()))
            .bind(("content", content.clone()))
            .bind(("before_sibling_id", before_sibling_id.clone()))
            .bind(("created_at", created_at.clone()))
            .bind(("modified_at", modified_at.clone()))
            .bind(("properties", Value::Object(props_with_schema.clone())))
            .await
            .map(|_| ())
            .context(format!(
                "Failed to create child node '{}' under parent '{}'",
                node_id, parent_id
            ))?;

        // Construct and return the created node
        Ok(Node {
            id: node_id,
            node_type,
            content,
            before_sibling_id,
            version: 1,
            created_at: now,
            modified_at: now,
            properties,
            embedding_vector: None,
            mentions: Vec::new(),
            mentioned_by: Vec::new(),
        })
    }

    pub async fn get_node(&self, id: &str) -> Result<Option<Node>> {
        // Direct record ID lookup (O(1) primary key access)
        // Note: We don't use FETCH data because it causes deserialization issues
        // with the polymorphic data field (Thing vs Object)
        let query = "SELECT * FROM type::thing('node', $id);";
        let mut response = self
            .db
            .query(query)
            .bind(("id", id.to_string()))
            .await
            .context("Failed to query node by record ID")?;

        let surreal_nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract query results")?;

        let mut node_opt: Option<Node> = surreal_nodes.into_iter().map(Into::into).next();

        // If node exists and has properties (types: task, schema), fetch them separately
        if let Some(ref mut node) = node_opt {
            let types_with_properties = ["task", "schema"];
            if types_with_properties.contains(&node.node_type.as_str()) {
                // Fetch properties using SQL query, excluding 'id' field to avoid Thing deserialization issues
                // SELECT * OMIT id gets all fields except the id (which is a Thing type that can't deserialize to JSON)
                let props_query = format!(
                    "SELECT * OMIT id FROM type::thing('{}', $id);",
                    node.node_type
                );
                let mut props_response = self
                    .db
                    .query(&props_query)
                    .bind(("id", id.to_string()))
                    .await;

                let result: Option<serde_json::Value> = match props_response {
                    Ok(ref mut response) => {
                        let raw: Result<
                            Vec<std::collections::HashMap<String, serde_json::Value>>,
                            _,
                        > = response.take(0);
                        match raw {
                            Ok(records) => {
                                let props_opt = records.into_iter().next().map(|map| {
                                    tracing::debug!(
                                        "Raw properties from {}: {:?}",
                                        node.node_type,
                                        map
                                    );
                                    serde_json::Value::Object(map.into_iter().collect())
                                });
                                tracing::debug!(
                                    "get_node({}) - properties after conversion: {:?}",
                                    id,
                                    props_opt
                                );
                                props_opt
                            }
                            Err(e) => {
                                tracing::warn!("get_node({}) - failed to deserialize: {:?}", id, e);
                                None
                            }
                        }
                    }
                    Err(e) => {
                        tracing::warn!("get_node({}) - query failed: {:?}", id, e);
                        None
                    }
                };

                if let Some(props) = result {
                    // Properties already exclude 'id' due to OMIT in query
                    node.properties = props;
                }
            }
        }

        Ok(node_opt)
    }

    pub async fn update_node(&self, id: &str, update: NodeUpdate) -> Result<Node> {
        // Fetch current node
        let current = self
            .get_node(id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Node not found: {}", id))?;

        let updated_content = update.content.unwrap_or(current.content);
        let updated_node_type = update.node_type.unwrap_or(current.node_type.clone());

        // embedding_vector is already Vec<f32>, no conversion needed
        let embedding_f32 = update.embedding_vector.flatten();

        // Merge properties if they're being updated
        // For types without dedicated tables (text, date, etc.), store properties directly in universal table
        //
        // NOTE: _schema_version is managed by NodeService, not SurrealStore.
        // NodeService adds _schema_version only for node types with schema fields.
        // Don't add/preserve _schema_version here - it causes properties pollution.
        let properties_update = if let Some(ref updated_props) = update.properties {
            let mut merged_props = current.properties.as_object().cloned().unwrap_or_default();
            if let Some(new_props) = updated_props.as_object() {
                for (key, value) in new_props {
                    merged_props.insert(key.clone(), value.clone());
                }
            }
            // Properties are merged as-is - no automatic _schema_version insertion
            Some(serde_json::Value::Object(merged_props))
        } else {
            None
        };

        // Build update query - include properties if they're being updated
        let (query, bind_properties) = if properties_update.is_some() {
            (
                "
                UPDATE type::thing('node', $id) SET
                    content = $content,
                    type = $node_type,
                    before_sibling_id = $before_sibling_id,
                    modified_at = time::now(),
                    version = version + 1,
                    embedding_vector = $embedding_vector,
                    properties = $properties;
            ",
                true,
            )
        } else {
            (
                "
                UPDATE type::thing('node', $id) SET
                    content = $content,
                    type = $node_type,
                    before_sibling_id = $before_sibling_id,
                    modified_at = time::now(),
                    version = version + 1,
                    embedding_vector = $embedding_vector;
            ",
                false,
            )
        };

        let mut query_builder = self
            .db
            .query(query)
            .bind(("id", id.to_string()))
            .bind(("content", updated_content))
            .bind(("node_type", updated_node_type.clone()))
            .bind(("before_sibling_id", update.before_sibling_id.flatten()))
            .bind(("embedding_vector", embedding_f32));

        if bind_properties {
            query_builder = query_builder.bind(("properties", properties_update.unwrap()));
        }

        query_builder.await.context("Failed to update node")?;

        // If properties were provided and node type has type-specific table, update it there too
        if let Some(updated_props) = update.properties {
            if TYPES_WITH_PROPERTIES.contains(&updated_node_type.as_str()) {
                // UPSERT with MERGE to preserve existing spoke data on type reconversions
                // Scenario: text‚Üítask creates task:uuid, task‚Üítext preserves it, text‚Üítask reconnects
                // MERGE ensures old task properties (priority, due_date) aren't lost on reconversion
                // Only adds missing defaults, preserves user-set values
                self.db
                    .query("UPSERT type::thing($table, $id) MERGE $properties;")
                    .bind(("table", updated_node_type.clone()))
                    .bind(("id", id.to_string()))
                    .bind(("properties", updated_props))
                    .await
                    .context("Failed to upsert properties in type-specific table")?;

                // Ensure data link exists (in case this is a type change)
                self.db
                    .query(
                        "UPDATE type::thing('node', $id) SET data = type::thing($type_table, $id);",
                    )
                    .bind(("id", id.to_string()))
                    .bind(("type_table", updated_node_type))
                    .await
                    .context("Failed to set data link")?;
            }
        }

        // Fetch and return updated node
        self.get_node(id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Node not found after update"))
    }

    /// Switch a node's type atomically, preserving old type in variants map
    ///
    /// This is an atomic type-switching operation that guarantees:
    /// - Node type is updated
    /// - New type-specific record is created (if type has properties)
    /// - Old type is preserved in variants map for lossless recovery
    /// - All updates happen atomically (all or nothing)
    ///
    /// # Variants Map Pattern
    ///
    /// The variants map stores the history of type-specific record IDs:
    /// ```json
    /// {
    ///   "task": "task:uuid-123",
    ///   "text": null,
    ///   "person": "person:uuid-456"
    /// }
    /// ```
    ///
    /// This enables:
    /// - Lossless type switching (can restore old properties)
    /// - Type history tracking
    /// - Future multi-type node support
    ///
    /// # Arguments
    ///
    /// * `node_id` - ID of the node to switch
    /// * `new_type` - New node type
    /// * `new_properties` - Properties for the new type
    ///
    /// # Returns
    ///
    /// The updated node with new type
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use nodespace_core::db::SurrealStore;
    /// # use serde_json::json;
    /// # async fn example(store: &SurrealStore) -> anyhow::Result<()> {
    /// // Switch a text node to a task node
    /// let node = store.switch_node_type_atomic(
    ///     "node-uuid",
    ///     "task",
    ///     json!({"status": "TODO", "priority": "HIGH"}),
    /// ).await?;
    /// # Ok(())
    /// # }
    /// ```
    pub async fn switch_node_type_atomic(
        &self,
        node_id: &str,
        new_type: &str,
        new_properties: Value,
    ) -> Result<Node> {
        // Validate new_type to prevent SQL injection
        validate_node_type(new_type)?;

        // Convert parameters to owned strings for 'static lifetime
        let node_id = node_id.to_string();
        let new_type = new_type.to_string();

        // Validate node exists
        let current_node = self
            .get_node(&node_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Node not found: {}", node_id))?;

        let old_type = current_node.node_type.clone();
        let now = Utc::now();
        let modified_at = now.to_rfc3339();

        // Build variants update: preserve old type, add new type
        // variants map format: {"task": "task:uuid", "text": null, ...}
        let old_type_record = if TYPES_WITH_PROPERTIES.contains(&old_type.as_str()) {
            format!("{}:{}", old_type, node_id)
        } else {
            "null".to_string()
        };

        let new_type_record = if TYPES_WITH_PROPERTIES.contains(&new_type.as_str()) {
            format!("{}:{}", new_type, node_id)
        } else {
            "null".to_string()
        };

        // Prepare properties
        let props_with_schema = new_properties.as_object().cloned().unwrap_or_default();
        let has_new_type_table = TYPES_WITH_PROPERTIES.contains(&new_type.as_str());

        // Build atomic transaction using Thing parameters
        let transaction_query = if has_new_type_table && !props_with_schema.is_empty() {
            // New type has properties table
            r#"
                BEGIN TRANSACTION;

                -- Update node type and variants map
                UPDATE $node_id SET
                    type = $new_type,
                    modified_at = $modified_at,
                    version = version + 1,
                    variants[$old_type] = $old_type_record,
                    variants[$new_type] = $new_type_id,
                    properties = $properties;

                -- Create new type-specific record
                CREATE $new_type_id CONTENT $properties;

                -- Update data link to point to new type-specific record
                UPDATE $node_id SET data = $new_type_id;

                COMMIT TRANSACTION;
            "#
            .to_string()
        } else {
            // New type doesn't have properties table
            r#"
                BEGIN TRANSACTION;

                -- Update node type and variants map
                UPDATE $node_id SET
                    type = $new_type,
                    modified_at = $modified_at,
                    version = version + 1,
                    variants[$old_type] = $old_type_record,
                    variants[$new_type] = $new_type_record,
                    properties = $properties,
                    data = NONE;

                COMMIT TRANSACTION;
            "#
            .to_string()
        };

        // Construct Thing objects for Record IDs
        let node_thing = surrealdb::sql::Thing::from(("node".to_string(), node_id.clone()));
        let new_type_thing = surrealdb::sql::Thing::from((new_type.clone(), node_id.clone()));

        // Execute transaction (we don't care about the return value, just the side effects)
        self.db
            .query(transaction_query)
            .bind(("node_id", node_thing))
            .bind(("new_type_id", new_type_thing))
            .bind(("new_type", new_type.clone()))
            .bind(("old_type", old_type.clone()))
            .bind(("old_type_record", old_type_record))
            .bind(("new_type_record", new_type_record))
            .bind(("modified_at", modified_at))
            .bind(("properties", Value::Object(props_with_schema)))
            .await
            .map(|_| ())
            .context(format!(
                "Failed to switch node '{}' type from '{}' to '{}'",
                node_id, old_type, new_type
            ))?;

        // Fetch and return updated node
        self.get_node(&node_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Node not found after type switch for '{}'", node_id))
    }

    /// Update a node with version check (optimistic locking)
    ///
    /// Only updates the node if its version matches the expected version.
    /// This provides atomic version-checked updates to prevent lost updates
    /// in concurrent scenarios.
    ///
    /// # Arguments
    ///
    /// * `id` - Node UUID to update
    /// * `expected_version` - Expected current version (for optimistic locking)
    /// * `update` - Fields to update
    ///
    /// # Returns
    ///
    /// * `Ok(Some(Node))` - Update succeeded, returns updated node
    /// * `Ok(None)` - Version mismatch, no update performed
    /// * `Err(_)` - Database error or node not found
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// # use nodespace_core::db::SurrealStore;
    /// # use nodespace_core::models::NodeUpdate;
    /// # use std::path::PathBuf;
    /// # #[tokio::main]
    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// # let store = SurrealStore::new(PathBuf::from("./data/surreal.db")).await?;
    /// let update = NodeUpdate {
    ///     content: Some("Updated content".to_string()),
    ///     ..Default::default()
    /// };
    ///
    /// match store.update_node_with_version_check("node-id", 5, update).await? {
    ///     Some(node) => println!("Updated to version {}", node.version),
    ///     None => println!("Version mismatch - node was modified by another process"),
    /// }
    /// # Ok(())
    /// # }
    /// ```
    pub async fn update_node_with_version_check(
        &self,
        id: &str,
        expected_version: i64,
        update: NodeUpdate,
    ) -> Result<Option<Node>> {
        // Fetch current node to build update values
        let current = self
            .get_node(id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Node not found: {}", id))?;

        // Calculate new version for explicit binding
        let new_version = expected_version + 1;

        // Atomic update with version check using record ID
        // SurrealDB's UPDATE returns the updated records
        let query = "
            UPDATE type::thing('node', $id) SET
                content = $content,
                type = $node_type,
                before_sibling_id = $before_sibling_id,
                properties = $properties,
                modified_at = time::now(),
                version = $new_version,
                embedding_vector = $embedding_vector
            WHERE version = $expected_version
            RETURN AFTER;
        ";

        let updated_content = update.content.unwrap_or(current.content);
        let updated_node_type = update.node_type.unwrap_or(current.node_type.clone());
        let updated_properties = update.properties.unwrap_or(current.properties);

        // embedding_vector is already Vec<f32>, no conversion needed
        let embedding_f32 = update.embedding_vector.flatten();

        let mut response = self
            .db
            .query(query)
            .bind(("id", id.to_string()))
            .bind(("expected_version", expected_version))
            .bind(("new_version", new_version))
            .bind(("content", updated_content))
            .bind(("node_type", updated_node_type))
            .bind(("before_sibling_id", update.before_sibling_id.flatten()))
            .bind(("properties", updated_properties))
            .bind(("embedding_vector", embedding_f32))
            .await
            .context("Failed to update node with version check")?;

        // Extract updated nodes from response
        let updated_nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract update results")?;

        // If no nodes were updated, version mismatch occurred
        if updated_nodes.is_empty() {
            return Ok(None);
        }

        // Convert and return the updated node
        Ok(Some(updated_nodes.into_iter().next().unwrap().into()))
    }

    pub async fn delete_node(&self, id: &str) -> Result<DeleteResult> {
        // Get node to determine type for Record ID
        let node = match self.get_node(id).await? {
            Some(n) => n,
            None => return Ok(DeleteResult { existed: false }),
        };

        // Delete using record IDs and graph edges
        // Use transaction for atomicity (all or nothing)
        let transaction_query = "
            BEGIN TRANSACTION;
            DELETE type::thing($table, $id);
            DELETE type::thing('node', $id);
            DELETE mentions WHERE in = type::thing('node', $id) OR out = type::thing('node', $id);
            DELETE has_child WHERE in = type::thing('node', $id) OR out = type::thing('node', $id);
            COMMIT TRANSACTION;
        ";

        self.db
            .query(transaction_query)
            .bind(("table", node.node_type.clone()))
            .bind(("id", node.id.clone()))
            .await
            .context("Failed to delete node and relations")?;

        Ok(DeleteResult { existed: true })
    }

    /// Delete a node with cascade cleanup in a single atomic transaction
    ///
    /// This is an enhanced atomic version of delete_node. It guarantees that either:
    /// - The node, type-specific record, all edges, and all mentions are ALL deleted
    /// - OR nothing is deleted (transaction rolls back on failure)
    ///
    /// # Cascade Cleanup
    ///
    /// Deletes the following in one atomic transaction:
    /// - Node record from universal `node` table
    /// - Type-specific record (if type has properties table)
    /// - All incoming and outgoing `has_child` edges
    /// - All incoming and outgoing `mentions` edges
    ///
    /// # Arguments
    ///
    /// * `node_id` - ID of the node to delete
    ///
    /// # Returns
    ///
    /// DeleteResult indicating whether the node existed
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use nodespace_core::db::SurrealStore;
    /// # async fn example(store: &SurrealStore) -> anyhow::Result<()> {
    /// let result = store.delete_node_cascade_atomic("node-uuid").await?;
    /// assert!(result.existed);
    /// # Ok(())
    /// # }
    /// ```
    pub async fn delete_node_cascade_atomic(&self, node_id: &str) -> Result<DeleteResult> {
        // Get node to determine type for Record ID
        let node = match self.get_node(node_id).await? {
            Some(n) => n,
            None => return Ok(DeleteResult { existed: false }),
        };

        // Build atomic cascade delete transaction using Thing parameters
        // This ensures ALL related data is deleted or NOTHING is deleted
        let node_type = node.node_type.clone();
        let node_id = node.id.clone();

        let transaction_query = r#"
            BEGIN TRANSACTION;

            -- Delete type-specific record (if exists)
            DELETE $type_id;

            -- Delete node from universal table
            DELETE $node_id;

            -- Delete all has_child edges (incoming and outgoing)
            DELETE has_child WHERE in = $node_id OR out = $node_id;

            -- Delete all mention edges (incoming and outgoing)
            DELETE mentions WHERE in = $node_id OR out = $node_id;

            COMMIT TRANSACTION;
        "#
        .to_string();

        // Construct Thing objects for Record IDs
        let node_thing = surrealdb::sql::Thing::from(("node".to_string(), node_id.clone()));
        let type_thing = surrealdb::sql::Thing::from((node_type.clone(), node_id.clone()));

        // Execute transaction (we don't care about the return value, just the side effects)
        self.db
            .query(&transaction_query)
            .bind(("node_id", node_thing))
            .bind(("type_id", type_thing))
            .await
            .map(|_| ())
            .context(format!(
                "Failed to delete node '{}' (type: {}) with cascade",
                node_id, node_type
            ))?;

        Ok(DeleteResult { existed: true })
    }

    /// Delete a node with version check (optimistic locking)
    ///
    /// Only deletes the node if its version matches the expected version.
    /// Returns the number of rows affected (0 if version mismatch, 1 if deleted).
    pub async fn delete_with_version_check(
        &self,
        id: &str,
        expected_version: i64,
    ) -> Result<usize> {
        // First get the node to check version
        let node = match self.get_node(id).await? {
            Some(n) => n,
            None => return Ok(0), // Node doesn't exist
        };

        // Check version match
        if node.version != expected_version {
            return Ok(0); // Version mismatch, no deletion
        }

        // Version matches, proceed with deletion
        let result = self.delete_node(id).await?;
        Ok(if result.existed { 1 } else { 0 })
    }

    pub async fn query_nodes(&self, query: NodeQuery) -> Result<Vec<Node>> {
        // Handle mentioned_by query using graph traversal
        if let Some(ref mentioned_node_id) = query.mentioned_by {
            // Get the mentioned node to construct proper Record ID
            let mentioned_node = self
                .get_node(mentioned_node_id)
                .await?
                .ok_or_else(|| anyhow::anyhow!("Target node not found: {}", mentioned_node_id))?;

            let record_id = Self::to_record_id(&mentioned_node.node_type, &mentioned_node.id);
            let thing = Thing::from(("nodes", Id::String(record_id)));

            // Query nodes that have mentions pointing to this node
            let sql = if query.limit.is_some() {
                "SELECT VALUE in FROM mentions WHERE out = $target_thing LIMIT $limit;"
            } else {
                "SELECT VALUE in FROM mentions WHERE out = $target_thing;"
            };

            let mut query_builder = self.db.query(sql).bind(("target_thing", thing));

            if let Some(limit) = query.limit {
                query_builder = query_builder.bind(("limit", limit));
            }

            let mut response = query_builder
                .await
                .context("Failed to query mentioned_by nodes")?;

            let source_things: Vec<Thing> = response
                .take(0)
                .context("Failed to extract source nodes from mentions")?;

            // Fetch full node records for each source
            let mut nodes = Vec::new();
            for thing in source_things {
                if let Id::String(id_str) = &thing.id {
                    // Extract UUID from "node_type:uuid" format
                    if let Some(uuid) = id_str.split(':').nth(1) {
                        if let Some(node) = self.get_node(uuid).await? {
                            nodes.push(node);
                        }
                    }
                }
            }

            // Note: include_containers_and_tasks filter not applicable for semantic search
            // (would require additional graph query to check hierarchy)

            return Ok(nodes);
        }

        // Handle content_contains query
        if let Some(ref search_query) = query.content_contains {
            let nodes = self
                .search_nodes_by_content(search_query, query.limit.map(|l| l as i64))
                .await?;

            // Note: include_containers_and_tasks filter not applicable for content search
            // (would require additional graph query to check hierarchy)

            return Ok(nodes);
        }

        // Build WHERE clause conditions
        let mut conditions = Vec::new();

        if query.node_type.is_some() {
            conditions.push("type = $node_type".to_string());
        }

        // Note: include_containers_and_tasks field removed - use graph edges and separate queries instead

        // Build SQL query
        let where_clause = if !conditions.is_empty() {
            Some(conditions.join(" AND "))
        } else {
            None
        };

        let sql = match (&where_clause, query.limit) {
            (None, None) => "SELECT * FROM node;".to_string(),
            (None, Some(_)) => "SELECT * FROM node LIMIT $limit;".to_string(),
            (Some(clause), None) => format!("SELECT * FROM node WHERE {};", clause),
            (Some(clause), Some(_)) => {
                format!("SELECT * FROM node WHERE {} LIMIT $limit;", clause)
            }
        };

        let mut query_builder = self.db.query(sql);

        if let Some(node_type) = &query.node_type {
            query_builder = query_builder.bind(("node_type", node_type.clone()));
        }

        if let Some(limit) = query.limit {
            query_builder = query_builder.bind(("limit", limit));
        }

        let mut response = query_builder.await.context("Failed to query nodes")?;
        let surreal_nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract nodes from query response")?;
        Ok(surreal_nodes.into_iter().map(Into::into).collect())
    }

    pub async fn get_children(&self, parent_id: Option<&str>) -> Result<Vec<Node>> {
        // Use graph edges for hierarchy traversal
        // Note: We don't use FETCH data because it causes deserialization issues (same as get_node)
        let surreal_nodes = if let Some(parent_id) = parent_id {
            // Create Thing record ID for parent node
            use surrealdb::sql::Thing;
            let parent_thing = Thing::from(("node".to_string(), parent_id.to_string()));

            // Query without FETCH - we'll manually fetch properties afterward
            let mut response = self
                .db
                .query("SELECT * FROM node WHERE id IN (SELECT VALUE out FROM has_child WHERE in = $parent_thing);")
                .bind(("parent_thing", parent_thing))
                .await
                .context("Failed to get children")?;

            let nodes: Vec<SurrealNode> = response
                .take(0)
                .context("Failed to extract children from response")?;

            nodes
        } else {
            // Root nodes: nodes that have NO incoming has_child edges
            let mut response = self
                .db
                .query("SELECT * FROM node WHERE count(<-has_child) = 0;")
                .await
                .context("Failed to get root nodes")?;

            let nodes: Vec<SurrealNode> = response
                .take(0)
                .context("Failed to extract root nodes from response")?;

            nodes
        };

        // Convert to nodes
        let mut nodes: Vec<Node> = surreal_nodes.into_iter().map(Into::into).collect();

        // Batch fetch properties for nodes that have them
        // Performance: 100 nodes with properties = 2-3 queries (vs 101 with N+1 pattern)
        use std::collections::HashMap;

        // Group nodes by type for batch fetching
        let mut nodes_by_type: HashMap<String, Vec<String>> = HashMap::new();
        for node in &nodes {
            if TYPES_WITH_PROPERTIES.contains(&node.node_type.as_str()) {
                nodes_by_type
                    .entry(node.node_type.clone())
                    .or_default()
                    .push(node.id.clone());
            }
        }

        // Batch fetch properties for each type
        let mut all_properties: HashMap<String, Value> = HashMap::new();
        for (node_type, node_ids) in nodes_by_type {
            match batch_fetch_properties(&self.db, &node_type, &node_ids).await {
                Ok(props_map) => {
                    all_properties.extend(props_map);
                }
                Err(e) => {
                    tracing::warn!(
                        "Failed to batch fetch properties for type '{}': {}",
                        node_type,
                        e
                    );
                }
            }
        }

        // Hydrate properties into nodes
        for node in &mut nodes {
            if let Some(props) = all_properties.get(&node.id) {
                node.properties = props.clone();
            }
        }

        // Sort by before_sibling_id in-memory (topological sort of linked list)
        // TODO: Implement proper linked list ordering
        Ok(nodes)
    }

    /// Get the parent of a node (via incoming has_child edge)
    ///
    /// Returns the node's parent if it has one, or None if it's a root node.
    ///
    /// # Arguments
    ///
    /// * `child_id` - The child node ID
    ///
    /// # Returns
    ///
    /// `Some(parent_node)` if the node has a parent, `None` if it's a root node
    pub async fn get_parent(&self, child_id: &str) -> Result<Option<Node>> {
        use surrealdb::sql::Thing;
        let child_thing = Thing::from(("node".to_string(), child_id.to_string()));

        // Query for parent via incoming has_child edge
        // SELECT * FROM node WHERE id IN (SELECT VALUE in FROM has_child WHERE out = $child_thing)
        let mut response = self
            .db
            .query("SELECT * FROM node WHERE id IN (SELECT VALUE in FROM has_child WHERE out = $child_thing) LIMIT 1;")
            .bind(("child_thing", child_thing))
            .await
            .context("Failed to get parent")?;

        let nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract parent from response")?;

        if nodes.is_empty() {
            return Ok(None);
        }

        // Convert to node and fetch properties if needed
        let mut node: Node = nodes.into_iter().next().unwrap().into();

        // Fetch properties if this node type has them
        if TYPES_WITH_PROPERTIES.contains(&node.node_type.as_str()) {
            if let Ok(props_map) =
                batch_fetch_properties(&self.db, &node.node_type, &[node.id.clone()]).await
            {
                if let Some(props) = props_map.get(&node.id) {
                    node.properties = props.clone();
                }
            }
        }

        Ok(Some(node))
    }

    /// Get entire node tree recursively in a SINGLE query
    ///
    /// This method leverages SurrealDB's recursive graph traversal to fetch
    /// a node and ALL its descendants at all levels in one database query.
    ///
    /// # Performance
    ///
    /// - **1 query** regardless of tree depth/size (vs N queries for manual traversal)
    /// - Ideal for: outline view, export, tree visualization
    ///
    /// # Arguments
    ///
    /// * `root_id` - ID of the root node to fetch tree from
    ///
    /// # Returns
    ///
    /// Returns root node with nested `children` arrays at all levels.
    /// Each node includes properties fetched from type-specific tables.
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// // Get entire tree in ONE query:
    /// let tree = store.get_node_tree("root-uuid").await?;
    /// // tree.children[0].children[0]... (fully nested)
    /// ```
    ///
    /// # Implementation Note
    ///
    /// Uses SurrealDB's `@` recursive projection operator:
    /// ```sql
    /// SELECT id, title,
    ///   ->has_child->node.{
    ///     id, title,
    ///     children: ->has_child->node.@  -- '@' repeats this projection recursively
    ///   } AS children
    /// FROM node:root_uuid;
    /// ```
    pub async fn get_node_tree(&self, root_id: &str) -> Result<Option<serde_json::Value>> {
        use surrealdb::sql::Thing;

        let root_thing = Thing::from(("node".to_string(), root_id.to_string()));

        // Recursive query with @ operator for infinite depth traversal
        let query = "
            SELECT
                id,
                type,
                content,
                before_sibling_id,
                version,
                created_at,
                modified_at,
                embedding_vector,
                embedding_stale,
                mentions,
                mentioned_by,
                data,
                variants,
                _schema_version,
                ->has_child->node.{
                    id,
                    type,
                    content,
                    before_sibling_id,
                    version,
                    created_at,
                    modified_at,
                    embedding_vector,
                    embedding_stale,
                    mentions,
                    mentioned_by,
                    data,
                    variants,
                    _schema_version,
                    children: ->has_child->node.@
                } AS children
            FROM $root_thing
            FETCH data;
        ";

        let mut response = self
            .db
            .query(query)
            .bind(("root_thing", root_thing))
            .await
            .context("Failed to fetch node tree")?;

        let results: Vec<serde_json::Value> = response
            .take(0)
            .context("Failed to parse node tree results")?;

        if results.is_empty() {
            return Ok(None);
        }

        // Return the tree as raw JSON (frontend can deserialize as needed)
        Ok(Some(results[0].clone()))
    }

    pub async fn search_nodes_by_content(
        &self,
        search_query: &str,
        limit: Option<i64>,
    ) -> Result<Vec<Node>> {
        // Use string::lowercase() for case-insensitive search
        // SurrealDB CONTAINS is case-sensitive by default
        let sql = if limit.is_some() {
            "SELECT * FROM node WHERE string::lowercase(content) CONTAINS string::lowercase($search_query) LIMIT $limit;"
        } else {
            "SELECT * FROM node WHERE string::lowercase(content) CONTAINS string::lowercase($search_query);"
        };

        let mut query_builder = self
            .db
            .query(sql)
            .bind(("search_query", search_query.to_string()));

        if let Some(lim) = limit {
            query_builder = query_builder.bind(("limit", lim));
        }

        let mut response = query_builder.await.context("Failed to search nodes")?;
        let surreal_nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract search results from response")?;
        Ok(surreal_nodes.into_iter().map(Into::into).collect())
    }

    /// Validate that creating a parent-child relationship won't create a cycle
    ///
    /// **Purpose**: Prevents cyclic references in the node hierarchy tree.
    ///
    /// **Example Cycle**: A‚ÜíB‚ÜíC‚ÜíA (adding A as child of C would create this)
    ///
    /// **Impact if not validated**:
    /// - Infinite loops in tree traversal queries
    /// - Stack overflow in recursive operations
    /// - Data corruption in hierarchy
    ///
    /// # Arguments
    ///
    /// * `parent_id` - Proposed parent node ID
    /// * `child_id` - Proposed child node ID
    ///
    /// # Returns
    ///
    /// `Ok(())` if no cycle would be created, `Err` if cycle detected
    ///
    /// # Examples
    ///
    /// ```
    /// // Valid: A‚ÜíB, B‚ÜíC (adding C as child of B)
    /// validate_no_cycle("B", "C").await?; // ‚úì OK
    ///
    /// // Invalid: A‚ÜíB‚ÜíC, trying to add A as child of C
    /// validate_no_cycle("C", "A").await?; // ‚úó Error: would create cycle A‚ÜíB‚ÜíC‚ÜíA
    /// ```
    async fn validate_no_cycle(&self, parent_id: &str, child_id: &str) -> Result<()> {
        use surrealdb::sql::Thing;

        // Check if parent is a descendant of child
        // If so, creating this edge would create a cycle
        let child_thing = Thing::from(("node".to_string(), child_id.to_string()));

        // Query: Get all descendants of child node recursively
        // Then check if parent is in that list
        // Using SurrealDB recursive graph traversal syntax (v2.1+) to check ALL descendant levels
        // The `{..+collect}` syntax means unbounded recursive traversal collecting unique nodes
        // This will detect cycles at any level: A‚ÜíB (direct), A‚ÜíB‚ÜíC (3-node), A‚ÜíB‚ÜíC‚ÜíD (4-node), etc.
        let query = "
            LET $descendants = $child_thing.{..+collect}->has_child->node;
            SELECT * FROM type::thing('node', $parent_id)
            WHERE id IN $descendants
            LIMIT 1;
        ";

        let mut response = self
            .db
            .query(query)
            .bind(("parent_id", parent_id.to_string()))
            .bind(("child_thing", child_thing))
            .await
            .context("Failed to check for cycles")?;

        // The query has 2 statements (LET, SELECT), we want the SELECT result at index 1
        let results: Vec<SurrealNode> = response
            .take(1)
            .context("Failed to parse cycle check results")?;

        if !results.is_empty() {
            return Err(anyhow::anyhow!(
                "Cannot create parent-child relationship: would create cycle. \
                Node '{}' is a descendant of node '{}', so '{}' cannot be a parent of '{}'.",
                parent_id,
                child_id,
                parent_id,
                child_id
            ));
        }

        Ok(())
    }

    pub async fn move_node(&self, id: &str, new_parent_id: Option<&str>) -> Result<()> {
        use surrealdb::sql::Thing;

        // Validate that moving won't create a cycle
        if let Some(parent_id) = new_parent_id {
            self.validate_no_cycle(parent_id, id).await?;
        }

        // Delete existing parent edge
        let child_thing = Thing::from(("node".to_string(), id.to_string()));
        self.db
            .query("DELETE has_child WHERE out = $child_thing;")
            .bind(("child_thing", child_thing.clone()))
            .await
            .context("Failed to delete existing parent edge")?;

        // Create new parent edge if parent is specified
        if let Some(parent_id) = new_parent_id {
            let parent_thing = Thing::from(("node".to_string(), parent_id.to_string()));
            self.db
                .query("RELATE $parent_thing->has_child->$child_thing;")
                .bind(("parent_thing", parent_thing))
                .bind(("child_thing", child_thing))
                .await
                .context("Failed to create new parent edge")?;
        }

        Ok(())
    }

    /// Move a node to a new parent atomically
    ///
    /// This is the atomic version of move_node. It guarantees that either:
    /// - The old edge is deleted AND the new edge is created
    /// - OR nothing changes (transaction rolls back on failure)
    ///
    /// # Arguments
    ///
    /// * `node_id` - ID of the node to move
    /// * `new_parent_id` - ID of the new parent (None = make root node)
    /// * `new_before_sibling_id` - Optional sibling ordering in new location
    ///
    /// # Returns
    ///
    /// Ok(()) on success
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// # use nodespace_core::db::SurrealStore;
    /// # async fn example(store: &SurrealStore) -> anyhow::Result<()> {
    /// // Move node to new parent
    /// store.move_node_atomic("child-uuid", Some("new-parent-uuid"), None).await?;
    ///
    /// // Make node a root node
    /// store.move_node_atomic("child-uuid", None, None).await?;
    /// # Ok(())
    /// # }
    /// ```
    pub async fn move_node_atomic(
        &self,
        node_id: &str,
        new_parent_id: Option<&str>,
        new_before_sibling_id: Option<&str>,
    ) -> Result<()> {
        // Convert parameters to owned strings for 'static lifetime
        let node_id = node_id.to_string();
        let new_parent_id = new_parent_id.map(|s| s.to_string());
        let new_before_sibling_id = new_before_sibling_id.map(|s| s.to_string());

        // Validate node exists
        let _node = self
            .get_node(&node_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Node not found: {}", node_id))?;

        // Validate that moving won't create a cycle
        if let Some(ref parent_id) = new_parent_id {
            // Validate parent exists
            let parent_exists = self.get_node(parent_id).await?;
            if parent_exists.is_none() {
                return Err(anyhow::anyhow!("Parent node not found: {}", parent_id));
            }

            self.validate_no_cycle(parent_id, &node_id).await?;
        }

        // Build atomic transaction query using Thing parameters
        let transaction_query = if new_parent_id.is_some() {
            // Move to new parent
            r#"
                BEGIN TRANSACTION;

                -- Delete old parent edge
                DELETE has_child WHERE out = $node_id;

                -- Update sibling ordering
                UPDATE $node_id SET before_sibling_id = $before_sibling_id;

                -- Create new parent edge (parent->has_child->child)
                RELATE $parent_id->has_child->$node_id;

                COMMIT TRANSACTION;
            "#
            .to_string()
        } else {
            // Make root node (delete parent edge only)
            r#"
                BEGIN TRANSACTION;

                -- Delete old parent edge
                DELETE has_child WHERE out = $node_id;

                -- Update sibling ordering
                UPDATE $node_id SET before_sibling_id = $before_sibling_id;

                COMMIT TRANSACTION;
            "#
            .to_string()
        };

        // Construct Thing objects for Record IDs
        let node_thing = surrealdb::sql::Thing::from(("node".to_string(), node_id.clone()));
        let parent_thing = new_parent_id
            .as_ref()
            .map(|pid| surrealdb::sql::Thing::from(("node".to_string(), pid.clone())));

        // Execute transaction
        // Execute transaction (we don't care about the return value, just the side effects)
        let mut query_builder = self
            .db
            .query(&transaction_query)
            .bind(("node_id", node_thing));

        if let Some(parent_thing) = parent_thing {
            query_builder = query_builder.bind(("parent_id", parent_thing));
        }

        query_builder
            .bind(("before_sibling_id", new_before_sibling_id.clone()))
            .await
            .map(|_| ())
            .context(format!(
                "Failed to move node '{}' to parent '{:?}'",
                node_id, new_parent_id
            ))?;

        Ok(())
    }

    pub async fn reorder_node(&self, id: &str, new_before_sibling_id: Option<&str>) -> Result<()> {
        // Update using record ID
        self.db
            .query("UPDATE type::thing('node', $id) SET before_sibling_id = $before_sibling_id;")
            .bind(("id", id.to_string()))
            .bind((
                "before_sibling_id",
                new_before_sibling_id.map(|s| s.to_string()),
            ))
            .await
            .context("Failed to reorder node")?;

        Ok(())
    }

    pub async fn create_mention(
        &self,
        source_id: &str,
        target_id: &str,
        container_id: &str,
    ) -> Result<()> {
        // Get node types to construct proper Record IDs
        let source_node = self
            .get_node(source_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Source node not found: {}", source_id))?;
        let target_node = self
            .get_node(target_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Target node not found: {}", target_id))?;

        // Construct Thing objects for proper Record ID binding
        let source_record_id = Self::to_record_id(&source_node.node_type, &source_node.id);
        let target_record_id = Self::to_record_id(&target_node.node_type, &target_node.id);

        let source_thing = Thing::from(("nodes", Id::String(source_record_id)));
        let target_thing = Thing::from(("nodes", Id::String(target_record_id)));

        // Check if mention already exists (for idempotency)
        let check_query = "SELECT VALUE id FROM mentions WHERE in = $source AND out = $target;";
        let mut check_response = self
            .db
            .query(check_query)
            .bind(("source", source_thing.clone()))
            .bind(("target", target_thing.clone()))
            .await
            .context("Failed to check for existing mention")?;

        let existing_mention_ids: Vec<Thing> = check_response
            .take(0)
            .context("Failed to extract mention check results")?;

        // Only create mention if it doesn't exist
        if existing_mention_ids.is_empty() {
            // RELATE statement using Thing objects
            let query =
                "RELATE $source->mentions->$target CONTENT { container_id: $container_id };";

            self.db
                .query(query)
                .bind(("source", source_thing))
                .bind(("target", target_thing))
                .bind(("container_id", container_id.to_string()))
                .await
                .context("Failed to create mention")?;
        }

        Ok(())
    }

    pub async fn delete_mention(&self, source_id: &str, target_id: &str) -> Result<()> {
        // Get node types to construct proper Record IDs
        let source_node = self
            .get_node(source_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Source node not found: {}", source_id))?;
        let target_node = self
            .get_node(target_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Target node not found: {}", target_id))?;

        // Construct Thing objects for proper Record ID binding
        let source_record_id = Self::to_record_id(&source_node.node_type, &source_node.id);
        let target_record_id = Self::to_record_id(&target_node.node_type, &target_node.id);

        let source_thing = Thing::from(("nodes", Id::String(source_record_id)));
        let target_thing = Thing::from(("nodes", Id::String(target_record_id)));

        self.db
            .query("DELETE FROM mentions WHERE in = $source AND out = $target;")
            .bind(("source", source_thing))
            .bind(("target", target_thing))
            .await
            .context("Failed to delete mention")?;

        Ok(())
    }

    pub async fn get_outgoing_mentions(&self, node_id: &str) -> Result<Vec<String>> {
        // Get node type to construct proper Record ID
        let node = self
            .get_node(node_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Node not found: {}", node_id))?;

        // Construct Thing for proper Record ID binding
        let record_id = Self::to_record_id(&node.node_type, &node.id);
        let thing = Thing::from(("nodes", Id::String(record_id)));

        let query = "SELECT out FROM mentions WHERE in = $node_thing;";
        let mut response = self
            .db
            .query(query)
            .bind(("node_thing", thing))
            .await
            .context("Failed to get outgoing mentions")?;

        #[derive(Debug, Deserialize)]
        struct MentionOut {
            out: Thing,
        }

        let results: Vec<MentionOut> = response
            .take(0)
            .context("Failed to extract outgoing mentions from response")?;

        // Extract UUIDs from Thing Record IDs
        // Thing.id is Id::String("node_type:uuid"), so we need to extract just the UUID part
        Ok(results
            .into_iter()
            .filter_map(|m| {
                if let Id::String(id_str) = &m.out.id {
                    // id_str format: "node_type:uuid", extract UUID (after last colon)
                    id_str.split(':').nth(1).map(String::from)
                } else {
                    None
                }
            })
            .collect())
    }

    pub async fn get_incoming_mentions(&self, node_id: &str) -> Result<Vec<String>> {
        // Get node type to construct proper Record ID
        let node = self
            .get_node(node_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Node not found: {}", node_id))?;

        // Construct Thing for proper Record ID binding
        let record_id = Self::to_record_id(&node.node_type, &node.id);
        let thing = Thing::from(("nodes", Id::String(record_id)));

        let query = "SELECT in FROM mentions WHERE out = $node_thing;";
        let mut response = self
            .db
            .query(query)
            .bind(("node_thing", thing))
            .await
            .context("Failed to get incoming mentions")?;

        #[derive(Debug, Deserialize)]
        struct MentionIn {
            #[serde(rename = "in")]
            in_field: Thing,
        }

        let results: Vec<MentionIn> = response
            .take(0)
            .context("Failed to extract incoming mentions from response")?;

        // Extract UUIDs from Thing Record IDs
        Ok(results
            .into_iter()
            .filter_map(|m| {
                if let Id::String(id_str) = &m.in_field.id {
                    // id_str format: "node_type:uuid", extract UUID (after first colon)
                    id_str.split(':').nth(1).map(String::from)
                } else {
                    None
                }
            })
            .collect())
    }

    pub async fn get_mentioning_containers(&self, node_id: &str) -> Result<Vec<Node>> {
        // Get node type to construct proper Record ID
        // If node doesn't exist, return empty array (not an error)
        let node = match self.get_node(node_id).await? {
            Some(n) => n,
            None => return Ok(Vec::new()),
        };

        // Construct Thing for proper Record ID binding
        let record_id = Self::to_record_id(&node.node_type, &node.id);
        let thing = Thing::from(("nodes", Id::String(record_id)));

        let query = "SELECT container_id FROM mentions WHERE out = $node_thing;";
        let mut response = self
            .db
            .query(query)
            .bind(("node_thing", thing))
            .await
            .context("Failed to get mentioning containers")?;

        #[derive(Debug, Deserialize)]
        struct MentionRecord {
            container_id: String,
        }

        let mention_records: Vec<MentionRecord> = response
            .take(0)
            .context("Failed to extract container IDs from response")?;

        // Deduplicate container IDs
        let mut container_ids: Vec<String> = mention_records
            .into_iter()
            .map(|m| m.container_id)
            .collect();
        container_ids.sort();
        container_ids.dedup();

        // Fetch full node records
        let mut nodes = Vec::new();
        for container_id in container_ids {
            if let Some(node) = self.get_node(&container_id).await? {
                nodes.push(node);
            }
        }

        Ok(nodes)
    }

    pub async fn get_schema(&self, node_type: &str) -> Result<Option<Value>> {
        // Schema nodes use simple IDs (just the node type name, e.g., "date")
        // They're differentiated by node_type = "schema"
        let schema_id = node_type.to_string();
        let node = self.get_node(&schema_id).await?;
        Ok(node.map(|n| n.properties))
    }

    pub async fn update_schema(&self, node_type: &str, schema: &Value) -> Result<()> {
        // Schema nodes use simple IDs (just the node type name, e.g., "date")
        let schema_id = node_type.to_string();

        // Check if schema node exists
        if self.get_node(&schema_id).await?.is_some() {
            // Update existing schema
            let update = NodeUpdate {
                properties: Some(schema.clone()),
                ..Default::default()
            };
            self.update_node(&schema_id, update).await?;
        } else {
            // Create new schema node with deterministic ID
            let node = Node::new_with_id(
                schema_id,
                "schema".to_string(),
                node_type.to_string(),
                schema.clone(),
            );
            self.create_node(node).await?;
        }

        Ok(())
    }

    pub async fn get_nodes_without_embeddings(&self, limit: Option<i64>) -> Result<Vec<Node>> {
        let sql = if limit.is_some() {
            "SELECT * FROM node WHERE embedding_vector IS NONE LIMIT $limit;"
        } else {
            "SELECT * FROM node WHERE embedding_vector IS NONE;"
        };

        let mut query_builder = self.db.query(sql);

        if let Some(lim) = limit {
            query_builder = query_builder.bind(("limit", lim));
        }

        let mut response = query_builder
            .await
            .context("Failed to get nodes without embeddings")?;
        let surreal_nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract nodes without embeddings from response")?;
        Ok(surreal_nodes.into_iter().map(Into::into).collect())
    }

    pub async fn update_embedding(&self, node_id: &str, embedding: &[f32]) -> Result<()> {
        // embedding is already f32 array, no conversion needed
        // Update using record ID
        self.db
            .query("UPDATE type::thing('node', $id) SET embedding_vector = $embedding, embedding_stale = false;")
            .bind(("id", node_id.to_string()))
            .bind(("embedding", embedding.to_vec()))
            .await
            .context("Failed to update embedding")?;

        Ok(())
    }

    /// Mark a node's embedding as stale (needing regeneration)
    ///
    /// Called when node content changes, signaling that the embedding vector
    /// needs to be regenerated. The embedding processor can then query for
    /// stale nodes and regenerate embeddings in batches.
    ///
    /// # Arguments
    ///
    /// * `node_id` - UUID of the node to mark as stale
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// # use nodespace_core::db::SurrealStore;
    /// # use std::path::PathBuf;
    /// # #[tokio::main]
    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// # let store = SurrealStore::new(PathBuf::from("./data/surreal.db")).await?;
    /// // Mark embedding as stale after content change
    /// store.mark_embedding_stale("node-id").await?;
    /// # Ok(())
    /// # }
    /// ```
    pub async fn mark_embedding_stale(&self, node_id: &str) -> Result<()> {
        // Update using record ID
        self.db
            .query("UPDATE type::thing('node', $id) SET embedding_stale = true;")
            .bind(("id", node_id.to_string()))
            .await
            .context("Failed to mark embedding as stale")?;

        Ok(())
    }

    /// Get nodes with stale embeddings
    ///
    /// Returns nodes where content has changed since the embedding was generated,
    /// allowing the embedding processor to regenerate embeddings in batches.
    ///
    /// # Arguments
    ///
    /// * `limit` - Optional limit on number of nodes to return
    ///
    /// # Returns
    ///
    /// Vector of nodes with stale embeddings (embedding_stale = true)
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// # use nodespace_core::db::SurrealStore;
    /// # use std::path::PathBuf;
    /// # #[tokio::main]
    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// # let store = SurrealStore::new(PathBuf::from("./data/surreal.db")).await?;
    /// // Get up to 100 nodes needing embedding regeneration
    /// let stale_nodes = store.get_nodes_with_stale_embeddings(Some(100)).await?;
    /// # Ok(())
    /// # }
    /// ```
    pub async fn get_nodes_with_stale_embeddings(&self, limit: Option<i64>) -> Result<Vec<Node>> {
        let sql = if limit.is_some() {
            "SELECT * FROM node WHERE embedding_stale = true LIMIT $limit;"
        } else {
            "SELECT * FROM node WHERE embedding_stale = true;"
        };

        let mut query_builder = self.db.query(sql);

        if let Some(lim) = limit {
            query_builder = query_builder.bind(("limit", lim));
        }

        let mut response = query_builder
            .await
            .context("Failed to get nodes with stale embeddings")?;
        let surreal_nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract nodes with stale embeddings from response")?;
        Ok(surreal_nodes.into_iter().map(Into::into).collect())
    }

    /// Search for nodes by embedding similarity using SurrealDB's native vector functions
    ///
    /// Converts the query embedding from binary blob to f32 array, then uses
    /// SurrealDB's `vector::similarity::cosine()` to find semantically similar nodes.
    ///
    /// # Arguments
    /// * `embedding` - Query embedding as binary blob (from EmbeddingService::to_blob)
    /// * `limit` - Maximum number of results to return
    /// * `threshold` - Optional minimum similarity score (0.0-1.0, default: 0.5)
    ///
    /// # Returns
    /// Vector of (Node, similarity_score) tuples, sorted by similarity descending
    pub async fn search_by_embedding(
        &self,
        embedding: &[f32],
        limit: i64,
        threshold: Option<f64>,
    ) -> Result<Vec<(Node, f64)>> {
        // embedding is already f32 array, no conversion needed
        let query_vector = embedding.to_vec();

        // Default threshold: 0.5 (moderate similarity)
        let min_similarity = threshold.unwrap_or(0.5);

        // SurrealDB query using vector::similarity::cosine
        // We need to explicitly select fields to avoid deserialization issues with the computed similarity field
        // Use SurrealQL's OR operator to provide defaults for NONE values (SurrealDB's COALESCE equivalent)
        // Note: parent_id/container_node_id removed - use graph edges instead
        let query = r#"
            SELECT
                uuid,
                node_type,
                content,
                before_sibling_id,
                version,
                created_at,
                modified_at,
                properties,
                embedding_vector,
                embedding_stale OR false AS embedding_stale,
                mentions OR [] AS mentions,
                mentioned_by OR [] AS mentioned_by,
                vector::similarity::cosine(embedding_vector, $query_vector) AS similarity
            FROM node
            WHERE embedding_vector != NONE
              AND vector::similarity::cosine(embedding_vector, $query_vector) > $threshold
            ORDER BY similarity DESC
            LIMIT $limit;
        "#;

        let mut response = self
            .db
            .query(query)
            .bind(("query_vector", query_vector))
            .bind(("threshold", min_similarity))
            .bind(("limit", limit))
            .await
            .context("Failed to execute vector similarity search")?;

        // Deserialize response with similarity scores
        #[derive(Debug, Deserialize)]
        struct NodeWithSimilarity {
            id: Thing,
            #[serde(rename = "type")]
            node_type: String,
            content: String,
            #[serde(default)]
            before_sibling_id: Option<String>,
            version: i64,
            created_at: String,
            modified_at: String,
            #[serde(default)]
            embedding_vector: Option<Vec<f32>>,
            #[serde(default)]
            embedding_stale: bool,
            #[serde(default)]
            mentions: Vec<String>,
            #[serde(default)]
            mentioned_by: Vec<String>,
            #[serde(skip_deserializing)]
            data: Option<Value>,
            #[serde(default)]
            variants: Value,
            #[serde(default)]
            properties: Value,
            similarity: f64,
        }

        let results: Vec<NodeWithSimilarity> = response
            .take(0)
            .context("Failed to extract similarity search results")?;

        // Convert to (Node, f64) tuples
        Ok(results
            .into_iter()
            .map(|nws| {
                let surreal_node = SurrealNode {
                    id: nws.id,
                    node_type: nws.node_type,
                    content: nws.content,
                    before_sibling_id: nws.before_sibling_id,
                    version: nws.version,
                    created_at: nws.created_at,
                    modified_at: nws.modified_at,
                    embedding_vector: nws.embedding_vector,
                    embedding_stale: nws.embedding_stale,
                    mentions: nws.mentions,
                    mentioned_by: nws.mentioned_by,
                    data: nws.data,
                    variants: nws.variants,
                    properties: nws.properties,
                };
                (surreal_node.into(), nws.similarity)
            })
            .collect())
    }

    /// Atomic bulk update using SurrealDB transactions
    ///
    /// Updates multiple nodes in a single atomic transaction. Either all updates
    /// succeed or all fail (rollback), ensuring data consistency.
    ///
    /// # Performance Considerations
    ///
    /// - **Optimal Batch Size:** 10-100 nodes (transaction overhead minimal)
    /// - **Large Batches:** >1000 nodes may hit transaction timeout (consider chunking)
    /// - **Validation Cost:** Pre-fetches all nodes for existence check
    ///
    /// # Arguments
    ///
    /// * `updates` - Vector of (node_id, NodeUpdate) tuples to apply
    ///
    /// # Returns
    ///
    /// * `Ok(())` - All updates succeeded
    /// * `Err(_)` - Transaction failed and rolled back, or batch size exceeded limit
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// # use nodespace_core::db::SurrealStore;
    /// # use nodespace_core::models::NodeUpdate;
    /// # use std::path::PathBuf;
    /// # #[tokio::main]
    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// # let store = SurrealStore::new(PathBuf::from("./data/surreal.db")).await?;
    /// let updates = vec![
    ///     ("node-1".to_string(), NodeUpdate {
    ///         content: Some("New content 1".to_string()),
    ///         ..Default::default()
    ///     }),
    ///     ("node-2".to_string(), NodeUpdate {
    ///         content: Some("New content 2".to_string()),
    ///         ..Default::default()
    ///     }),
    /// ];
    ///
    /// store.bulk_update(updates).await?; // All-or-nothing
    /// # Ok(())
    /// # }
    /// ```
    pub async fn bulk_update(&self, updates: Vec<(String, NodeUpdate)>) -> Result<()> {
        if updates.is_empty() {
            return Ok(());
        }

        // Prevent excessive batch sizes that could cause transaction timeouts
        const MAX_BATCH_SIZE: usize = 1000;
        if updates.len() > MAX_BATCH_SIZE {
            return Err(anyhow::anyhow!(
                "Bulk update batch size ({}) exceeds maximum ({}). Consider chunking the updates into smaller batches.",
                updates.len(),
                MAX_BATCH_SIZE
            ));
        }

        // Build transaction query
        let mut transaction_parts = vec!["BEGIN TRANSACTION;".to_string()];

        for (idx, (id, _)) in updates.iter().enumerate() {
            // Validate node exists (will fetch again later for merging values)
            self.get_node(id)
                .await?
                .ok_or_else(|| anyhow::anyhow!("Node not found: {}", id))?;

            // Generate UPDATE statement using record ID
            let update_stmt = format!(
                "UPDATE type::thing('node', $id_{idx}) SET
                    content = $content_{idx},
                    type = $node_type_{idx},
                    before_sibling_id = $before_sibling_id_{idx},
                    modified_at = time::now(),
                    version = version + 1,
                    embedding_vector = $embedding_vector_{idx};",
                idx = idx
            );
            transaction_parts.push(update_stmt);
        }

        transaction_parts.push("COMMIT TRANSACTION;".to_string());
        let transaction_query = transaction_parts.join("\n");

        // Build query with all bindings
        let mut query_builder = self.db.query(transaction_query);

        for (idx, (id, update)) in updates.iter().enumerate() {
            // Fetch current node again for building merged values
            let current = self
                .get_node(id)
                .await?
                .ok_or_else(|| anyhow::anyhow!("Node not found: {}", id))?;

            let updated_content = update.content.clone().unwrap_or(current.content);
            let updated_node_type = update.node_type.clone().unwrap_or(current.node_type);

            // Convert embedding blob to f32 if provided
            // embedding_vector is already Vec<f32>, no conversion needed
            let embedding_f32 = update.embedding_vector.clone().flatten();

            query_builder = query_builder
                .bind((format!("id_{}", idx), id.clone()))
                .bind((format!("content_{}", idx), updated_content))
                .bind((format!("node_type_{}", idx), updated_node_type))
                .bind((
                    format!("before_sibling_id_{}", idx),
                    update.before_sibling_id.clone().flatten(),
                ))
                .bind((format!("embedding_vector_{}", idx), embedding_f32));
        }

        query_builder
            .await
            .context("Failed to execute bulk update transaction")?;

        Ok(())
    }

    pub async fn batch_create_nodes(&self, nodes: Vec<Node>) -> Result<Vec<Node>> {
        let mut created_nodes = Vec::new();

        for node in nodes {
            let created = self.create_node(node).await?;
            created_nodes.push(created);
        }

        Ok(created_nodes)
    }

    pub fn close(&self) -> Result<()> {
        // SurrealDB handles cleanup automatically on drop
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde_json::json;
    use tempfile::TempDir;

    async fn create_test_store() -> Result<(SurrealStore, TempDir)> {
        let temp_dir = TempDir::new()?;
        let db_path = temp_dir.path().join("test_surreal.db");
        let store = SurrealStore::new(db_path).await?;
        Ok((store, temp_dir))
    }

    #[tokio::test]
    async fn test_create_and_get_node() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        let node = Node::new("text".to_string(), "Test content".to_string(), json!({}));

        let created = store.create_node(node.clone()).await?;
        assert_eq!(created.id, node.id);
        assert_eq!(created.content, "Test content");

        let fetched = store.get_node(&node.id).await?;
        assert!(fetched.is_some());
        assert_eq!(fetched.unwrap().id, node.id);

        Ok(())
    }

    #[tokio::test]
    async fn test_update_node() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        let node = Node::new(
            "text".to_string(),
            "Original content".to_string(),
            json!({}),
        );

        let created = store.create_node(node.clone()).await?;

        let update = NodeUpdate {
            content: Some("Updated content".to_string()),
            ..Default::default()
        };

        let updated = store.update_node(&created.id, update).await?;
        assert_eq!(updated.content, "Updated content");

        Ok(())
    }

    #[tokio::test]
    async fn test_delete_node() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        let node = Node::new("text".to_string(), "Test content".to_string(), json!({}));

        let created = store.create_node(node.clone()).await?;

        let result = store.delete_node(&created.id).await?;
        assert!(result.existed);

        let fetched = store.get_node(&created.id).await?;
        assert!(fetched.is_none());

        Ok(())
    }

    #[tokio::test]
    async fn test_schema_operations() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        let schema = json!({
            "type": "object",
            "properties": {
                "status": {"type": "string"}
            }
        });

        store.update_schema("task", &schema).await?;

        let fetched = store.get_schema("task").await?;
        assert!(fetched.is_some());
        assert_eq!(fetched.unwrap(), schema);

        Ok(())
    }

    // Vector Similarity Search Tests

    #[tokio::test]
    async fn test_search_empty_database() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create a dummy embedding (384 floats)
        let query_vector = vec![0.5f32; 384];

        // Search empty database
        let results = store.search_by_embedding(&query_vector, 10, None).await?;

        assert_eq!(results.len(), 0, "Empty database should return no results");

        Ok(())
    }

    #[tokio::test]
    async fn test_search_with_similar_nodes() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create nodes with different embeddings
        let base_vector = vec![1.0f32; 384];
        let similar_vector = vec![0.99f32; 384]; // Very similar
        let dissimilar_vector = vec![-1.0f32; 384]; // Opposite direction

        // Create nodes
        let node1 = Node::new("text".to_string(), "Base content".to_string(), json!({}));
        let mut created1 = store.create_node(node1).await?;
        store
            .update_embedding(&created1.id, &similar_vector)
            .await?;
        created1.embedding_vector = Some(similar_vector.clone());

        let node2 = Node::new(
            "text".to_string(),
            "Dissimilar content".to_string(),
            json!({}),
        );
        let mut created2 = store.create_node(node2).await?;
        store
            .update_embedding(&created2.id, &dissimilar_vector)
            .await?;
        created2.embedding_vector = Some(dissimilar_vector);

        // Search with base embedding
        let results = store.search_by_embedding(&base_vector, 10, None).await?;

        // Should return nodes sorted by similarity (highest first)
        assert!(!results.is_empty(), "Should find at least one similar node");

        // First result should be more similar (higher score)
        if results.len() > 1 {
            assert!(
                results[0].1 > results[1].1,
                "Results should be sorted by similarity descending"
            );
        }

        Ok(())
    }

    #[tokio::test]
    async fn test_search_with_threshold_filter() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create query vector
        let query_vector = vec![1.0f32; 384];

        // Create node with similar embedding
        let similar_vector = vec![0.99f32; 384];

        let node = Node::new("text".to_string(), "Test content".to_string(), json!({}));
        let created = store.create_node(node).await?;
        store.update_embedding(&created.id, &similar_vector).await?;

        // Search with high threshold (0.99) - should find the node
        let results_high_threshold = store
            .search_by_embedding(&query_vector, 10, Some(0.9))
            .await?;
        assert!(
            !results_high_threshold.is_empty(),
            "Should find node with similarity > 0.9"
        );

        // Search with very high threshold (0.999) - might not find it
        let results_very_high = store
            .search_by_embedding(&query_vector, 10, Some(0.999))
            .await?;
        // This test is lenient because exact similarity depends on normalization
        assert!(
            results_very_high.len() <= results_high_threshold.len(),
            "Higher threshold should return fewer or equal results"
        );

        Ok(())
    }

    #[tokio::test]
    async fn test_search_respects_limit() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create 5 nodes with embeddings
        let base_vector = vec![1.0f32; 384];

        for i in 0..5 {
            let node = Node::new("text".to_string(), format!("Content {}", i), json!({}));
            let created = store.create_node(node).await?;
            store.update_embedding(&created.id, &base_vector).await?;
        }

        // Search with limit of 3
        let results = store
            .search_by_embedding(&base_vector, 3, Some(0.5))
            .await?;

        assert!(
            results.len() <= 3,
            "Should respect limit parameter (expected <= 3, got {})",
            results.len()
        );

        Ok(())
    }

    // Performance Benchmark Tests
    //
    // These tests measure search query performance on databases of varying sizes.
    // Current implementation uses linear scan (O(n)) without vector indexes.
    // Performance targets are based on real-world measurements on RocksDB storage.

    #[tokio::test]
    async fn test_search_performance_1k_nodes() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create 1,000 nodes with embeddings
        let base_vector = vec![1.0f32; 384];

        tracing::info!("Creating 1,000 nodes for performance test...");
        for i in 0..1000 {
            let node = Node::new(
                "text".to_string(),
                format!("Performance test content {}", i),
                json!({}),
            );
            let created = store.create_node(node).await?;
            store.update_embedding(&created.id, &base_vector).await?;

            if i % 100 == 0 {
                tracing::info!("Created {} nodes", i);
            }
        }

        tracing::info!("Starting performance benchmark...");

        // Measure search time (after data is created)
        let start = std::time::Instant::now();
        let results = store
            .search_by_embedding(&base_vector, 20, Some(0.5))
            .await?;
        let elapsed = start.elapsed();

        tracing::info!(
            "Search completed in {:?} with {} results",
            elapsed,
            results.len()
        );

        // Performance target: < 1500ms for 1,000 nodes (linear scan on RocksDB)
        // Real-world measurement: ~950ms
        // Note: This is the search query time only, not data creation time
        assert!(
            elapsed.as_millis() < 1500,
            "Search should complete in < 1500ms (took {:?})",
            elapsed
        );

        Ok(())
    }

    #[tokio::test]
    async fn test_search_with_real_nlp_embeddings() -> Result<()> {
        use nodespace_nlp_engine::EmbeddingService;
        use std::sync::Arc;

        let (store, _temp_dir) = create_test_store().await?;

        // Initialize real NLP engine
        let mut nlp_service = EmbeddingService::new(Default::default())?;
        nlp_service.initialize()?;
        let nlp = Arc::new(nlp_service);

        // Create nodes with semantically similar and dissimilar content
        let similar_text_1 = "Machine learning algorithms for data analysis";
        let similar_text_2 = "Deep learning neural networks and AI models";
        let dissimilar_text = "The weather forecast predicts sunny skies tomorrow";

        // Generate real embeddings
        let emb1 = nlp.generate_embedding(similar_text_1)?;
        let emb2 = nlp.generate_embedding(similar_text_2)?;
        let emb3 = nlp.generate_embedding(dissimilar_text)?;

        // Create nodes
        let node1 = Node::new("text".to_string(), similar_text_1.to_string(), json!({}));
        let mut created1 = store.create_node(node1).await?;
        store.update_embedding(&created1.id, &emb1).await?;
        created1.embedding_vector = Some(emb1.clone());

        let node2 = Node::new("text".to_string(), similar_text_2.to_string(), json!({}));
        let mut created2 = store.create_node(node2).await?;
        store.update_embedding(&created2.id, &emb2).await?;
        created2.embedding_vector = Some(emb2.clone());

        let node3 = Node::new("text".to_string(), dissimilar_text.to_string(), json!({}));
        let mut created3 = store.create_node(node3).await?;
        store.update_embedding(&created3.id, &emb3).await?;
        created3.embedding_vector = Some(emb3);

        // Search with first embedding (machine learning topic)
        let results = store.search_by_embedding(&emb1, 10, Some(0.3)).await?;

        // Verify results
        assert!(!results.is_empty(), "Should find at least one similar node");

        // The most similar should be the ML/AI content (node2), not the weather content
        let (top_node, top_similarity) = &results[0];
        tracing::info!(
            "Top result: content='{}', similarity={:.3}",
            top_node.content,
            top_similarity
        );

        // Find similarity scores for each content type
        let ml_similarity = results
            .iter()
            .find(|(n, _)| n.id == created2.id)
            .map(|(_, s)| *s);
        let weather_similarity = results
            .iter()
            .find(|(n, _)| n.id == created3.id)
            .map(|(_, s)| *s);

        tracing::info!(
            "ML/AI similarity: {:?}, Weather similarity: {:?}",
            ml_similarity,
            weather_similarity
        );

        // ML/AI content should be more similar to the query than weather content
        if let (Some(ml_sim), Some(weather_sim)) = (ml_similarity, weather_similarity) {
            assert!(
                ml_sim > weather_sim,
                "ML/AI content (sim={:.3}) should rank higher than weather content (sim={:.3})",
                ml_sim,
                weather_sim
            );
        }

        // Top result should have high similarity (> 0.7 for semantically related content)
        assert!(
            top_similarity > &0.5,
            "Top result should have similarity > 0.5 (got {:.3})",
            top_similarity
        );

        Ok(())
    }

    #[tokio::test]
    async fn test_search_performance_10k_nodes() -> Result<()> {
        // Skip this test unless RUN_LONG_TESTS=1 is set
        // Reason: Test takes ~10 minutes total (10K node creation + search)
        // The search itself is fast (~9.5s), but setup is slow
        if std::env::var("RUN_LONG_TESTS").unwrap_or_default() != "1" {
            eprintln!("Skipping 10K performance test (set RUN_LONG_TESTS=1 to run)");
            return Ok(());
        }

        let (store, _temp_dir) = create_test_store().await?;

        // Create 10,000 nodes with embeddings
        let base_vector = vec![1.0f32; 384];

        tracing::info!("Creating 10,000 nodes for performance test...");
        for i in 0..10000 {
            let node = Node::new(
                "text".to_string(),
                format!("Performance test content {}", i),
                json!({}),
            );
            let created = store.create_node(node).await?;
            store.update_embedding(&created.id, &base_vector).await?;

            if i % 1000 == 0 {
                tracing::info!("Created {} nodes", i);
            }
        }

        tracing::info!("Starting performance benchmark...");

        // Measure search time
        let start = std::time::Instant::now();
        let results = store
            .search_by_embedding(&base_vector, 20, Some(0.5))
            .await?;
        let elapsed = start.elapsed();

        tracing::info!(
            "Search completed in {:?} with {} results",
            elapsed,
            results.len()
        );

        // Performance target: < 15000ms (15 seconds) for 10,000 nodes (linear scan)
        // Estimated: ~9.5 seconds based on 1K node measurements (linear scaling)
        // Note: This is acceptable for MVP without vector indexes
        assert!(
            elapsed.as_millis() < 15000,
            "Search should complete in < 15s (took {:?})",
            elapsed
        );

        Ok(())
    }

    // ============================================================================
    // Atomic Transactional Operations Tests (Issue #532)
    // ============================================================================

    #[tokio::test]
    async fn test_create_child_node_atomic_success() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create parent node
        let parent = Node::new("text".to_string(), "Parent".to_string(), json!({}));
        let parent = store.create_node(parent).await?;

        // Create child atomically
        let child = store
            .create_child_node_atomic(&parent.id, "text", "Child content", json!({}), None)
            .await?;

        // Verify child was created
        assert_eq!(child.content, "Child content");
        assert_eq!(child.node_type, "text");

        // Verify parent-child edge exists
        let children = store.get_children(Some(&parent.id)).await?;
        assert_eq!(children.len(), 1);
        assert_eq!(children[0].id, child.id);

        Ok(())
    }

    #[tokio::test]
    async fn test_create_child_node_atomic_with_properties() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create parent
        let parent = Node::new("text".to_string(), "Parent".to_string(), json!({}));
        let parent = store.create_node(parent).await?;

        // Create task child atomically with properties
        let properties = json!({
            "status": "TODO",
            "priority": "HIGH"
        });

        let child = store
            .create_child_node_atomic(&parent.id, "task", "Task content", properties, None)
            .await?;

        // Verify properties were set
        let fetched = store.get_node(&child.id).await?.unwrap();
        assert_eq!(fetched.properties["status"], "TODO");
        assert_eq!(fetched.properties["priority"], "HIGH");

        Ok(())
    }

    #[tokio::test]
    async fn test_create_child_node_atomic_rollback_on_failure() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Count initial nodes (seeded core schemas: task, date, text, header, code-block, quote-block, ordered-list = 7)
        let initial_nodes = store.query_nodes(NodeQuery::new()).await?;
        let initial_count = initial_nodes.len();

        // Try to create child with non-existent parent (should fail)
        let result = store
            .create_child_node_atomic("non-existent-parent", "text", "Child", json!({}), None)
            .await;

        assert!(result.is_err());

        // Verify no new nodes were created (orphan nodes would increase the count)
        let final_nodes = store.query_nodes(NodeQuery::new()).await?;
        assert_eq!(
            final_nodes.len(),
            initial_count,
            "No nodes should be created after failed transaction - expected {} nodes, got {}",
            initial_count,
            final_nodes.len()
        );

        Ok(())
    }

    #[tokio::test]
    async fn test_move_node_atomic_success() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create parent1, parent2, and child
        let parent1 = store
            .create_node(Node::new(
                "text".to_string(),
                "Parent 1".to_string(),
                json!({}),
            ))
            .await?;
        let parent2 = store
            .create_node(Node::new(
                "text".to_string(),
                "Parent 2".to_string(),
                json!({}),
            ))
            .await?;
        let child = store
            .create_child_node_atomic(&parent1.id, "text", "Child", json!({}), None)
            .await?;

        // Verify child is under parent1
        let children1 = store.get_children(Some(&parent1.id)).await?;
        assert_eq!(children1.len(), 1);

        // Move child to parent2 atomically
        store
            .move_node_atomic(&child.id, Some(&parent2.id), None)
            .await?;

        // Verify child is now under parent2
        let children1_after = store.get_children(Some(&parent1.id)).await?;
        let children2_after = store.get_children(Some(&parent2.id)).await?;

        assert_eq!(children1_after.len(), 0, "Parent1 should have no children");
        assert_eq!(children2_after.len(), 1, "Parent2 should have 1 child");
        assert_eq!(children2_after[0].id, child.id);

        Ok(())
    }

    #[tokio::test]
    async fn test_move_node_atomic_to_root() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create parent and child
        let parent = store
            .create_node(Node::new(
                "text".to_string(),
                "Parent".to_string(),
                json!({}),
            ))
            .await?;
        let child = store
            .create_child_node_atomic(&parent.id, "text", "Child", json!({}), None)
            .await?;

        // Move child to root
        store.move_node_atomic(&child.id, None, None).await?;

        // Verify child is a root node
        let parent_children = store.get_children(Some(&parent.id)).await?;
        let root_nodes = store.get_children(None).await?;

        assert_eq!(parent_children.len(), 0);
        assert!(root_nodes.iter().any(|n| n.id == child.id));

        Ok(())
    }

    #[tokio::test]
    async fn test_move_node_atomic_prevents_cycles() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create parent and child
        let parent = store
            .create_node(Node::new(
                "text".to_string(),
                "Parent".to_string(),
                json!({}),
            ))
            .await?;
        let child = store
            .create_child_node_atomic(&parent.id, "text", "Child", json!({}), None)
            .await?;

        // Try to move parent under child (would create cycle)
        let result = store
            .move_node_atomic(&parent.id, Some(&child.id), None)
            .await;

        assert!(
            result.is_err(),
            "Moving parent under child should fail (cycle detection)"
        );

        Ok(())
    }

    #[tokio::test]
    async fn test_delete_node_cascade_atomic_success() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create parent and child
        let parent = store
            .create_node(Node::new(
                "text".to_string(),
                "Parent".to_string(),
                json!({}),
            ))
            .await?;
        let child = store
            .create_child_node_atomic(&parent.id, "text", "Child", json!({}), None)
            .await?;

        // Delete parent (should cascade delete edges)
        let result = store.delete_node_cascade_atomic(&parent.id).await?;
        assert!(result.existed);

        // Verify parent was deleted
        let parent_fetched = store.get_node(&parent.id).await?;
        assert!(parent_fetched.is_none());

        // Verify child still exists (cascade doesn't delete children, only edges)
        let child_fetched = store.get_node(&child.id).await?;
        assert!(child_fetched.is_some());

        // Verify child is now a root node (no parent edge)
        let root_nodes = store.get_children(None).await?;
        assert!(root_nodes.iter().any(|n| n.id == child.id));

        Ok(())
    }

    #[tokio::test]
    async fn test_delete_node_cascade_atomic_idempotent() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Delete non-existent node (should succeed idempotently)
        let result = store.delete_node_cascade_atomic("non-existent-id").await?;
        assert!(!result.existed);

        Ok(())
    }

    #[tokio::test]
    async fn test_delete_node_cascade_atomic_with_task() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create task node with properties
        let task = Node::new(
            "task".to_string(),
            "Task content".to_string(),
            json!({"status": "TODO"}),
        );
        let task = store.create_node(task).await?;

        // Delete task (should delete both node and task-specific record)
        let result = store.delete_node_cascade_atomic(&task.id).await?;
        assert!(result.existed);

        // Verify complete deletion
        let fetched = store.get_node(&task.id).await?;
        assert!(fetched.is_none());

        Ok(())
    }

    #[tokio::test]
    async fn test_switch_node_type_atomic_text_to_task() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create text node
        let node = store
            .create_node(Node::new(
                "text".to_string(),
                "Original text".to_string(),
                json!({}),
            ))
            .await?;

        // Switch to task type atomically
        let updated = store
            .switch_node_type_atomic(
                &node.id,
                "task",
                json!({"status": "TODO", "priority": "HIGH"}),
            )
            .await?;

        // Verify type switch
        assert_eq!(updated.node_type, "task");
        assert_eq!(updated.properties["status"], "TODO");
        assert_eq!(updated.properties["priority"], "HIGH");

        // Verify content preserved
        assert_eq!(updated.content, "Original text");

        Ok(())
    }

    #[tokio::test]
    async fn test_switch_node_type_atomic_task_to_text() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create task node
        let task = store
            .create_node(Node::new(
                "task".to_string(),
                "Task content".to_string(),
                json!({"status": "DONE"}),
            ))
            .await?;

        // Switch to text type atomically
        let updated = store
            .switch_node_type_atomic(&task.id, "text", json!({}))
            .await?;

        // Verify type switch
        assert_eq!(updated.node_type, "text");

        // Verify content preserved
        assert_eq!(updated.content, "Task content");

        Ok(())
    }

    #[tokio::test]
    async fn test_switch_node_type_atomic_preserves_variants() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create text node
        let node = store
            .create_node(Node::new(
                "text".to_string(),
                "Content".to_string(),
                json!({}),
            ))
            .await?;

        // Switch to task
        store
            .switch_node_type_atomic(&node.id, "task", json!({"status": "TODO"}))
            .await?;

        // Switch back to text
        let _final_node = store
            .switch_node_type_atomic(&node.id, "text", json!({}))
            .await?;

        // Fetch with properties to check variants map
        let fetched = store.get_node(&node.id).await?.unwrap();

        // Variants should be preserved (this is implementation detail, test structure exists)
        assert_eq!(fetched.node_type, "text");

        Ok(())
    }

    #[tokio::test]
    async fn test_atomic_operations_performance() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create parent
        let parent = store
            .create_node(Node::new(
                "text".to_string(),
                "Parent".to_string(),
                json!({}),
            ))
            .await?;

        // Measure create_child_node_atomic performance with multiple iterations
        // to account for variance and get statistically reliable results
        const ITERATIONS: usize = 20;
        let mut measurements = Vec::with_capacity(ITERATIONS);

        for i in 0..ITERATIONS {
            let start = std::time::Instant::now();
            let _child = store
                .create_child_node_atomic(
                    &parent.id,
                    "text",
                    &format!("Child{}", i),
                    json!({}),
                    None,
                )
                .await?;
            measurements.push(start.elapsed());
        }

        // Calculate P95 percentile (95th percentile of measurements)
        measurements.sort();
        let p95_index = (ITERATIONS * 95) / 100;
        let p95_latency = measurements[p95_index];

        // Performance target: P95 <15ms for atomic operations (from Issue #532)
        // P95 percentile is more reliable than single measurements for performance validation
        assert!(
            p95_latency.as_millis() < 15,
            "create_child_node_atomic P95 latency should be <15ms, got {:?}. Measurements (ms): {:?}",
            p95_latency,
            measurements
                .iter()
                .map(|d| d.as_millis())
                .collect::<Vec<_>>()
        );

        Ok(())
    }
}
