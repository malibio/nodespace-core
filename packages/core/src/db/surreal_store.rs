//! SurrealStore - Direct SurrealDB Backend Implementation
//!
//! This module provides the primary and only database backend for NodeSpace,
//! using SurrealDB embedded database with RocksDB storage engine.
//!
//! # Architecture
//!
//! SurrealStore uses a **graph-native architecture** (Issue #511):
//! 1. **Universal `node` table** - All node data with record IDs, graph edges for hierarchy
//! 2. **Type-specific tables** - Optional tables for types with properties (currently: `task`)
//! 3. **Graph edges** - `has_child` edges for parent-child relationships
//!
//! # Design Principles
//!
//! 1. **Embedded RocksDB**: Desktop-only backend using `kv-rocksdb` engine
//! 2. **SCHEMALESS Mode**: Core tables use SCHEMALESS for dynamic properties
//! 3. **Record IDs**: Native SurrealDB format `node:uuid` (type embedded in ID)
//! 4. **Graph Edges**: Hierarchy via `has_child` edges (no parent_id/container_node_id fields)
//! 5. **Direct Access**: No abstraction layers, SurrealStore used directly by services
//!
//! # Performance Targets (from PoC)
//!
//! - Startup time: <100ms (PoC: 52ms)
//! - 100K nodes query: <200ms (PoC: 104ms)
//! - Deep pagination: <50ms (PoC: 8.3ms)
//! - Complex queries avg: <300ms (PoC: 211ms)
//!
//! # Examples
//!
//! ```rust,no_run
//! use nodespace_core::db::SurrealStore;
//! use std::path::PathBuf;
//!
//! #[tokio::main]
//! async fn main() -> anyhow::Result<()> {
//!     // Create embedded SurrealDB store
//!     let db_path = PathBuf::from("./data/surreal.db");
//!     let store = SurrealStore::new(db_path).await?;
//!
//!     // Direct database access
//!     let node = store.get_node("task:550e8400-e29b-41d4-a716-446655440000").await?;
//!
//!     Ok(())
//! }
//! ```

use crate::models::{DeleteResult, Node, NodeQuery, NodeUpdate};
use anyhow::{Context, Result};
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use serde_json::Value;
use std::path::PathBuf;
use std::sync::Arc;
use surrealdb::engine::local::{Db, RocksDb};
use surrealdb::engine::remote::http::{Client, Http};
use surrealdb::opt::auth::Root;
use surrealdb::sql::{Id, Thing};
use surrealdb::Surreal;

/// Internal struct matching SurrealDB's schema
///
/// # Schema Evolution
///
/// - **v1.0** (Issue #470): Initial SurrealDB schema migration
///   - Core node fields with embedding vector storage
///   - Version-based optimistic concurrency control
///
/// - **v1.1** (Issue #481): Advanced SurrealDB features
///   - Added `embedding_stale` field for tracking embedding staleness
///   - Automatically set when content changes, cleared when embedding regenerated
///
/// - **v1.2** (Issue #511): Graph-native architecture
///   - Removed `uuid`, `parent_id`, `container_node_id`, `properties` fields
///   - Added `data` field: Optional record link to type-specific table
///   - Added `variants` field: Type history for lossless type switching
///   - Added `_schema_version` field: Universal versioning
///   - Table renamed from `nodes` to `node` (singular)
///   - Hierarchy via `has_child` graph edges only
///   - Only `task` type table exists (other types are schema-only)
///
/// # Embedding Storage Architecture (Issue #495)
///
/// Embeddings use a **hybrid storage architecture** with different representations
/// at different boundaries:
///
/// - **External API** (`Node` struct): `Vec<u8>` binary blobs
///   - Generated by `EmbeddingService::to_blob()` (little-endian f32 encoding)
///   - Storage-efficient format for transfer and external persistence
///
/// - **Database Storage** (`SurrealNode` struct): `Vec<f32>` float arrays
///   - Required by SurrealDB's `vector::similarity::cosine()` function
///   - Enables native vector operations without conversion overhead
///
/// This dual representation optimizes for both external compatibility (binary blobs)
/// and internal query performance (native f32 arrays).
#[derive(Debug, Clone, Serialize, Deserialize)]
struct SurrealNode {
    // Record ID is stored in the 'id' field returned by SurrealDB (e.g., node:âŸ¨uuidâŸ©)
    id: Thing, // SurrealDB record ID (table:id format)
    #[serde(rename = "type")]
    node_type: String,
    content: String,
    before_sibling_id: Option<String>,
    version: i64,
    created_at: String,
    modified_at: String,
    embedding_vector: Option<Vec<f32>>,
    embedding_stale: bool,
    mentions: Vec<String>,
    mentioned_by: Vec<String>,
    // Graph-native architecture fields (Issue #511)
    // Note: data field is skipped during deserialization due to FETCH complications
    // Properties will be fetched separately when needed
    #[serde(skip_deserializing)]
    data: Option<Value>, // Placeholder - properties fetched separately
    variants: Value,      // Type history map {task: "task:uuid", text: null}
    _schema_version: i64, // Universal schema version
}

impl From<SurrealNode> for Node {
    fn from(sn: SurrealNode) -> Self {
        // Convert f32 vector back to binary blob (Vec<u8>) for Node struct
        let embedding_vector = sn.embedding_vector.map(|floats| {
            floats
                .iter()
                .flat_map(|f| f.to_le_bytes())
                .collect::<Vec<u8>>()
        });

        // Extract UUID from Thing record ID (e.g., node:âŸ¨uuidâŸ© -> uuid)
        let id = match &sn.id.id {
            Id::String(s) => {
                // Format is "node:uuid", extract the UUID part
                s.split(':').nth(1).unwrap_or(s).to_string()
            }
            _ => sn.id.id.to_string(),
        };

        // Extract properties from data field if it's an object (populated by FETCH data)
        // When FETCH data: data = {id: "task:uuid", ...properties}
        // Extract all fields except 'id' as properties
        let properties = if let Some(Value::Object(ref obj)) = sn.data {
            // Remove the 'id' field and use remaining fields as properties
            let mut props = obj.clone();
            props.remove("id");
            Value::Object(props)
        } else {
            serde_json::json!({})
        };

        Node {
            id,
            node_type: sn.node_type,
            content: sn.content,
            parent_id: None,         // Removed - use graph edges instead
            container_node_id: None, // Removed - use graph edges instead
            before_sibling_id: sn.before_sibling_id,
            version: sn.version,
            created_at: DateTime::parse_from_rfc3339(&sn.created_at)
                .map(|dt| dt.with_timezone(&Utc))
                .unwrap_or_else(|_| Utc::now()),
            modified_at: DateTime::parse_from_rfc3339(&sn.modified_at)
                .map(|dt| dt.with_timezone(&Utc))
                .unwrap_or_else(|_| Utc::now()),
            properties,
            embedding_vector,
            mentions: sn.mentions,
            mentioned_by: sn.mentioned_by,
        }
    }
}

/// SurrealStore implements NodeStore trait for SurrealDB backend
///
/// Supports two connection modes:
/// - **Embedded RocksDB**: Desktop production mode (Surreal<Db>)
/// - **HTTP Client**: Dev-proxy mode (Surreal<Client>)
///
/// Uses hybrid dual-table architecture for optimal query performance.
pub struct SurrealStore<C = Db>
where
    C: surrealdb::Connection,
{
    /// SurrealDB connection
    db: Arc<Surreal<C>>,
}

/// Type alias for embedded RocksDB store
pub type EmbeddedStore = SurrealStore<Db>;

/// Type alias for HTTP client store
pub type HttpStore = SurrealStore<Client>;

impl SurrealStore<Db> {
    /// Create a new SurrealStore with embedded RocksDB backend
    ///
    /// # Arguments
    ///
    /// * `db_path` - Path to RocksDB database directory
    ///
    /// # Returns
    ///
    /// Initialized SurrealStore with schema setup complete
    ///
    /// # Errors
    ///
    /// Returns error if:
    /// - Database path is invalid
    /// - RocksDB initialization fails
    /// - Schema initialization fails
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// # use nodespace_core::db::SurrealStore;
    /// # use std::path::PathBuf;
    /// # #[tokio::main]
    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// let store = SurrealStore::new(PathBuf::from("./data/surreal.db")).await?;
    /// # Ok(())
    /// # }
    /// ```
    pub async fn new(db_path: PathBuf) -> Result<Self> {
        // Initialize embedded RocksDb
        let db = Surreal::new::<RocksDb>(db_path)
            .await
            .context("Failed to initialize SurrealDB with RocksDB backend")?;

        // Use namespace and database
        db.use_ns("nodespace")
            .use_db("nodes")
            .await
            .context("Failed to set namespace/database")?;

        let db = Arc::new(db);

        // Initialize schema (create tables)
        Self::initialize_schema(&db).await?;

        // Seed core schemas (create schema nodes)
        Self::seed_core_schemas(&db).await?;

        Ok(Self { db })
    }
}

impl SurrealStore<Client> {
    /// Create HTTP client store for dev-proxy mode
    ///
    /// This connects to a remote SurrealDB server via HTTP API.
    /// Used by dev-proxy to enable Surrealist inspection while preserving business logic.
    ///
    /// # Arguments
    ///
    /// * `endpoint` - SurrealDB server address (e.g., "127.0.0.1:8000")
    /// * `namespace` - Database namespace (e.g., "nodespace")
    /// * `database` - Database name (e.g., "nodes")
    /// * `username` - Auth username (e.g., "root")
    /// * `password` - Auth password (e.g., "root")
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// use nodespace_core::db::SurrealStore;
    ///
    /// #[tokio::main]
    /// async fn main() -> anyhow::Result<()> {
    ///     let store = SurrealStore::new_http(
    ///         "127.0.0.1:8000",
    ///         "nodespace",
    ///         "nodes",
    ///         "root",
    ///         "root"
    ///     ).await?;
    ///
    ///     // Use store normally - same API as embedded mode
    ///     let node = store.get_node("some-id").await?;
    ///
    ///     Ok(())
    /// }
    /// ```
    pub async fn new_http(
        endpoint: &str,
        namespace: &str,
        database: &str,
        username: &str,
        password: &str,
    ) -> Result<Self> {
        tracing::info!("Connecting to SurrealDB HTTP server at {}", endpoint);

        // Create HTTP client connection to remote SurrealDB server
        let db = Surreal::new::<Http>(endpoint)
            .await
            .context("Failed to connect to SurrealDB HTTP server")?;

        // Authenticate with root credentials
        db.signin(Root { username, password })
            .await
            .context("Failed to authenticate with SurrealDB")?;

        // Set namespace and database
        db.use_ns(namespace)
            .use_db(database)
            .await
            .context("Failed to set namespace/database")?;

        let db = Arc::new(db);

        // IMPORTANT: Do NOT call initialize_schema() or seed_core_schemas()
        // In HTTP mode, the server should already be initialized.
        // Calling these would try to recreate tables/schemas.
        tracing::info!("âœ… Connected to SurrealDB HTTP server");

        Ok(Self { db })
    }
}

impl<C> SurrealStore<C>
where
    C: surrealdb::Connection,
{
    /// Initialize database schema (universal node table + core type tables)
    ///
    /// Creates SCHEMALESS tables for flexible property handling while maintaining
    /// core field structure.
    ///
    /// # Graph-Native Architecture (Issue #511)
    /// - Table name: `node` (singular, consistent naming)
    /// - New fields: data, variants, _schema_version (initialized on creation)
    async fn initialize_schema(db: &Arc<Surreal<Db>>) -> Result<()> {
        // Universal node table (singular) - SCHEMALESS for maximum flexibility
        db.query(
            "
            DEFINE TABLE IF NOT EXISTS node SCHEMALESS;
            ",
        )
        .await
        .context("Failed to create universal node table")?;

        // Phase 6 (Issue #511): Only create type tables for types with properties
        // Types without properties (text, date, header, code_block, quote_block, ordered_list)
        // don't need separate tables - all data is in the node table
        let core_types_with_properties = ["task", "schema"];

        for node_type in core_types_with_properties {
            db.query(format!(
                "DEFINE TABLE IF NOT EXISTS {} SCHEMALESS;",
                node_type
            ))
            .await
            .with_context(|| format!("Failed to create {} table", node_type))?;
        }

        // Mentions table for reference graph
        db.query(
            "
            DEFINE TABLE IF NOT EXISTS mentions SCHEMALESS TYPE RELATION;
            ",
        )
        .await
        .context("Failed to create mentions table")?;

        // has_child graph edges for hierarchy
        // RELATE table for parent->child relationships
        // Replaces parent_id field-based queries with graph traversal
        db.query(
            "
            DEFINE TABLE IF NOT EXISTS has_child SCHEMALESS TYPE RELATION;
            ",
        )
        .await
        .context("Failed to create has_child relation table")?;

        // Critical indexes for graph traversal performance
        // Without these, traversal is O(nÂ²) - WITH them it's O(1) for parent/child lookups
        db.query(
            "
            DEFINE INDEX IF NOT EXISTS idx_has_child_in ON has_child FIELDS in;
            DEFINE INDEX IF NOT EXISTS idx_has_child_out ON has_child FIELDS out;
            ",
        )
        .await
        .context("Failed to create has_child indexes")?;

        Ok(())
    }

    /// Seed core schema definitions as nodes
    ///
    /// Creates schema nodes (node_type = "schema") with schema definitions
    /// stored in properties. Checks for existing schemas to be idempotent.
    async fn seed_core_schemas(db: &Arc<Surreal<Db>>) -> Result<()> {
        use serde_json::json;

        // Check if schemas already exist by trying to get one
        // If any schema exists, assume all are seeded (they're created atomically)
        // Use record ID for schema lookup
        let task_exists = db
            .query("SELECT * FROM type::thing('node', 'task') LIMIT 1")
            .await
            .context("Failed to check for existing schemas")?
            .take::<Option<SurrealNode>>(0)
            .ok()
            .flatten()
            .is_some();

        if task_exists {
            tracing::info!("âœ… Core schemas already seeded");
            return Ok(());
        }

        tracing::info!("ðŸŒ± Seeding core schemas...");

        // Create temporary SurrealStore to use create_node method
        let store = SurrealStore::<Db> { db: Arc::clone(db) };

        let now = Utc::now();

        // Task schema
        let task_node = Node {
            id: "task".to_string(),
            node_type: "schema".to_string(),
            content: "Task".to_string(),
            parent_id: None,
            container_node_id: None,
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Task tracking schema",
                "fields": [
                    {
                        "name": "status",
                        "type": "enum",
                        "protection": "core",
                        "core_values": ["OPEN", "IN_PROGRESS", "DONE"],
                        "user_values": [],
                        "indexed": true,
                        "required": true,
                        "extensible": true,
                        "default": "OPEN",
                        "description": "Task status"
                    },
                    {
                        "name": "priority",
                        "type": "enum",
                        "protection": "user",
                        "core_values": ["LOW", "MEDIUM", "HIGH"],
                        "user_values": [],
                        "indexed": true,
                        "required": false,
                        "extensible": true,
                        "description": "Task priority"
                    },
                    {
                        "name": "due_date",
                        "type": "date",
                        "protection": "user",
                        "indexed": true,
                        "required": false,
                        "description": "Due date"
                    },
                    {
                        "name": "started_at",
                        "type": "date",
                        "protection": "user",
                        "indexed": false,
                        "required": false,
                        "description": "Started at"
                    },
                    {
                        "name": "completed_at",
                        "type": "date",
                        "protection": "user",
                        "indexed": false,
                        "required": false,
                        "description": "Completed at"
                    },
                    {
                        "name": "assignee",
                        "type": "text",
                        "protection": "user",
                        "indexed": true,
                        "required": false,
                        "description": "Assignee"
                    }
                ]
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(task_node).await?;

        // Date schema
        let date_node = Node {
            id: "date".to_string(),
            node_type: "schema".to_string(),
            content: "Date".to_string(),
            parent_id: None,
            container_node_id: None,
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Date node schema",
                "fields": []
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(date_node).await?;

        // Text schema
        let text_node = Node {
            id: "text".to_string(),
            node_type: "schema".to_string(),
            content: "Text".to_string(),
            parent_id: None,
            container_node_id: None,
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Plain text content",
                "fields": []
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(text_node).await?;

        // Header schema
        let header_node = Node {
            id: "header".to_string(),
            node_type: "schema".to_string(),
            content: "Header".to_string(),
            parent_id: None,
            container_node_id: None,
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Markdown header (h1-h6)",
                "fields": []
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(header_node).await?;

        // Code block schema
        let code_block_node = Node {
            id: "code-block".to_string(),
            node_type: "schema".to_string(),
            content: "Code Block".to_string(),
            parent_id: None,
            container_node_id: None,
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Code block with syntax highlighting",
                "fields": []
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(code_block_node).await?;

        // Quote block schema
        let quote_block_node = Node {
            id: "quote-block".to_string(),
            node_type: "schema".to_string(),
            content: "Quote Block".to_string(),
            parent_id: None,
            container_node_id: None,
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Blockquote for citations",
                "fields": []
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(quote_block_node).await?;

        // Ordered list schema
        let ordered_list_node = Node {
            id: "ordered-list".to_string(),
            node_type: "schema".to_string(),
            content: "Ordered List".to_string(),
            parent_id: None,
            container_node_id: None,
            before_sibling_id: None,
            version: 1,
            created_at: now,
            modified_at: now,
            properties: json!({
                "is_core": true,
                "version": 1,
                "description": "Numbered list item",
                "fields": []
            }),
            embedding_vector: None,
            mentions: vec![],
            mentioned_by: vec![],
        };
        store.create_node(ordered_list_node).await?;

        tracing::info!("âœ… Core schemas seeded successfully");

        Ok(())
    }

    /// Convert Turso-style ID to SurrealDB Record ID format
    ///
    /// Turso IDs are plain UUIDs. SurrealDB uses `table:uuid` format.
    /// This method extracts the type from the node and constructs the Record ID.
    ///
    /// # Arguments
    ///
    /// * `node_type` - The node type (becomes table name)
    /// * `id` - The UUID portion
    ///
    /// # Returns
    ///
    /// SurrealDB Record ID string: `table:uuid`
    fn to_record_id(node_type: &str, id: &str) -> String {
        format!("{}:{}", node_type, id)
    }

    /// Parse SurrealDB Record ID into (table, uuid) components
    ///
    /// # Arguments
    ///
    /// * `record_id` - SurrealDB Record ID (e.g., "task:uuid")
    ///
    /// # Returns
    ///
    /// Tuple of (table_name, uuid_portion)
    #[allow(dead_code)]
    fn parse_record_id(record_id: &str) -> Result<(String, String)> {
        let parts: Vec<&str> = record_id.splitn(2, ':').collect();
        if parts.len() != 2 {
            return Err(anyhow::anyhow!(
                "Invalid Record ID format: {}. Expected 'table:uuid'",
                record_id
            ));
        }
        Ok((parts[0].to_string(), parts[1].to_string()))
    }
}

impl<C> SurrealStore<C>
where
    C: surrealdb::Connection,
{
    /// Convert binary blob embedding to f32 array for SurrealDB vector functions
    ///
    /// Embeddings are stored as Vec<u8> (bytes), but SurrealDB vector functions
    /// require Vec<f32>. This performs the conversion.
    ///
    /// # Arguments
    /// * `blob` - Binary embedding data (384 dimensions * 4 bytes = 1536 bytes)
    ///
    /// # Returns
    /// Vec<f32> with 384 elements
    ///
    /// # Errors
    /// Returns error if blob length is not divisible by 4 (invalid f32 encoding)
    fn blob_to_f32_array(blob: &[u8]) -> Result<Vec<f32>> {
        if !blob.len().is_multiple_of(4) {
            return Err(anyhow::anyhow!(
                "Invalid embedding blob: length {} not divisible by 4",
                blob.len()
            ));
        }

        let float_count = blob.len() / 4;
        let mut floats = Vec::with_capacity(float_count);

        for chunk in blob.chunks_exact(4) {
            let bytes: [u8; 4] = chunk.try_into().unwrap();
            floats.push(f32::from_le_bytes(bytes));
        }

        Ok(floats)
    }

    pub async fn create_node(&self, node: Node) -> Result<Node> {
        // Convert embedding blob to f32 array if present
        let embedding_f32 = node
            .embedding_vector
            .as_ref()
            .map(|blob| Self::blob_to_f32_array(blob))
            .transpose()?;

        // Insert into universal node table (graph-native architecture)
        // Record ID format: node:uuid (constructed by type::thing)
        let query = "
            CREATE type::thing($table, $id) CONTENT {
                type: $node_type,
                content: $content,
                before_sibling_id: $before_sibling_id,
                version: $version,
                created_at: $created_at,
                modified_at: $modified_at,
                embedding_vector: $embedding_vector,
                embedding_stale: $embedding_stale,
                mentions: $mentions,
                mentioned_by: $mentioned_by,
                data: $data,
                variants: $variants,
                _schema_version: $_schema_version
            };
        ";

        // Initialize graph-native fields
        let variants_value = serde_json::json!({});

        self.db
            .query(query)
            .bind(("table", "node"))
            .bind(("id", node.id.clone())) // Just the UUID, type::thing will construct node:uuid
            .bind(("node_type", node.node_type.clone()))
            .bind(("content", node.content.clone()))
            .bind(("before_sibling_id", node.before_sibling_id.clone()))
            .bind(("version", node.version))
            .bind(("created_at", node.created_at.to_rfc3339()))
            .bind(("modified_at", node.modified_at.to_rfc3339()))
            .bind(("embedding_vector", embedding_f32))
            .bind(("embedding_stale", false))
            .bind(("mentions", Vec::<String>::new()))
            .bind(("mentioned_by", Vec::<String>::new()))
            .bind(("data", None::<String>)) // Will be set below if type has properties
            .bind(("variants", variants_value))
            .bind(("_schema_version", 1i64))
            .await
            .context("Failed to create node in universal table")?;

        // Insert into type-specific table for types with properties (task, schema)
        let types_with_properties = ["task", "schema"];
        if types_with_properties.contains(&node.node_type.as_str())
            && !node
                .properties
                .as_object()
                .unwrap_or(&serde_json::Map::new())
                .is_empty()
        {
            // Store properties directly in type-specific table (flattened)
            let props = node.properties.clone();

            self.db
                .query("CREATE type::thing($table, $id) CONTENT $properties;")
                .bind(("table", node.node_type.clone()))
                .bind(("id", node.id.clone()))
                .bind(("properties", props))
                .await
                .context("Failed to create node in type-specific table")?;

            // Set data field to link to type-specific record
            self.db
                .query("UPDATE type::thing('node', $id) SET data = type::thing($type_table, $id);")
                .bind(("id", node.id.clone()))
                .bind(("type_table", node.node_type.clone()))
                .await
                .context("Failed to set data link")?;
        }

        // Create has_child graph edge if parent_id is set
        // This establishes the parent-child relationship in the graph
        if let Some(parent_id) = &node.parent_id {
            // Create Thing record IDs (not strings) for RELATE statement
            use surrealdb::sql::Thing;
            let parent_thing = Thing::from(("node".to_string(), parent_id.to_string()));
            let child_thing = Thing::from(("node".to_string(), node.id.clone()));

            self.db
                .query("RELATE $parent_thing->has_child->$child_thing;")
                .bind(("parent_thing", parent_thing))
                .bind(("child_thing", child_thing))
                .await
                .context("Failed to create parent-child edge")?;
        }

        // Return the created node directly
        Ok(node)
    }

    pub async fn get_node(&self, id: &str) -> Result<Option<Node>> {
        // Direct record ID lookup (O(1) primary key access)
        // Note: We don't use FETCH data because it causes deserialization issues
        // with the polymorphic data field (Thing vs Object)
        let query = "SELECT * FROM type::thing('node', $id);";
        let mut response = self
            .db
            .query(query)
            .bind(("id", id.to_string()))
            .await
            .context("Failed to query node by record ID")?;

        let surreal_nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract query results")?;

        let mut node_opt: Option<Node> = surreal_nodes.into_iter().map(Into::into).next();

        // If node exists and has properties (types: task, schema), fetch them separately
        if let Some(ref mut node) = node_opt {
            let types_with_properties = ["task", "schema"];
            if types_with_properties.contains(&node.node_type.as_str()) {
                // Fetch properties using SQL query, excluding 'id' field to avoid Thing deserialization issues
                // SELECT * OMIT id gets all fields except the id (which is a Thing type that can't deserialize to JSON)
                let props_query = format!(
                    "SELECT * OMIT id FROM type::thing('{}', $id);",
                    node.node_type
                );
                let mut props_response = self
                    .db
                    .query(&props_query)
                    .bind(("id", id.to_string()))
                    .await;

                let result: Option<serde_json::Value> = match props_response {
                    Ok(ref mut response) => {
                        let raw: Result<
                            Vec<std::collections::HashMap<String, serde_json::Value>>,
                            _,
                        > = response.take(0);
                        match raw {
                            Ok(records) => records
                                .into_iter()
                                .next()
                                .map(|map| serde_json::Value::Object(map.into_iter().collect())),
                            Err(_) => None,
                        }
                    }
                    Err(_) => None,
                };

                if let Some(props) = result {
                    // Properties already exclude 'id' due to OMIT in query
                    node.properties = props;
                }
            }
        }

        Ok(node_opt)
    }

    pub async fn update_node(&self, id: &str, update: NodeUpdate) -> Result<Node> {
        // Fetch current node
        let current = self
            .get_node(id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Node not found: {}", id))?;

        // Update using record ID (O(1) primary key access)
        let query = "
            UPDATE type::thing('node', $id) SET
                content = $content,
                type = $node_type,
                before_sibling_id = $before_sibling_id,
                modified_at = time::now(),
                version = version + 1,
                embedding_vector = $embedding_vector;
        ";

        let updated_content = update.content.unwrap_or(current.content);
        let updated_node_type = update.node_type.unwrap_or(current.node_type.clone());

        // Convert embedding blob to f32 if provided
        let embedding_f32 = update
            .embedding_vector
            .flatten()
            .as_ref()
            .map(|blob| Self::blob_to_f32_array(blob))
            .transpose()?;

        self.db
            .query(query)
            .bind(("id", id.to_string()))
            .bind(("content", updated_content))
            .bind(("node_type", updated_node_type.clone()))
            .bind(("before_sibling_id", update.before_sibling_id.flatten()))
            .bind(("embedding_vector", embedding_f32))
            .await
            .context("Failed to update node")?;

        // If properties were provided and node type has type-specific table, update it
        if let Some(updated_props) = update.properties {
            let types_with_properties = ["task", "schema"];
            if types_with_properties.contains(&updated_node_type.as_str()) {
                // Update or create record in type-specific table
                self.db
                    .query("UPDATE type::thing($table, $id) CONTENT $properties;")
                    .bind(("table", updated_node_type.clone()))
                    .bind(("id", id.to_string()))
                    .bind(("properties", updated_props))
                    .await
                    .context("Failed to update properties in type-specific table")?;

                // Ensure data link exists (in case this is a type change)
                self.db
                    .query("UPDATE type::thing('node', $id) SET data = type::thing($type_table, $id);")
                    .bind(("id", id.to_string()))
                    .bind(("type_table", updated_node_type))
                    .await
                    .context("Failed to set data link")?;
            }
        }

        // Fetch and return updated node
        self.get_node(id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Node not found after update"))
    }

    /// Update a node with version check (optimistic locking)
    ///
    /// Only updates the node if its version matches the expected version.
    /// This provides atomic version-checked updates to prevent lost updates
    /// in concurrent scenarios.
    ///
    /// # Arguments
    ///
    /// * `id` - Node UUID to update
    /// * `expected_version` - Expected current version (for optimistic locking)
    /// * `update` - Fields to update
    ///
    /// # Returns
    ///
    /// * `Ok(Some(Node))` - Update succeeded, returns updated node
    /// * `Ok(None)` - Version mismatch, no update performed
    /// * `Err(_)` - Database error or node not found
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// # use nodespace_core::db::SurrealStore;
    /// # use nodespace_core::models::NodeUpdate;
    /// # use std::path::PathBuf;
    /// # #[tokio::main]
    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// # let store = SurrealStore::new(PathBuf::from("./data/surreal.db")).await?;
    /// let update = NodeUpdate {
    ///     content: Some("Updated content".to_string()),
    ///     ..Default::default()
    /// };
    ///
    /// match store.update_node_with_version_check("node-id", 5, update).await? {
    ///     Some(node) => println!("Updated to version {}", node.version),
    ///     None => println!("Version mismatch - node was modified by another process"),
    /// }
    /// # Ok(())
    /// # }
    /// ```
    pub async fn update_node_with_version_check(
        &self,
        id: &str,
        expected_version: i64,
        update: NodeUpdate,
    ) -> Result<Option<Node>> {
        // Fetch current node to build update values
        let current = self
            .get_node(id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Node not found: {}", id))?;

        // Atomic update with version check using record ID
        // SurrealDB's UPDATE returns the updated records
        let query = "
            UPDATE type::thing('node', $id) SET
                content = $content,
                type = $node_type,
                before_sibling_id = $before_sibling_id,
                modified_at = time::now(),
                version = version + 1,
                embedding_vector = $embedding_vector
            WHERE version = $expected_version
            RETURN AFTER;
        ";

        let updated_content = update.content.unwrap_or(current.content);
        let updated_node_type = update.node_type.unwrap_or(current.node_type.clone());

        // Convert embedding blob to f32 if provided
        let embedding_f32 = update
            .embedding_vector
            .flatten()
            .as_ref()
            .map(|blob| Self::blob_to_f32_array(blob))
            .transpose()?;

        let mut response = self
            .db
            .query(query)
            .bind(("id", id.to_string()))
            .bind(("expected_version", expected_version))
            .bind(("content", updated_content))
            .bind(("node_type", updated_node_type))
            .bind(("before_sibling_id", update.before_sibling_id.flatten()))
            .bind(("embedding_vector", embedding_f32))
            .await
            .context("Failed to update node with version check")?;

        // Extract updated nodes from response
        let updated_nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract update results")?;

        // If no nodes were updated, version mismatch occurred
        if updated_nodes.is_empty() {
            return Ok(None);
        }

        // Convert and return the updated node
        Ok(Some(updated_nodes.into_iter().next().unwrap().into()))
    }

    pub async fn delete_node(&self, id: &str) -> Result<DeleteResult> {
        // Get node to determine type for Record ID
        let node = match self.get_node(id).await? {
            Some(n) => n,
            None => return Ok(DeleteResult { existed: false }),
        };

        // Delete using record IDs and graph edges
        // Use transaction for atomicity (all or nothing)
        let transaction_query = "
            BEGIN TRANSACTION;
            DELETE type::thing($table, $id);
            DELETE type::thing('node', $id);
            DELETE mentions WHERE in = type::thing('node', $id) OR out = type::thing('node', $id);
            DELETE has_child WHERE in = type::thing('node', $id) OR out = type::thing('node', $id);
            COMMIT TRANSACTION;
        ";

        self.db
            .query(transaction_query)
            .bind(("table", node.node_type.clone()))
            .bind(("id", node.id.clone()))
            .await
            .context("Failed to delete node and relations")?;

        Ok(DeleteResult { existed: true })
    }

    /// Delete a node with version check (optimistic locking)
    ///
    /// Only deletes the node if its version matches the expected version.
    /// Returns the number of rows affected (0 if version mismatch, 1 if deleted).
    pub async fn delete_with_version_check(
        &self,
        id: &str,
        expected_version: i64,
    ) -> Result<usize> {
        // First get the node to check version
        let node = match self.get_node(id).await? {
            Some(n) => n,
            None => return Ok(0), // Node doesn't exist
        };

        // Check version match
        if node.version != expected_version {
            return Ok(0); // Version mismatch, no deletion
        }

        // Version matches, proceed with deletion
        let result = self.delete_node(id).await?;
        Ok(if result.existed { 1 } else { 0 })
    }

    pub async fn query_nodes(&self, query: NodeQuery) -> Result<Vec<Node>> {
        // Handle mentioned_by query using graph traversal
        if let Some(ref mentioned_node_id) = query.mentioned_by {
            // Get the mentioned node to construct proper Record ID
            let mentioned_node = self
                .get_node(mentioned_node_id)
                .await?
                .ok_or_else(|| anyhow::anyhow!("Target node not found: {}", mentioned_node_id))?;

            let record_id = Self::to_record_id(&mentioned_node.node_type, &mentioned_node.id);
            let thing = Thing::from(("nodes", Id::String(record_id)));

            // Query nodes that have mentions pointing to this node
            let sql = if query.limit.is_some() {
                "SELECT VALUE in FROM mentions WHERE out = $target_thing LIMIT $limit;"
            } else {
                "SELECT VALUE in FROM mentions WHERE out = $target_thing;"
            };

            let mut query_builder = self.db.query(sql).bind(("target_thing", thing));

            if let Some(limit) = query.limit {
                query_builder = query_builder.bind(("limit", limit));
            }

            let mut response = query_builder
                .await
                .context("Failed to query mentioned_by nodes")?;

            let source_things: Vec<Thing> = response
                .take(0)
                .context("Failed to extract source nodes from mentions")?;

            // Fetch full node records for each source
            let mut nodes = Vec::new();
            for thing in source_things {
                if let Id::String(id_str) = &thing.id {
                    // Extract UUID from "node_type:uuid" format
                    if let Some(uuid) = id_str.split(':').nth(1) {
                        if let Some(node) = self.get_node(uuid).await? {
                            nodes.push(node);
                        }
                    }
                }
            }

            // Note: include_containers_and_tasks filter not applicable for semantic search
            // (would require additional graph query to check hierarchy)

            return Ok(nodes);
        }

        // Handle content_contains query
        if let Some(ref search_query) = query.content_contains {
            let nodes = self
                .search_nodes_by_content(search_query, query.limit.map(|l| l as i64))
                .await?;

            // Note: include_containers_and_tasks filter not applicable for content search
            // (would require additional graph query to check hierarchy)

            return Ok(nodes);
        }

        // Build WHERE clause conditions
        let mut conditions = Vec::new();

        if query.node_type.is_some() {
            conditions.push("type = $node_type".to_string());
        }

        if let Some(true) = query.include_containers_and_tasks {
            // Include tasks OR root nodes (no incoming has_child edges)
            conditions.push("(type = 'task' OR !EXISTS(<-has_child<-node))".to_string());
        }

        // Build SQL query
        let where_clause = if !conditions.is_empty() {
            Some(conditions.join(" AND "))
        } else {
            None
        };

        let sql = match (&where_clause, query.limit) {
            (None, None) => "SELECT * FROM node;".to_string(),
            (None, Some(_)) => "SELECT * FROM node LIMIT $limit;".to_string(),
            (Some(clause), None) => format!("SELECT * FROM node WHERE {};", clause),
            (Some(clause), Some(_)) => {
                format!("SELECT * FROM node WHERE {} LIMIT $limit;", clause)
            }
        };

        let mut query_builder = self.db.query(sql);

        if let Some(node_type) = &query.node_type {
            query_builder = query_builder.bind(("node_type", node_type.clone()));
        }

        if let Some(limit) = query.limit {
            query_builder = query_builder.bind(("limit", limit));
        }

        let mut response = query_builder.await.context("Failed to query nodes")?;
        let surreal_nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract nodes from query response")?;
        Ok(surreal_nodes.into_iter().map(Into::into).collect())
    }

    pub async fn get_children(&self, parent_id: Option<&str>) -> Result<Vec<Node>> {
        // Use graph edges for hierarchy traversal
        let surreal_nodes: Vec<SurrealNode> = if let Some(parent_id) = parent_id {
            // Create Thing record ID for parent node
            use surrealdb::sql::Thing;
            let parent_thing = Thing::from(("node".to_string(), parent_id.to_string()));

            // Use a subquery to find child IDs from has_child edges, then fetch the nodes
            let mut response = self
                .db
                .query("SELECT * FROM node WHERE id IN (SELECT VALUE out FROM has_child WHERE in = $parent_thing) FETCH data;")
                .bind(("parent_thing", parent_thing))
                .await
                .context("Failed to get children")?;

            response
                .take(0)
                .context("Failed to extract children from response")?
        } else {
            // Root nodes: nodes that have NO incoming has_child edges
            // Use count(<-has_child) = 0 to find nodes without parents
            let mut response = self
                .db
                .query("SELECT * FROM node WHERE count(<-has_child) = 0 FETCH data;")
                .await
                .context("Failed to get root nodes")?;

            response
                .take(0)
                .context("Failed to extract root nodes from response")?
        };

        // Sort by before_sibling_id in-memory (topological sort of linked list)
        // TODO: Implement proper linked list ordering
        Ok(surreal_nodes.into_iter().map(Into::into).collect())
    }

    pub async fn search_nodes_by_content(
        &self,
        search_query: &str,
        limit: Option<i64>,
    ) -> Result<Vec<Node>> {
        let sql = if limit.is_some() {
            "SELECT * FROM node WHERE content CONTAINS $search_query LIMIT $limit;"
        } else {
            "SELECT * FROM node WHERE content CONTAINS $search_query;"
        };

        let mut query_builder = self
            .db
            .query(sql)
            .bind(("search_query", search_query.to_string()));

        if let Some(lim) = limit {
            query_builder = query_builder.bind(("limit", lim));
        }

        let mut response = query_builder.await.context("Failed to search nodes")?;
        let surreal_nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract search results from response")?;
        Ok(surreal_nodes.into_iter().map(Into::into).collect())
    }

    pub async fn move_node(&self, id: &str, new_parent_id: Option<&str>) -> Result<()> {
        use surrealdb::sql::Thing;

        // Delete existing parent edge
        let child_thing = Thing::from(("node".to_string(), id.to_string()));
        self.db
            .query("DELETE has_child WHERE out = $child_thing;")
            .bind(("child_thing", child_thing.clone()))
            .await
            .context("Failed to delete existing parent edge")?;

        // Create new parent edge if parent is specified
        if let Some(parent_id) = new_parent_id {
            let parent_thing = Thing::from(("node".to_string(), parent_id.to_string()));
            self.db
                .query("RELATE $parent_thing->has_child->$child_thing;")
                .bind(("parent_thing", parent_thing))
                .bind(("child_thing", child_thing))
                .await
                .context("Failed to create new parent edge")?;
        }

        Ok(())
    }

    pub async fn reorder_node(&self, id: &str, new_before_sibling_id: Option<&str>) -> Result<()> {
        // Update using record ID
        self.db
            .query("UPDATE type::thing('node', $id) SET before_sibling_id = $before_sibling_id;")
            .bind(("id", id.to_string()))
            .bind((
                "before_sibling_id",
                new_before_sibling_id.map(|s| s.to_string()),
            ))
            .await
            .context("Failed to reorder node")?;

        Ok(())
    }

    pub async fn create_mention(
        &self,
        source_id: &str,
        target_id: &str,
        container_id: &str,
    ) -> Result<()> {
        // Get node types to construct proper Record IDs
        let source_node = self
            .get_node(source_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Source node not found: {}", source_id))?;
        let target_node = self
            .get_node(target_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Target node not found: {}", target_id))?;

        // Construct Thing objects for proper Record ID binding
        let source_record_id = Self::to_record_id(&source_node.node_type, &source_node.id);
        let target_record_id = Self::to_record_id(&target_node.node_type, &target_node.id);

        let source_thing = Thing::from(("nodes", Id::String(source_record_id)));
        let target_thing = Thing::from(("nodes", Id::String(target_record_id)));

        // Check if mention already exists (for idempotency)
        let check_query = "SELECT VALUE id FROM mentions WHERE in = $source AND out = $target;";
        let mut check_response = self
            .db
            .query(check_query)
            .bind(("source", source_thing.clone()))
            .bind(("target", target_thing.clone()))
            .await
            .context("Failed to check for existing mention")?;

        let existing_mention_ids: Vec<Thing> = check_response
            .take(0)
            .context("Failed to extract mention check results")?;

        // Only create mention if it doesn't exist
        if existing_mention_ids.is_empty() {
            // RELATE statement using Thing objects
            let query =
                "RELATE $source->mentions->$target CONTENT { container_id: $container_id };";

            self.db
                .query(query)
                .bind(("source", source_thing))
                .bind(("target", target_thing))
                .bind(("container_id", container_id.to_string()))
                .await
                .context("Failed to create mention")?;
        }

        Ok(())
    }

    pub async fn delete_mention(&self, source_id: &str, target_id: &str) -> Result<()> {
        // Get node types to construct proper Record IDs
        let source_node = self
            .get_node(source_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Source node not found: {}", source_id))?;
        let target_node = self
            .get_node(target_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Target node not found: {}", target_id))?;

        // Construct Thing objects for proper Record ID binding
        let source_record_id = Self::to_record_id(&source_node.node_type, &source_node.id);
        let target_record_id = Self::to_record_id(&target_node.node_type, &target_node.id);

        let source_thing = Thing::from(("nodes", Id::String(source_record_id)));
        let target_thing = Thing::from(("nodes", Id::String(target_record_id)));

        self.db
            .query("DELETE FROM mentions WHERE in = $source AND out = $target;")
            .bind(("source", source_thing))
            .bind(("target", target_thing))
            .await
            .context("Failed to delete mention")?;

        Ok(())
    }

    pub async fn get_outgoing_mentions(&self, node_id: &str) -> Result<Vec<String>> {
        // Get node type to construct proper Record ID
        let node = self
            .get_node(node_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Node not found: {}", node_id))?;

        // Construct Thing for proper Record ID binding
        let record_id = Self::to_record_id(&node.node_type, &node.id);
        let thing = Thing::from(("nodes", Id::String(record_id)));

        let query = "SELECT out FROM mentions WHERE in = $node_thing;";
        let mut response = self
            .db
            .query(query)
            .bind(("node_thing", thing))
            .await
            .context("Failed to get outgoing mentions")?;

        #[derive(Debug, Deserialize)]
        struct MentionOut {
            out: Thing,
        }

        let results: Vec<MentionOut> = response
            .take(0)
            .context("Failed to extract outgoing mentions from response")?;

        // Extract UUIDs from Thing Record IDs
        // Thing.id is Id::String("node_type:uuid"), so we need to extract just the UUID part
        Ok(results
            .into_iter()
            .filter_map(|m| {
                if let Id::String(id_str) = &m.out.id {
                    // id_str format: "node_type:uuid", extract UUID (after last colon)
                    id_str.split(':').nth(1).map(String::from)
                } else {
                    None
                }
            })
            .collect())
    }

    pub async fn get_incoming_mentions(&self, node_id: &str) -> Result<Vec<String>> {
        // Get node type to construct proper Record ID
        let node = self
            .get_node(node_id)
            .await?
            .ok_or_else(|| anyhow::anyhow!("Node not found: {}", node_id))?;

        // Construct Thing for proper Record ID binding
        let record_id = Self::to_record_id(&node.node_type, &node.id);
        let thing = Thing::from(("nodes", Id::String(record_id)));

        let query = "SELECT in FROM mentions WHERE out = $node_thing;";
        let mut response = self
            .db
            .query(query)
            .bind(("node_thing", thing))
            .await
            .context("Failed to get incoming mentions")?;

        #[derive(Debug, Deserialize)]
        struct MentionIn {
            #[serde(rename = "in")]
            in_field: Thing,
        }

        let results: Vec<MentionIn> = response
            .take(0)
            .context("Failed to extract incoming mentions from response")?;

        // Extract UUIDs from Thing Record IDs
        Ok(results
            .into_iter()
            .filter_map(|m| {
                if let Id::String(id_str) = &m.in_field.id {
                    // id_str format: "node_type:uuid", extract UUID (after first colon)
                    id_str.split(':').nth(1).map(String::from)
                } else {
                    None
                }
            })
            .collect())
    }

    pub async fn get_mentioning_containers(&self, node_id: &str) -> Result<Vec<Node>> {
        // Get node type to construct proper Record ID
        // If node doesn't exist, return empty array (not an error)
        let node = match self.get_node(node_id).await? {
            Some(n) => n,
            None => return Ok(Vec::new()),
        };

        // Construct Thing for proper Record ID binding
        let record_id = Self::to_record_id(&node.node_type, &node.id);
        let thing = Thing::from(("nodes", Id::String(record_id)));

        let query = "SELECT container_id FROM mentions WHERE out = $node_thing;";
        let mut response = self
            .db
            .query(query)
            .bind(("node_thing", thing))
            .await
            .context("Failed to get mentioning containers")?;

        #[derive(Debug, Deserialize)]
        struct MentionRecord {
            container_id: String,
        }

        let mention_records: Vec<MentionRecord> = response
            .take(0)
            .context("Failed to extract container IDs from response")?;

        // Deduplicate container IDs
        let mut container_ids: Vec<String> = mention_records
            .into_iter()
            .map(|m| m.container_id)
            .collect();
        container_ids.sort();
        container_ids.dedup();

        // Fetch full node records
        let mut nodes = Vec::new();
        for container_id in container_ids {
            if let Some(node) = self.get_node(&container_id).await? {
                nodes.push(node);
            }
        }

        Ok(nodes)
    }

    pub async fn get_schema(&self, node_type: &str) -> Result<Option<Value>> {
        // Schema nodes use simple IDs (just the node type name, e.g., "date")
        // They're differentiated by node_type = "schema"
        let schema_id = node_type.to_string();
        let node = self.get_node(&schema_id).await?;
        Ok(node.map(|n| n.properties))
    }

    pub async fn update_schema(&self, node_type: &str, schema: &Value) -> Result<()> {
        // Schema nodes use simple IDs (just the node type name, e.g., "date")
        let schema_id = node_type.to_string();

        // Check if schema node exists
        if self.get_node(&schema_id).await?.is_some() {
            // Update existing schema
            let update = NodeUpdate {
                properties: Some(schema.clone()),
                ..Default::default()
            };
            self.update_node(&schema_id, update).await?;
        } else {
            // Create new schema node with deterministic ID
            let node = Node::new_with_id(
                schema_id,
                "schema".to_string(),
                node_type.to_string(),
                None,
                schema.clone(),
            );
            self.create_node(node).await?;
        }

        Ok(())
    }

    pub async fn get_nodes_without_embeddings(&self, limit: Option<i64>) -> Result<Vec<Node>> {
        let sql = if limit.is_some() {
            "SELECT * FROM node WHERE embedding_vector IS NONE LIMIT $limit;"
        } else {
            "SELECT * FROM node WHERE embedding_vector IS NONE;"
        };

        let mut query_builder = self.db.query(sql);

        if let Some(lim) = limit {
            query_builder = query_builder.bind(("limit", lim));
        }

        let mut response = query_builder
            .await
            .context("Failed to get nodes without embeddings")?;
        let surreal_nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract nodes without embeddings from response")?;
        Ok(surreal_nodes.into_iter().map(Into::into).collect())
    }

    pub async fn update_embedding(&self, node_id: &str, embedding: &[u8]) -> Result<()> {
        // Convert binary blob to f32 array for SurrealDB vector functions
        let embedding_f32 = Self::blob_to_f32_array(embedding)?;

        // Update using record ID
        self.db
            .query("UPDATE type::thing('node', $id) SET embedding_vector = $embedding, embedding_stale = false;")
            .bind(("id", node_id.to_string()))
            .bind(("embedding", embedding_f32))
            .await
            .context("Failed to update embedding")?;

        Ok(())
    }

    /// Mark a node's embedding as stale (needing regeneration)
    ///
    /// Called when node content changes, signaling that the embedding vector
    /// needs to be regenerated. The embedding processor can then query for
    /// stale nodes and regenerate embeddings in batches.
    ///
    /// # Arguments
    ///
    /// * `node_id` - UUID of the node to mark as stale
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// # use nodespace_core::db::SurrealStore;
    /// # use std::path::PathBuf;
    /// # #[tokio::main]
    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// # let store = SurrealStore::new(PathBuf::from("./data/surreal.db")).await?;
    /// // Mark embedding as stale after content change
    /// store.mark_embedding_stale("node-id").await?;
    /// # Ok(())
    /// # }
    /// ```
    pub async fn mark_embedding_stale(&self, node_id: &str) -> Result<()> {
        // Update using record ID
        self.db
            .query("UPDATE type::thing('node', $id) SET embedding_stale = true;")
            .bind(("id", node_id.to_string()))
            .await
            .context("Failed to mark embedding as stale")?;

        Ok(())
    }

    /// Get nodes with stale embeddings
    ///
    /// Returns nodes where content has changed since the embedding was generated,
    /// allowing the embedding processor to regenerate embeddings in batches.
    ///
    /// # Arguments
    ///
    /// * `limit` - Optional limit on number of nodes to return
    ///
    /// # Returns
    ///
    /// Vector of nodes with stale embeddings (embedding_stale = true)
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// # use nodespace_core::db::SurrealStore;
    /// # use std::path::PathBuf;
    /// # #[tokio::main]
    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// # let store = SurrealStore::new(PathBuf::from("./data/surreal.db")).await?;
    /// // Get up to 100 nodes needing embedding regeneration
    /// let stale_nodes = store.get_nodes_with_stale_embeddings(Some(100)).await?;
    /// # Ok(())
    /// # }
    /// ```
    pub async fn get_nodes_with_stale_embeddings(&self, limit: Option<i64>) -> Result<Vec<Node>> {
        let sql = if limit.is_some() {
            "SELECT * FROM node WHERE embedding_stale = true LIMIT $limit;"
        } else {
            "SELECT * FROM node WHERE embedding_stale = true;"
        };

        let mut query_builder = self.db.query(sql);

        if let Some(lim) = limit {
            query_builder = query_builder.bind(("limit", lim));
        }

        let mut response = query_builder
            .await
            .context("Failed to get nodes with stale embeddings")?;
        let surreal_nodes: Vec<SurrealNode> = response
            .take(0)
            .context("Failed to extract nodes with stale embeddings from response")?;
        Ok(surreal_nodes.into_iter().map(Into::into).collect())
    }

    /// Search for nodes by embedding similarity using SurrealDB's native vector functions
    ///
    /// Converts the query embedding from binary blob to f32 array, then uses
    /// SurrealDB's `vector::similarity::cosine()` to find semantically similar nodes.
    ///
    /// # Arguments
    /// * `embedding` - Query embedding as binary blob (from EmbeddingService::to_blob)
    /// * `limit` - Maximum number of results to return
    /// * `threshold` - Optional minimum similarity score (0.0-1.0, default: 0.5)
    ///
    /// # Returns
    /// Vector of (Node, similarity_score) tuples, sorted by similarity descending
    pub async fn search_by_embedding(
        &self,
        embedding: &[u8],
        limit: i64,
        threshold: Option<f64>,
    ) -> Result<Vec<(Node, f64)>> {
        // Convert binary blob to f32 array for SurrealDB
        let query_vector = Self::blob_to_f32_array(embedding)?;

        // Default threshold: 0.5 (moderate similarity)
        let min_similarity = threshold.unwrap_or(0.5);

        // SurrealDB query using vector::similarity::cosine
        // We need to explicitly select fields to avoid deserialization issues with the computed similarity field
        // Use SurrealQL's OR operator to provide defaults for NONE values (SurrealDB's COALESCE equivalent)
        let query = r#"
            SELECT
                uuid,
                node_type,
                content,
                parent_id,
                container_node_id,
                before_sibling_id,
                version,
                created_at,
                modified_at,
                properties,
                embedding_vector,
                embedding_stale OR false AS embedding_stale,
                mentions OR [] AS mentions,
                mentioned_by OR [] AS mentioned_by,
                vector::similarity::cosine(embedding_vector, $query_vector) AS similarity
            FROM node
            WHERE embedding_vector != NONE
              AND vector::similarity::cosine(embedding_vector, $query_vector) > $threshold
            ORDER BY similarity DESC
            LIMIT $limit;
        "#;

        let mut response = self
            .db
            .query(query)
            .bind(("query_vector", query_vector))
            .bind(("threshold", min_similarity))
            .bind(("limit", limit))
            .await
            .context("Failed to execute vector similarity search")?;

        // Deserialize response with similarity scores
        #[derive(Debug, Deserialize)]
        struct NodeWithSimilarity {
            id: Thing,
            #[serde(rename = "type")]
            node_type: String,
            content: String,
            #[serde(default)]
            before_sibling_id: Option<String>,
            version: i64,
            created_at: String,
            modified_at: String,
            #[serde(default)]
            embedding_vector: Option<Vec<f32>>,
            #[serde(default)]
            embedding_stale: bool,
            #[serde(default)]
            mentions: Vec<String>,
            #[serde(default)]
            mentioned_by: Vec<String>,
            #[serde(skip_deserializing)]
            data: Option<Value>,
            #[serde(default)]
            variants: Value,
            #[serde(default)]
            _schema_version: i64,
            similarity: f64,
        }

        let results: Vec<NodeWithSimilarity> = response
            .take(0)
            .context("Failed to extract similarity search results")?;

        // Convert to (Node, f64) tuples
        Ok(results
            .into_iter()
            .map(|nws| {
                let surreal_node = SurrealNode {
                    id: nws.id,
                    node_type: nws.node_type,
                    content: nws.content,
                    before_sibling_id: nws.before_sibling_id,
                    version: nws.version,
                    created_at: nws.created_at,
                    modified_at: nws.modified_at,
                    embedding_vector: nws.embedding_vector,
                    embedding_stale: nws.embedding_stale,
                    mentions: nws.mentions,
                    mentioned_by: nws.mentioned_by,
                    data: nws.data,
                    variants: nws.variants,
                    _schema_version: nws._schema_version,
                };
                (surreal_node.into(), nws.similarity)
            })
            .collect())
    }

    /// Atomic bulk update using SurrealDB transactions
    ///
    /// Updates multiple nodes in a single atomic transaction. Either all updates
    /// succeed or all fail (rollback), ensuring data consistency.
    ///
    /// # Performance Considerations
    ///
    /// - **Optimal Batch Size:** 10-100 nodes (transaction overhead minimal)
    /// - **Large Batches:** >1000 nodes may hit transaction timeout (consider chunking)
    /// - **Validation Cost:** Pre-fetches all nodes for existence check
    ///
    /// # Arguments
    ///
    /// * `updates` - Vector of (node_id, NodeUpdate) tuples to apply
    ///
    /// # Returns
    ///
    /// * `Ok(())` - All updates succeeded
    /// * `Err(_)` - Transaction failed and rolled back, or batch size exceeded limit
    ///
    /// # Examples
    ///
    /// ```rust,no_run
    /// # use nodespace_core::db::SurrealStore;
    /// # use nodespace_core::models::NodeUpdate;
    /// # use std::path::PathBuf;
    /// # #[tokio::main]
    /// # async fn main() -> Result<(), Box<dyn std::error::Error>> {
    /// # let store = SurrealStore::new(PathBuf::from("./data/surreal.db")).await?;
    /// let updates = vec![
    ///     ("node-1".to_string(), NodeUpdate {
    ///         content: Some("New content 1".to_string()),
    ///         ..Default::default()
    ///     }),
    ///     ("node-2".to_string(), NodeUpdate {
    ///         content: Some("New content 2".to_string()),
    ///         ..Default::default()
    ///     }),
    /// ];
    ///
    /// store.bulk_update(updates).await?; // All-or-nothing
    /// # Ok(())
    /// # }
    /// ```
    pub async fn bulk_update(&self, updates: Vec<(String, NodeUpdate)>) -> Result<()> {
        if updates.is_empty() {
            return Ok(());
        }

        // Prevent excessive batch sizes that could cause transaction timeouts
        const MAX_BATCH_SIZE: usize = 1000;
        if updates.len() > MAX_BATCH_SIZE {
            return Err(anyhow::anyhow!(
                "Bulk update batch size ({}) exceeds maximum ({}). Consider chunking the updates into smaller batches.",
                updates.len(),
                MAX_BATCH_SIZE
            ));
        }

        // Build transaction query
        let mut transaction_parts = vec!["BEGIN TRANSACTION;".to_string()];

        for (idx, (id, _)) in updates.iter().enumerate() {
            // Validate node exists (will fetch again later for merging values)
            self.get_node(id)
                .await?
                .ok_or_else(|| anyhow::anyhow!("Node not found: {}", id))?;

            // Generate UPDATE statement using record ID
            let update_stmt = format!(
                "UPDATE type::thing('node', $id_{idx}) SET
                    content = $content_{idx},
                    type = $node_type_{idx},
                    before_sibling_id = $before_sibling_id_{idx},
                    modified_at = time::now(),
                    version = version + 1,
                    embedding_vector = $embedding_vector_{idx};",
                idx = idx
            );
            transaction_parts.push(update_stmt);
        }

        transaction_parts.push("COMMIT TRANSACTION;".to_string());
        let transaction_query = transaction_parts.join("\n");

        // Build query with all bindings
        let mut query_builder = self.db.query(transaction_query);

        for (idx, (id, update)) in updates.iter().enumerate() {
            // Fetch current node again for building merged values
            let current = self
                .get_node(id)
                .await?
                .ok_or_else(|| anyhow::anyhow!("Node not found: {}", id))?;

            let updated_content = update.content.clone().unwrap_or(current.content);
            let updated_node_type = update.node_type.clone().unwrap_or(current.node_type);

            // Convert embedding blob to f32 if provided
            let embedding_f32 = update
                .embedding_vector
                .clone()
                .flatten()
                .as_ref()
                .map(|blob| Self::blob_to_f32_array(blob))
                .transpose()?;

            query_builder = query_builder
                .bind((format!("id_{}", idx), id.clone()))
                .bind((format!("content_{}", idx), updated_content))
                .bind((format!("node_type_{}", idx), updated_node_type))
                .bind((
                    format!("before_sibling_id_{}", idx),
                    update.before_sibling_id.clone().flatten(),
                ))
                .bind((format!("embedding_vector_{}", idx), embedding_f32));
        }

        query_builder
            .await
            .context("Failed to execute bulk update transaction")?;

        Ok(())
    }

    pub async fn batch_create_nodes(&self, nodes: Vec<Node>) -> Result<Vec<Node>> {
        let mut created_nodes = Vec::new();

        for node in nodes {
            let created = self.create_node(node).await?;
            created_nodes.push(created);
        }

        Ok(created_nodes)
    }

    pub fn close(&self) -> Result<()> {
        // SurrealDB handles cleanup automatically on drop
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde_json::json;
    use tempfile::TempDir;

    async fn create_test_store() -> Result<(SurrealStore, TempDir)> {
        let temp_dir = TempDir::new()?;
        let db_path = temp_dir.path().join("test_surreal.db");
        let store = SurrealStore::new(db_path).await?;
        Ok((store, temp_dir))
    }

    #[tokio::test]
    async fn test_create_and_get_node() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        let node = Node::new(
            "text".to_string(),
            "Test content".to_string(),
            None,
            json!({}),
        );

        let created = store.create_node(node.clone()).await?;
        assert_eq!(created.id, node.id);
        assert_eq!(created.content, "Test content");

        let fetched = store.get_node(&node.id).await?;
        assert!(fetched.is_some());
        assert_eq!(fetched.unwrap().id, node.id);

        Ok(())
    }

    #[tokio::test]
    async fn test_update_node() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        let node = Node::new(
            "text".to_string(),
            "Original content".to_string(),
            None,
            json!({}),
        );

        let created = store.create_node(node.clone()).await?;

        let update = NodeUpdate {
            content: Some("Updated content".to_string()),
            ..Default::default()
        };

        let updated = store.update_node(&created.id, update).await?;
        assert_eq!(updated.content, "Updated content");

        Ok(())
    }

    #[tokio::test]
    async fn test_delete_node() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        let node = Node::new(
            "text".to_string(),
            "Test content".to_string(),
            None,
            json!({}),
        );

        let created = store.create_node(node.clone()).await?;

        let result = store.delete_node(&created.id).await?;
        assert!(result.existed);

        let fetched = store.get_node(&created.id).await?;
        assert!(fetched.is_none());

        Ok(())
    }

    #[tokio::test]
    async fn test_schema_operations() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        let schema = json!({
            "type": "object",
            "properties": {
                "status": {"type": "string"}
            }
        });

        store.update_schema("task", &schema).await?;

        let fetched = store.get_schema("task").await?;
        assert!(fetched.is_some());
        assert_eq!(fetched.unwrap(), schema);

        Ok(())
    }

    // Vector Similarity Search Tests

    #[test]
    fn test_blob_to_f32_conversion() {
        // Valid embedding: 3 floats (12 bytes)
        let floats = [1.0f32, 2.5f32, -0.5f32];
        let blob: Vec<u8> = floats.iter().flat_map(|f| f.to_le_bytes()).collect();

        let result = EmbeddedStore::blob_to_f32_array(&blob).unwrap();
        assert_eq!(result.len(), 3);
        assert_eq!(result[0], 1.0);
        assert_eq!(result[1], 2.5);
        assert_eq!(result[2], -0.5);
    }

    #[test]
    fn test_blob_to_f32_invalid_length() {
        // Invalid blob: 13 bytes (not divisible by 4)
        let invalid_blob = vec![0u8; 13];

        let result = EmbeddedStore::blob_to_f32_array(&invalid_blob);
        assert!(result.is_err());
        assert!(result
            .unwrap_err()
            .to_string()
            .contains("not divisible by 4"));
    }

    #[tokio::test]
    async fn test_search_empty_database() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create a dummy embedding (384 floats)
        let query_vector = vec![0.5f32; 384];
        let query_blob: Vec<u8> = query_vector.iter().flat_map(|f| f.to_le_bytes()).collect();

        // Search empty database
        let results = store.search_by_embedding(&query_blob, 10, None).await?;

        assert_eq!(results.len(), 0, "Empty database should return no results");

        Ok(())
    }

    #[tokio::test]
    async fn test_search_with_similar_nodes() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create nodes with different embeddings
        let base_vector = vec![1.0f32; 384];
        let similar_vector = vec![0.99f32; 384]; // Very similar
        let dissimilar_vector = vec![-1.0f32; 384]; // Opposite direction

        let base_blob: Vec<u8> = base_vector.iter().flat_map(|f| f.to_le_bytes()).collect();
        let similar_blob: Vec<u8> = similar_vector
            .iter()
            .flat_map(|f| f.to_le_bytes())
            .collect();
        let dissimilar_blob: Vec<u8> = dissimilar_vector
            .iter()
            .flat_map(|f| f.to_le_bytes())
            .collect();

        // Create nodes
        let node1 = Node::new(
            "text".to_string(),
            "Base content".to_string(),
            None,
            json!({}),
        );
        let mut created1 = store.create_node(node1).await?;
        store.update_embedding(&created1.id, &similar_blob).await?;
        created1.embedding_vector = Some(similar_blob.clone());

        let node2 = Node::new(
            "text".to_string(),
            "Dissimilar content".to_string(),
            None,
            json!({}),
        );
        let mut created2 = store.create_node(node2).await?;
        store
            .update_embedding(&created2.id, &dissimilar_blob)
            .await?;
        created2.embedding_vector = Some(dissimilar_blob);

        // Search with base embedding
        let results = store.search_by_embedding(&base_blob, 10, None).await?;

        // Should return nodes sorted by similarity (highest first)
        assert!(!results.is_empty(), "Should find at least one similar node");

        // First result should be more similar (higher score)
        if results.len() > 1 {
            assert!(
                results[0].1 > results[1].1,
                "Results should be sorted by similarity descending"
            );
        }

        Ok(())
    }

    #[tokio::test]
    async fn test_search_with_threshold_filter() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create query vector
        let query_vector = vec![1.0f32; 384];
        let query_blob: Vec<u8> = query_vector.iter().flat_map(|f| f.to_le_bytes()).collect();

        // Create node with similar embedding
        let similar_vector = vec![0.99f32; 384];
        let similar_blob: Vec<u8> = similar_vector
            .iter()
            .flat_map(|f| f.to_le_bytes())
            .collect();

        let node = Node::new(
            "text".to_string(),
            "Test content".to_string(),
            None,
            json!({}),
        );
        let created = store.create_node(node).await?;
        store.update_embedding(&created.id, &similar_blob).await?;

        // Search with high threshold (0.99) - should find the node
        let results_high_threshold = store
            .search_by_embedding(&query_blob, 10, Some(0.9))
            .await?;
        assert!(
            !results_high_threshold.is_empty(),
            "Should find node with similarity > 0.9"
        );

        // Search with very high threshold (0.999) - might not find it
        let results_very_high = store
            .search_by_embedding(&query_blob, 10, Some(0.999))
            .await?;
        // This test is lenient because exact similarity depends on normalization
        assert!(
            results_very_high.len() <= results_high_threshold.len(),
            "Higher threshold should return fewer or equal results"
        );

        Ok(())
    }

    #[tokio::test]
    async fn test_search_respects_limit() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create 5 nodes with embeddings
        let base_vector = vec![1.0f32; 384];
        let blob: Vec<u8> = base_vector.iter().flat_map(|f| f.to_le_bytes()).collect();

        for i in 0..5 {
            let node = Node::new(
                "text".to_string(),
                format!("Content {}", i),
                None,
                json!({}),
            );
            let created = store.create_node(node).await?;
            store.update_embedding(&created.id, &blob).await?;
        }

        // Search with limit of 3
        let results = store.search_by_embedding(&blob, 3, Some(0.5)).await?;

        assert!(
            results.len() <= 3,
            "Should respect limit parameter (expected <= 3, got {})",
            results.len()
        );

        Ok(())
    }

    // Performance Benchmark Tests
    //
    // These tests measure search query performance on databases of varying sizes.
    // Current implementation uses linear scan (O(n)) without vector indexes.
    // Performance targets are based on real-world measurements on RocksDB storage.

    #[tokio::test]
    async fn test_search_performance_1k_nodes() -> Result<()> {
        let (store, _temp_dir) = create_test_store().await?;

        // Create 1,000 nodes with embeddings
        let base_vector = vec![1.0f32; 384];
        let blob: Vec<u8> = base_vector.iter().flat_map(|f| f.to_le_bytes()).collect();

        tracing::info!("Creating 1,000 nodes for performance test...");
        for i in 0..1000 {
            let node = Node::new(
                "text".to_string(),
                format!("Performance test content {}", i),
                None,
                json!({}),
            );
            let created = store.create_node(node).await?;
            store.update_embedding(&created.id, &blob).await?;

            if i % 100 == 0 {
                tracing::info!("Created {} nodes", i);
            }
        }

        tracing::info!("Starting performance benchmark...");

        // Measure search time (after data is created)
        let start = std::time::Instant::now();
        let results = store.search_by_embedding(&blob, 20, Some(0.5)).await?;
        let elapsed = start.elapsed();

        tracing::info!(
            "Search completed in {:?} with {} results",
            elapsed,
            results.len()
        );

        // Performance target: < 1500ms for 1,000 nodes (linear scan on RocksDB)
        // Real-world measurement: ~950ms
        // Note: This is the search query time only, not data creation time
        assert!(
            elapsed.as_millis() < 1500,
            "Search should complete in < 1500ms (took {:?})",
            elapsed
        );

        Ok(())
    }

    #[tokio::test]
    async fn test_search_with_real_nlp_embeddings() -> Result<()> {
        use nodespace_nlp_engine::EmbeddingService;
        use std::sync::Arc;

        let (store, _temp_dir) = create_test_store().await?;

        // Initialize real NLP engine
        let mut nlp_service = EmbeddingService::new(Default::default())?;
        nlp_service.initialize()?;
        let nlp = Arc::new(nlp_service);

        // Create nodes with semantically similar and dissimilar content
        let similar_text_1 = "Machine learning algorithms for data analysis";
        let similar_text_2 = "Deep learning neural networks and AI models";
        let dissimilar_text = "The weather forecast predicts sunny skies tomorrow";

        // Generate real embeddings
        let emb1 = nlp.generate_embedding(similar_text_1)?;
        let emb2 = nlp.generate_embedding(similar_text_2)?;
        let emb3 = nlp.generate_embedding(dissimilar_text)?;

        let blob1 = EmbeddingService::to_blob(&emb1);
        let blob2 = EmbeddingService::to_blob(&emb2);
        let blob3 = EmbeddingService::to_blob(&emb3);

        // Create nodes
        let node1 = Node::new(
            "text".to_string(),
            similar_text_1.to_string(),
            None,
            json!({}),
        );
        let mut created1 = store.create_node(node1).await?;
        store.update_embedding(&created1.id, &blob1).await?;
        created1.embedding_vector = Some(blob1.clone());

        let node2 = Node::new(
            "text".to_string(),
            similar_text_2.to_string(),
            None,
            json!({}),
        );
        let mut created2 = store.create_node(node2).await?;
        store.update_embedding(&created2.id, &blob2).await?;
        created2.embedding_vector = Some(blob2.clone());

        let node3 = Node::new(
            "text".to_string(),
            dissimilar_text.to_string(),
            None,
            json!({}),
        );
        let mut created3 = store.create_node(node3).await?;
        store.update_embedding(&created3.id, &blob3).await?;
        created3.embedding_vector = Some(blob3);

        // Search with first embedding (machine learning topic)
        let results = store.search_by_embedding(&blob1, 10, Some(0.3)).await?;

        // Verify results
        assert!(!results.is_empty(), "Should find at least one similar node");

        // The most similar should be the ML/AI content (node2), not the weather content
        let (top_node, top_similarity) = &results[0];
        tracing::info!(
            "Top result: content='{}', similarity={:.3}",
            top_node.content,
            top_similarity
        );

        // Find similarity scores for each content type
        let ml_similarity = results
            .iter()
            .find(|(n, _)| n.id == created2.id)
            .map(|(_, s)| *s);
        let weather_similarity = results
            .iter()
            .find(|(n, _)| n.id == created3.id)
            .map(|(_, s)| *s);

        tracing::info!(
            "ML/AI similarity: {:?}, Weather similarity: {:?}",
            ml_similarity,
            weather_similarity
        );

        // ML/AI content should be more similar to the query than weather content
        if let (Some(ml_sim), Some(weather_sim)) = (ml_similarity, weather_similarity) {
            assert!(
                ml_sim > weather_sim,
                "ML/AI content (sim={:.3}) should rank higher than weather content (sim={:.3})",
                ml_sim,
                weather_sim
            );
        }

        // Top result should have high similarity (> 0.7 for semantically related content)
        assert!(
            top_similarity > &0.5,
            "Top result should have similarity > 0.5 (got {:.3})",
            top_similarity
        );

        Ok(())
    }

    #[tokio::test]
    async fn test_search_performance_10k_nodes() -> Result<()> {
        // Skip this test unless RUN_LONG_TESTS=1 is set
        // Reason: Test takes ~10 minutes total (10K node creation + search)
        // The search itself is fast (~9.5s), but setup is slow
        if std::env::var("RUN_LONG_TESTS").unwrap_or_default() != "1" {
            eprintln!("Skipping 10K performance test (set RUN_LONG_TESTS=1 to run)");
            return Ok(());
        }

        let (store, _temp_dir) = create_test_store().await?;

        // Create 10,000 nodes with embeddings
        let base_vector = vec![1.0f32; 384];
        let blob: Vec<u8> = base_vector.iter().flat_map(|f| f.to_le_bytes()).collect();

        tracing::info!("Creating 10,000 nodes for performance test...");
        for i in 0..10000 {
            let node = Node::new(
                "text".to_string(),
                format!("Performance test content {}", i),
                None,
                json!({}),
            );
            let created = store.create_node(node).await?;
            store.update_embedding(&created.id, &blob).await?;

            if i % 1000 == 0 {
                tracing::info!("Created {} nodes", i);
            }
        }

        tracing::info!("Starting performance benchmark...");

        // Measure search time
        let start = std::time::Instant::now();
        let results = store.search_by_embedding(&blob, 20, Some(0.5)).await?;
        let elapsed = start.elapsed();

        tracing::info!(
            "Search completed in {:?} with {} results",
            elapsed,
            results.len()
        );

        // Performance target: < 15000ms (15 seconds) for 10,000 nodes (linear scan)
        // Estimated: ~9.5 seconds based on 1K node measurements (linear scaling)
        // Note: This is acceptable for MVP without vector indexes
        assert!(
            elapsed.as_millis() < 15000,
            "Search should complete in < 15s (took {:?})",
            elapsed
        );

        Ok(())
    }
}
